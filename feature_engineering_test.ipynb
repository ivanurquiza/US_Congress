{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Test - 25 Trades\n",
    "\n",
    "Testing the feature engineering pipeline on a small sample before running on 100k trades.\n",
    "\n",
    "**What this does:**\n",
    "1. Classify asset types (stock/treasury/etf)\n",
    "2. Extract market features for each type\n",
    "3. Calculate returns, fundamentals, technicals, events\n",
    "4. Output wide dataset ready for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For tech indicators\n",
    "try:\n",
    "    import ta\n",
    "except:\n",
    "    print(\"Installing ta library...\")\n",
    "    !pip install ta --quiet\n",
    "    import ta\n",
    "\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data\n",
    "\n",
    "Load your trades CSV and take first 25 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "# df_full = pd.read_csv('your_trades.csv')\n",
    "\n",
    "# For testing, create sample data structure\n",
    "# Replace this with: df = df_full.head(25)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': ['2024-01-15', '2024-01-20', '2024-02-01'],\n",
    "    'ticker': ['AAPL', 'TLT', 'SPY'],\n",
    "    'Company': ['Apple Inc.', 'iShares 20+ Year Treasury Bond ETF', 'SPDR S&P 500 ETF Trust'],\n",
    "    'transaction_type': ['Purchase', 'Sale', 'Purchase'],\n",
    "    'amount': [50000, 100000, 75000],\n",
    "    'member_name': ['Rep. Smith', 'Sen. Jones', 'Rep. Davis']\n",
    "})\n",
    "\n",
    "# Convert date\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"Testing with {len(df)} trades\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Classify Asset Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_asset(ticker, company_name):\n",
    "    \"\"\"\n",
    "    Figure out what kind of asset this is\n",
    "    \"\"\"\n",
    "    ticker_upper = str(ticker).upper()\n",
    "    company_upper = str(company_name).upper()\n",
    "    \n",
    "    # Treasury bonds\n",
    "    treasury_keywords = ['TREASURY', 'T-BILL', 'US GOVT', 'GOVERNMENT BOND']\n",
    "    if any(kw in company_upper for kw in treasury_keywords):\n",
    "        return 'treasury'\n",
    "    \n",
    "    # ETFs\n",
    "    etf_keywords = ['ETF', 'ISHARES', 'VANGUARD', 'SPDR', 'INVESCO', 'PROSHARES']\n",
    "    if any(kw in company_upper for kw in etf_keywords):\n",
    "        return 'etf'\n",
    "    \n",
    "    # Property transactions (skip these)\n",
    "    property_keywords = ['PROPERTY', 'REAL ESTATE TRANSACTION', 'LAND']\n",
    "    if any(kw in company_upper for kw in property_keywords):\n",
    "        return 'property'\n",
    "    \n",
    "    # Corporate bonds (not treasury, but has BOND)\n",
    "    if 'BOND' in company_upper and 'ETF' not in company_upper:\n",
    "        return 'corporate_bond'\n",
    "    \n",
    "    # Everything else is a stock\n",
    "    return 'stock'\n",
    "\n",
    "# Apply classification\n",
    "df['asset_type'] = df.apply(lambda x: classify_asset(x['ticker'], x['Company']), axis=1)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nAsset type distribution:\")\n",
    "print(df['asset_type'].value_counts())\n",
    "\n",
    "# Filter out property transactions\n",
    "df = df[df['asset_type'] != 'property'].copy()\n",
    "print(f\"\\nAfter filtering: {len(df)} trades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Price Data (Batch)\n",
    "\n",
    "Download all historical data at once to avoid repeated API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_all_price_data(df, lookback_years=3):\n",
    "    \"\"\"\n",
    "    Download price history for all unique tickers\n",
    "    Returns dict: {ticker: DataFrame}\n",
    "    \"\"\"\n",
    "    # Get date range\n",
    "    min_date = df['date'].min() - timedelta(days=lookback_years * 365)\n",
    "    max_date = df['date'].max() + timedelta(days=200)  # For forward returns\n",
    "    \n",
    "    print(f\"Downloading data from {min_date.date()} to {max_date.date()}\")\n",
    "    \n",
    "    # Get unique tickers\n",
    "    tickers = df['ticker'].unique()\n",
    "    print(f\"Unique tickers: {len(tickers)}\")\n",
    "    \n",
    "    price_data = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            print(f\"  Downloading {ticker}...\", end=\" \")\n",
    "            data = yf.download(ticker, start=min_date, end=max_date, progress=False)\n",
    "            \n",
    "            if len(data) > 0:\n",
    "                price_data[ticker] = data\n",
    "                print(f\"✓ {len(data)} days\")\n",
    "            else:\n",
    "                print(\"✗ No data\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error: {e}\")\n",
    "    \n",
    "    return price_data\n",
    "\n",
    "# Download\n",
    "price_data = download_all_price_data(df)\n",
    "print(f\"\\nSuccessfully downloaded {len(price_data)} tickers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Functions\n",
    "\n",
    "Each function extracts specific features from the cached price data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. Returns (backward and forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_returns(ticker, trade_date, price_data):\n",
    "    \"\"\"\n",
    "    Calculate returns before and after trade date\n",
    "    \"\"\"\n",
    "    if ticker not in price_data:\n",
    "        return {}\n",
    "    \n",
    "    data = price_data[ticker]\n",
    "    \n",
    "    # Find closest date (in case trade_date is weekend/holiday)\n",
    "    dates = data.index\n",
    "    closest_idx = dates.searchsorted(trade_date)\n",
    "    \n",
    "    if closest_idx >= len(dates) or closest_idx == 0:\n",
    "        return {}\n",
    "    \n",
    "    trade_idx = closest_idx\n",
    "    trade_price = data.iloc[trade_idx]['Close']\n",
    "    \n",
    "    features = {'entry_price': trade_price}\n",
    "    \n",
    "    # Backward returns (what happened before)\n",
    "    periods_back = [5, 20, 60, 120, 252]  # ~1W, 1M, 3M, 6M, 1Y\n",
    "    for period in periods_back:\n",
    "        if trade_idx >= period:\n",
    "            past_price = data.iloc[trade_idx - period]['Close']\n",
    "            ret = (trade_price - past_price) / past_price\n",
    "            features[f'return_{period}d_back'] = ret\n",
    "    \n",
    "    # Forward returns (what happened after) - THIS IS YOUR TARGET\n",
    "    periods_fwd = [5, 20, 60, 120]\n",
    "    for period in periods_fwd:\n",
    "        if trade_idx + period < len(data):\n",
    "            future_price = data.iloc[trade_idx + period]['Close']\n",
    "            ret = (future_price - trade_price) / trade_price\n",
    "            features[f'return_{period}d_fwd'] = ret\n",
    "            \n",
    "            # Also track max gain/loss in that window\n",
    "            window = data.iloc[trade_idx:trade_idx + period + 1]\n",
    "            max_price = window['High'].max()\n",
    "            min_price = window['Low'].min()\n",
    "            \n",
    "            features[f'max_gain_{period}d'] = (max_price - trade_price) / trade_price\n",
    "            features[f'max_loss_{period}d'] = (min_price - trade_price) / trade_price\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Test\n",
    "test_ret = get_returns('AAPL', datetime(2024, 1, 15), price_data)\n",
    "print(\"Sample return features:\")\n",
    "for k, v in list(test_ret.items())[:5]:\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B. Volatility and Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volatility_metrics(ticker, trade_date, price_data):\n",
    "    \"\"\"\n",
    "    Volatility and risk measures\n",
    "    \"\"\"\n",
    "    if ticker not in price_data:\n",
    "        return {}\n",
    "    \n",
    "    data = price_data[ticker]\n",
    "    dates = data.index\n",
    "    trade_idx = dates.searchsorted(trade_date)\n",
    "    \n",
    "    if trade_idx == 0 or trade_idx >= len(dates):\n",
    "        return {}\n",
    "    \n",
    "    # Get lookback window\n",
    "    lookback = 60  # 3 months\n",
    "    if trade_idx < lookback:\n",
    "        return {}\n",
    "    \n",
    "    window = data.iloc[trade_idx - lookback:trade_idx]\n",
    "    returns = window['Close'].pct_change().dropna()\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Historical volatility (annualized)\n",
    "    features['volatility_60d'] = returns.std() * np.sqrt(252)\n",
    "    \n",
    "    # Max drawdown\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    features['max_drawdown_60d'] = drawdown.min()\n",
    "    \n",
    "    # Downside deviation (only negative returns)\n",
    "    negative_returns = returns[returns < 0]\n",
    "    if len(negative_returns) > 0:\n",
    "        features['downside_dev_60d'] = negative_returns.std() * np.sqrt(252)\n",
    "    else:\n",
    "        features['downside_dev_60d'] = 0\n",
    "    \n",
    "    # VaR (Value at Risk - 5th percentile)\n",
    "    features['var_95_60d'] = returns.quantile(0.05)\n",
    "    \n",
    "    # Percent of down days\n",
    "    features['pct_down_days_60d'] = (returns < 0).sum() / len(returns)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Test\n",
    "test_vol = get_volatility_metrics('AAPL', datetime(2024, 1, 15), price_data)\n",
    "print(\"\\nSample volatility features:\")\n",
    "for k, v in test_vol.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3C. Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_technical_indicators(ticker, trade_date, price_data):\n",
    "    \"\"\"\n",
    "    RSI, MACD, moving averages, etc.\n",
    "    \"\"\"\n",
    "    if ticker not in price_data:\n",
    "        return {}\n",
    "    \n",
    "    data = price_data[ticker].copy()\n",
    "    dates = data.index\n",
    "    trade_idx = dates.searchsorted(trade_date)\n",
    "    \n",
    "    if trade_idx == 0 or trade_idx >= len(dates):\n",
    "        return {}\n",
    "    \n",
    "    # Need enough history for 200-day MA\n",
    "    if trade_idx < 200:\n",
    "        return {}\n",
    "    \n",
    "    # Get window up to trade date\n",
    "    hist_data = data.iloc[:trade_idx + 1]\n",
    "    \n",
    "    # Moving averages\n",
    "    hist_data['sma_20'] = hist_data['Close'].rolling(20).mean()\n",
    "    hist_data['sma_50'] = hist_data['Close'].rolling(50).mean()\n",
    "    hist_data['sma_200'] = hist_data['Close'].rolling(200).mean()\n",
    "    \n",
    "    # RSI\n",
    "    hist_data['rsi'] = ta.momentum.RSIIndicator(hist_data['Close'], window=14).rsi()\n",
    "    \n",
    "    # MACD\n",
    "    macd = ta.trend.MACD(hist_data['Close'])\n",
    "    hist_data['macd'] = macd.macd()\n",
    "    hist_data['macd_signal'] = macd.macd_signal()\n",
    "    hist_data['macd_diff'] = macd.macd_diff()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    bb = ta.volatility.BollingerBands(hist_data['Close'])\n",
    "    hist_data['bb_upper'] = bb.bollinger_hband()\n",
    "    hist_data['bb_lower'] = bb.bollinger_lband()\n",
    "    hist_data['bb_middle'] = bb.bollinger_mavg()\n",
    "    \n",
    "    # Get values at trade date (last row)\n",
    "    trade_row = hist_data.iloc[-1]\n",
    "    \n",
    "    features = {\n",
    "        # Moving averages\n",
    "        'sma_20': trade_row['sma_20'],\n",
    "        'sma_50': trade_row['sma_50'],\n",
    "        'sma_200': trade_row['sma_200'],\n",
    "        \n",
    "        # Price vs MAs (>1 = above MA)\n",
    "        'price_vs_sma20': trade_row['Close'] / trade_row['sma_20'] if trade_row['sma_20'] > 0 else np.nan,\n",
    "        'price_vs_sma50': trade_row['Close'] / trade_row['sma_50'] if trade_row['sma_50'] > 0 else np.nan,\n",
    "        'price_vs_sma200': trade_row['Close'] / trade_row['sma_200'] if trade_row['sma_200'] > 0 else np.nan,\n",
    "        \n",
    "        # RSI (overbought >70, oversold <30)\n",
    "        'rsi': trade_row['rsi'],\n",
    "        'rsi_overbought': 1 if trade_row['rsi'] > 70 else 0,\n",
    "        'rsi_oversold': 1 if trade_row['rsi'] < 30 else 0,\n",
    "        \n",
    "        # MACD\n",
    "        'macd': trade_row['macd'],\n",
    "        'macd_signal': trade_row['macd_signal'],\n",
    "        'macd_diff': trade_row['macd_diff'],\n",
    "        'macd_bullish': 1 if trade_row['macd_diff'] > 0 else 0,\n",
    "        \n",
    "        # Bollinger position (0=lower band, 1=upper band)\n",
    "        'bb_position': (trade_row['Close'] - trade_row['bb_lower']) / (trade_row['bb_upper'] - trade_row['bb_lower']) if (trade_row['bb_upper'] - trade_row['bb_lower']) > 0 else 0.5,\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Test\n",
    "test_tech = get_technical_indicators('AAPL', datetime(2024, 1, 15), price_data)\n",
    "print(\"\\nSample technical indicators:\")\n",
    "for k, v in list(test_tech.items())[:5]:\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D. Fundamentals (from yfinance .info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fundamentals(ticker):\n",
    "    \"\"\"\n",
    "    Get fundamental data - note: this is CURRENT, not historical\n",
    "    For proper backtest, you'd need point-in-time data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "        \n",
    "        features = {\n",
    "            # Valuation\n",
    "            'pe_ratio': info.get('trailingPE', np.nan),\n",
    "            'forward_pe': info.get('forwardPE', np.nan),\n",
    "            'pb_ratio': info.get('priceToBook', np.nan),\n",
    "            'ps_ratio': info.get('priceToSalesTrailing12Months', np.nan),\n",
    "            'peg_ratio': info.get('pegRatio', np.nan),\n",
    "            \n",
    "            # Size\n",
    "            'market_cap': info.get('marketCap', np.nan),\n",
    "            \n",
    "            # Profitability\n",
    "            'roe': info.get('returnOnEquity', np.nan),\n",
    "            'roa': info.get('returnOnAssets', np.nan),\n",
    "            'profit_margin': info.get('profitMargins', np.nan),\n",
    "            'operating_margin': info.get('operatingMargins', np.nan),\n",
    "            \n",
    "            # Financial health\n",
    "            'debt_to_equity': info.get('debtToEquity', np.nan),\n",
    "            'current_ratio': info.get('currentRatio', np.nan),\n",
    "            \n",
    "            # Dividends\n",
    "            'dividend_yield': info.get('dividendYield', 0),\n",
    "            \n",
    "            # Growth\n",
    "            'revenue_growth': info.get('revenueGrowth', np.nan),\n",
    "            'earnings_growth': info.get('earningsGrowth', np.nan),\n",
    "            \n",
    "            # Risk\n",
    "            'beta': info.get('beta', np.nan),\n",
    "            \n",
    "            # Sector\n",
    "            'sector': info.get('sector', 'Unknown'),\n",
    "            'industry': info.get('industry', 'Unknown'),\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting fundamentals for {ticker}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Test\n",
    "test_fund = get_fundamentals('AAPL')\n",
    "print(\"\\nSample fundamentals:\")\n",
    "for k, v in list(test_fund.items())[:5]:\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3E. Market Context (SPY, VIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_context(trade_date, price_data):\n",
    "    \"\"\"\n",
    "    What was the overall market doing?\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # S&P 500 (using SPY as proxy)\n",
    "    if 'SPY' in price_data:\n",
    "        spy = price_data['SPY']\n",
    "        dates = spy.index\n",
    "        trade_idx = dates.searchsorted(trade_date)\n",
    "        \n",
    "        if trade_idx > 0 and trade_idx < len(spy):\n",
    "            spy_price = spy.iloc[trade_idx]['Close']\n",
    "            \n",
    "            # Calculate SPY 200-day MA\n",
    "            if trade_idx >= 200:\n",
    "                spy_sma200 = spy.iloc[trade_idx - 200:trade_idx + 1]['Close'].mean()\n",
    "                features['spy_vs_sma200'] = spy_price / spy_sma200\n",
    "                features['market_bull'] = 1 if spy_price > spy_sma200 else 0\n",
    "            \n",
    "            # SPY returns\n",
    "            if trade_idx >= 20:\n",
    "                spy_20d_ago = spy.iloc[trade_idx - 20]['Close']\n",
    "                features['spy_return_20d'] = (spy_price - spy_20d_ago) / spy_20d_ago\n",
    "            \n",
    "            if trade_idx >= 60:\n",
    "                spy_60d_ago = spy.iloc[trade_idx - 60]['Close']\n",
    "                features['spy_return_60d'] = (spy_price - spy_60d_ago) / spy_60d_ago\n",
    "    \n",
    "    # VIX (fear index)\n",
    "    if '^VIX' in price_data:\n",
    "        vix = price_data['^VIX']\n",
    "        dates = vix.index\n",
    "        trade_idx = dates.searchsorted(trade_date)\n",
    "        \n",
    "        if trade_idx > 0 and trade_idx < len(vix):\n",
    "            vix_level = vix.iloc[trade_idx]['Close']\n",
    "            features['vix_level'] = vix_level\n",
    "            features['vix_high'] = 1 if vix_level > 20 else 0\n",
    "            features['vix_extreme'] = 1 if vix_level > 30 else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Need to download SPY and VIX first\n",
    "print(\"Downloading market indices...\")\n",
    "if 'SPY' not in price_data:\n",
    "    min_date = df['date'].min() - timedelta(days=365)\n",
    "    max_date = df['date'].max() + timedelta(days=30)\n",
    "    price_data['SPY'] = yf.download('SPY', start=min_date, end=max_date, progress=False)\n",
    "    price_data['^VIX'] = yf.download('^VIX', start=min_date, end=max_date, progress=False)\n",
    "\n",
    "# Test\n",
    "test_mkt = get_market_context(datetime(2024, 1, 15), price_data)\n",
    "print(\"\\nSample market context:\")\n",
    "for k, v in test_mkt.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3F. Relative Performance (vs Market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_performance(ticker, trade_date, price_data):\n",
    "    \"\"\"\n",
    "    How is this stock doing vs the market?\n",
    "    \"\"\"\n",
    "    if ticker not in price_data or 'SPY' not in price_data:\n",
    "        return {}\n",
    "    \n",
    "    stock_data = price_data[ticker]\n",
    "    spy_data = price_data['SPY']\n",
    "    \n",
    "    # Get aligned data up to trade date\n",
    "    stock_dates = stock_data.index\n",
    "    trade_idx = stock_dates.searchsorted(trade_date)\n",
    "    \n",
    "    if trade_idx < 60 or trade_idx >= len(stock_data):\n",
    "        return {}\n",
    "    \n",
    "    # 60-day window\n",
    "    stock_window = stock_data.iloc[trade_idx - 60:trade_idx + 1]['Close']\n",
    "    \n",
    "    # Get SPY for same dates\n",
    "    spy_aligned = spy_data.reindex(stock_window.index, method='ffill')\n",
    "    \n",
    "    if len(spy_aligned) == 0:\n",
    "        return {}\n",
    "    \n",
    "    # Calculate returns\n",
    "    stock_ret = (stock_window.iloc[-1] - stock_window.iloc[0]) / stock_window.iloc[0]\n",
    "    spy_ret = (spy_aligned['Close'].iloc[-1] - spy_aligned['Close'].iloc[0]) / spy_aligned['Close'].iloc[0]\n",
    "    \n",
    "    # Beta (simplified - just correlation * (stock_vol / spy_vol))\n",
    "    stock_returns = stock_window.pct_change().dropna()\n",
    "    spy_returns = spy_aligned['Close'].pct_change().dropna()\n",
    "    \n",
    "    # Align\n",
    "    combined = pd.DataFrame({\n",
    "        'stock': stock_returns,\n",
    "        'spy': spy_returns\n",
    "    }).dropna()\n",
    "    \n",
    "    if len(combined) > 10:\n",
    "        covariance = combined['stock'].cov(combined['spy'])\n",
    "        spy_var = combined['spy'].var()\n",
    "        beta = covariance / spy_var if spy_var > 0 else 1\n",
    "    else:\n",
    "        beta = np.nan\n",
    "    \n",
    "    features = {\n",
    "        'stock_return_60d': stock_ret,\n",
    "        'spy_return_60d_aligned': spy_ret,\n",
    "        'relative_strength_60d': stock_ret - spy_ret,\n",
    "        'outperforming': 1 if stock_ret > spy_ret else 0,\n",
    "        'beta_60d': beta,\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Test\n",
    "test_rel = get_relative_performance('AAPL', datetime(2024, 1, 15), price_data)\n",
    "print(\"\\nSample relative performance:\")\n",
    "for k, v in test_rel.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3G. Corporate Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corporate_events(ticker, trade_date):\n",
    "    \"\"\"\n",
    "    Proximity to earnings, dividends, etc.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        \n",
    "        features = {\n",
    "            'has_earnings_date': 0,\n",
    "            'days_to_earnings': np.nan,\n",
    "            'near_earnings_30d': 0,\n",
    "        }\n",
    "        \n",
    "        # Try to get earnings calendar\n",
    "        try:\n",
    "            calendar = stock.calendar\n",
    "            if calendar is not None and 'Earnings Date' in calendar:\n",
    "                earnings_date = calendar['Earnings Date']\n",
    "                if isinstance(earnings_date, pd.Timestamp):\n",
    "                    days_diff = (earnings_date - trade_date).days\n",
    "                    features['has_earnings_date'] = 1\n",
    "                    features['days_to_earnings'] = days_diff\n",
    "                    features['near_earnings_30d'] = 1 if abs(days_diff) <= 30 else 0\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Dividends\n",
    "        try:\n",
    "            dividends = stock.dividends\n",
    "            if dividends is not None and len(dividends) > 0:\n",
    "                # Find most recent dividend before trade\n",
    "                past_divs = dividends[dividends.index <= trade_date]\n",
    "                if len(past_divs) > 0:\n",
    "                    last_div_date = past_divs.index[-1]\n",
    "                    days_since = (trade_date - last_div_date).days\n",
    "                    features['days_since_dividend'] = days_since\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "# Test\n",
    "test_events = get_corporate_events('AAPL', datetime(2024, 1, 15))\n",
    "print(\"\\nSample corporate events:\")\n",
    "for k, v in test_events.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3H. Entry Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entry_quality(ticker, trade_date, price_data):\n",
    "    \"\"\"\n",
    "    Did they buy at the bottom or top of recent range?\n",
    "    \"\"\"\n",
    "    if ticker not in price_data:\n",
    "        return {}\n",
    "    \n",
    "    data = price_data[ticker]\n",
    "    dates = data.index\n",
    "    trade_idx = dates.searchsorted(trade_date)\n",
    "    \n",
    "    if trade_idx < 120 or trade_idx >= len(data):\n",
    "        return {}\n",
    "    \n",
    "    trade_price = data.iloc[trade_idx]['Close']\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # 6-month (120 trading days) range\n",
    "    window = data.iloc[trade_idx - 120:trade_idx + 1]\n",
    "    price_max = window['High'].max()\n",
    "    price_min = window['Low'].min()\n",
    "    \n",
    "    # Where in the range? (0 = bottom, 100 = top)\n",
    "    if price_max > price_min:\n",
    "        percentile = ((trade_price - price_min) / (price_max - price_min)) * 100\n",
    "        features['price_percentile_120d'] = percentile\n",
    "        features['bought_near_bottom'] = 1 if percentile < 20 else 0\n",
    "        features['bought_near_top'] = 1 if percentile > 80 else 0\n",
    "    \n",
    "    # Volume percentile\n",
    "    trade_volume = data.iloc[trade_idx]['Volume']\n",
    "    avg_volume = window['Volume'].mean()\n",
    "    features['volume_ratio'] = trade_volume / avg_volume if avg_volume > 0 else 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Test\n",
    "test_entry = get_entry_quality('AAPL', datetime(2024, 1, 15), price_data)\n",
    "print(\"\\nSample entry quality:\")\n",
    "for k, v in test_entry.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Master Feature Extraction\n",
    "\n",
    "Combine all feature functions based on asset type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(row, price_data):\n",
    "    \"\"\"\n",
    "    Extract all relevant features for a single trade\n",
    "    \"\"\"\n",
    "    ticker = row['ticker']\n",
    "    trade_date = row['date']\n",
    "    asset_type = row['asset_type']\n",
    "    \n",
    "    # Start with the original row data\n",
    "    features = row.to_dict()\n",
    "    \n",
    "    # Market context (always include)\n",
    "    features.update(get_market_context(trade_date, price_data))\n",
    "    \n",
    "    # Asset-specific features\n",
    "    if asset_type == 'stock':\n",
    "        features.update(get_returns(ticker, trade_date, price_data))\n",
    "        features.update(get_volatility_metrics(ticker, trade_date, price_data))\n",
    "        features.update(get_technical_indicators(ticker, trade_date, price_data))\n",
    "        features.update(get_fundamentals(ticker))\n",
    "        features.update(get_relative_performance(ticker, trade_date, price_data))\n",
    "        features.update(get_corporate_events(ticker, trade_date))\n",
    "        features.update(get_entry_quality(ticker, trade_date, price_data))\n",
    "    \n",
    "    elif asset_type == 'treasury':\n",
    "        # For treasuries: returns, yields, duration\n",
    "        features.update(get_returns(ticker, trade_date, price_data))\n",
    "        features.update(get_volatility_metrics(ticker, trade_date, price_data))\n",
    "        # Add treasury-specific features here (yield curve, etc.)\n",
    "    \n",
    "    elif asset_type == 'etf':\n",
    "        # ETFs: subset of stock features\n",
    "        features.update(get_returns(ticker, trade_date, price_data))\n",
    "        features.update(get_volatility_metrics(ticker, trade_date, price_data))\n",
    "        features.update(get_technical_indicators(ticker, trade_date, price_data))\n",
    "        features.update(get_relative_performance(ticker, trade_date, price_data))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Process All Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Processing {len(df)} trades...\\n\")\n",
    "\n",
    "enriched_trades = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"[{idx + 1}/{len(df)}] {row['ticker']} ({row['asset_type']}) on {row['date'].date()}\")\n",
    "    \n",
    "    try:\n",
    "        features = extract_all_features(row, price_data)\n",
    "        enriched_trades.append(features)\n",
    "        print(f\"  ✓ Extracted {len(features)} features\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "        # Add original row with NaNs for features\n",
    "        enriched_trades.append(row.to_dict())\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_enriched = pd.DataFrame(enriched_trades)\n",
    "\n",
    "print(f\"\\n✓ Done! Final dataset: {df_enriched.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Inspect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape:\", df_enriched.shape)\n",
    "print(f\"\\nColumns: {len(df_enriched.columns)}\")\n",
    "print(\"\\nColumn list:\")\n",
    "print(df_enriched.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a sample row\n",
    "print(\"Sample trade (first stock):\")\n",
    "stock_trades = df_enriched[df_enriched['asset_type'] == 'stock']\n",
    "if len(stock_trades) > 0:\n",
    "    sample = stock_trades.iloc[0]\n",
    "    \n",
    "    # Show key features\n",
    "    key_features = [\n",
    "        'ticker', 'date', 'transaction_type', 'entry_price',\n",
    "        'return_20d_back', 'return_20d_fwd',\n",
    "        'pe_ratio', 'rsi', 'beta_60d',\n",
    "        'price_percentile_120d', 'near_earnings_30d'\n",
    "    ]\n",
    "    \n",
    "    for feat in key_features:\n",
    "        if feat in sample:\n",
    "            print(f\"  {feat}: {sample[feat]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing data\n",
    "print(\"\\nMissing data summary:\")\n",
    "missing_pct = (df_enriched.isnull().sum() / len(df_enriched) * 100).sort_values(ascending=False)\n",
    "print(missing_pct.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats for key numeric features\n",
    "numeric_cols = df_enriched.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\nNumeric features: {len(numeric_cols)}\")\n",
    "print(\"\\nSummary stats for returns:\")\n",
    "return_cols = [c for c in numeric_cols if 'return' in c]\n",
    "if len(return_cols) > 0:\n",
    "    print(df_enriched[return_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_file = 'enriched_trades_test.csv'\n",
    "df_enriched.to_csv(output_file, index=False)\n",
    "print(f\"✓ Saved to {output_file}\")\n",
    "\n",
    "# Also save by asset type\n",
    "for asset_type in df_enriched['asset_type'].unique():\n",
    "    subset = df_enriched[df_enriched['asset_type'] == asset_type]\n",
    "    filename = f'enriched_{asset_type}_trades_test.csv'\n",
    "    subset.to_csv(filename, index=False)\n",
    "    print(f\"✓ Saved {len(subset)} {asset_type} trades to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we built:**\n",
    "- Asset classification (stock/treasury/etf)\n",
    "- ~100-120 features per stock trade\n",
    "- Returns (backward/forward), volatility, technicals, fundamentals\n",
    "- Market context, relative performance, corporate events\n",
    "- Entry quality metrics\n",
    "\n",
    "**Next steps:**\n",
    "1. Review the output CSVs\n",
    "2. Check feature quality and missing data patterns\n",
    "3. Adjust feature functions if needed\n",
    "4. Scale up to full 100k trades\n",
    "5. Add treasury-specific features\n",
    "6. Calculate abnormal returns (CAPM, Fama-French)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
