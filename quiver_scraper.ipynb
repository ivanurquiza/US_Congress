{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiver Quant Election Contributions Scraper\n",
    "\n",
    "This notebook scrapes all political contribution data from QuiverQuant.\n",
    "\n",
    "**What it does:**\n",
    "- Gets the main table with all companies\n",
    "- Clicks into each company's detail page\n",
    "- Extracts all contribution data\n",
    "- Saves everything to an Excel file\n",
    "\n",
    "**Requirements:**\n",
    "```bash\n",
    "pip install selenium openpyxl pandas webdriver-manager\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Adjust these settings as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main settings\n",
    "BASE_URL = \"https://www.quiverquant.com/election-contributions/\"\n",
    "OUTPUT_FILE = r\"data/contributions.xlsx\"\n",
    "\n",
    "# Timing settings (in seconds)\n",
    "PAGE_TIMEOUT = 30      # Max time to wait for page load\n",
    "DELAY_BETWEEN = 1.5    # Delay between requests (be nice to the server)\n",
    "\n",
    "# Browser settings\n",
    "HEADLESS = True        # Set to False to see the browser window\n",
    "\n",
    "# Optional: limit number of companies (None = all)\n",
    "MAX_COMPANIES = None   # Change to 10 for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browser Setup\n",
    "\n",
    "Configure Chrome with anti-detection features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    \"\"\"\n",
    "    Sets up Chrome webdriver with stealth options to avoid detection\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    # Run headless (no visible window)\n",
    "    if HEADLESS:\n",
    "        options.add_argument('--headless=new')\n",
    "    \n",
    "    # Basic options for stability\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    options.add_argument('--window-size=1920,1080')\n",
    "    \n",
    "    # Mimic a real browser\n",
    "    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
    "    \n",
    "    # Hide automation flags\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    # Initialize driver (auto-downloads correct chromedriver)\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    # Remove webdriver property\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    return driver\n",
    "\n",
    "# Initialize the driver\n",
    "print(\"Setting up browser...\")\n",
    "driver = setup_driver()\n",
    "print(\"✓ Browser ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extract Main Table\n",
    "\n",
    "Get the list of all companies from the main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_table(driver):\n",
    "    \"\"\"\n",
    "    Scrapes the main table with all companies\n",
    "    Returns: list of dicts with company data\n",
    "    \"\"\"\n",
    "    print(\"\\nGetting main company list...\")\n",
    "    print(f\"URL: {BASE_URL}\")\n",
    "    \n",
    "    # Load the page\n",
    "    driver.get(BASE_URL)\n",
    "    wait = WebDriverWait(driver, PAGE_TIMEOUT)\n",
    "    time.sleep(3)  # Let the page fully load\n",
    "    \n",
    "    try:\n",
    "        # Find the main table\n",
    "        table = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"table\")))\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Get all rows\n",
    "        rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "        print(f\"Found {len(rows)} rows in main table\")\n",
    "        \n",
    "        companies_data = []\n",
    "        \n",
    "        # Skip header row (start at index 1)\n",
    "        for idx, row in enumerate(rows[1:], 1):\n",
    "            try:\n",
    "                # Get all cells in this row\n",
    "                cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(cols) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # First column has the company link\n",
    "                company_cell = cols[0]\n",
    "                link = company_cell.find_element(By.TAG_NAME, \"a\")\n",
    "                \n",
    "                company_name = link.text.strip()\n",
    "                company_url = link.get_attribute('href')\n",
    "                \n",
    "                if not company_name or not company_url:\n",
    "                    continue\n",
    "                \n",
    "                # Build row data\n",
    "                row_data = {\n",
    "                    'company_name': company_name,\n",
    "                    'company_url': company_url\n",
    "                }\n",
    "                \n",
    "                # Add other columns from the main table\n",
    "                for i, col in enumerate(cols[1:], 1):\n",
    "                    row_data[f'main_col_{i}'] = col.text.strip()\n",
    "                \n",
    "                companies_data.append(row_data)\n",
    "                print(f\"  [{len(companies_data)}] {company_name}\")\n",
    "                \n",
    "                # Stop if we hit the limit\n",
    "                if MAX_COMPANIES and len(companies_data) >= MAX_COMPANIES:\n",
    "                    print(f\"\\n⚠ Reached limit of {MAX_COMPANIES} companies\")\n",
    "                    break\n",
    "                \n",
    "            except StaleElementReferenceException:\n",
    "                # Element changed, skip it\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"  Error on row {idx}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\n✓ Extracted {len(companies_data)} companies\")\n",
    "        return companies_data\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(\"✗ Timeout loading main table\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Run it\n",
    "companies = extract_main_table(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Contributions for Each Company\n",
    "\n",
    "Click into each company page and get all their political contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_contributions(driver, company_url, company_name, index, total):\n",
    "    \"\"\"\n",
    "    Scrapes contribution data from a single company's detail page\n",
    "    Returns: list of dicts with contribution records\n",
    "    \"\"\"\n",
    "    print(f\"\\n[{index}/{total}] Processing: {company_name}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Navigate to company page\n",
    "        driver.get(company_url)\n",
    "        wait = WebDriverWait(driver, PAGE_TIMEOUT)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Find the contributions table\n",
    "        table = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table\")))\n",
    "        time.sleep(1)\n",
    "        \n",
    "        rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "        \n",
    "        if len(rows) == 0:\n",
    "            print(\"  ⚠ No rows found\")\n",
    "            return []\n",
    "        \n",
    "        # Extract headers from first row\n",
    "        headers = []\n",
    "        header_row = rows[0]\n",
    "        header_cells = header_row.find_elements(By.TAG_NAME, \"th\")\n",
    "        if not header_cells:\n",
    "            header_cells = header_row.find_elements(By.TAG_NAME, \"td\")\n",
    "        \n",
    "        for cell in header_cells:\n",
    "            header_text = cell.text.strip()\n",
    "            if header_text:\n",
    "                headers.append(header_text)\n",
    "            else:\n",
    "                headers.append(f\"Column_{len(headers)+1}\")\n",
    "        \n",
    "        # Extract data rows\n",
    "        contributions = []\n",
    "        \n",
    "        for row in rows[1:]:\n",
    "            try:\n",
    "                cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(cols) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Build record\n",
    "                row_data = {'Company': company_name}\n",
    "                \n",
    "                for i, col in enumerate(cols):\n",
    "                    header = headers[i] if i < len(headers) else f'Column_{i+1}'\n",
    "                    cell_text = col.text.strip()\n",
    "                    row_data[header] = cell_text\n",
    "                \n",
    "                contributions.append(row_data)\n",
    "            \n",
    "            except StaleElementReferenceException:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        print(f\"  ✓ Extracted {len(contributions)} contributions\")\n",
    "        return contributions\n",
    "    \n",
    "    except TimeoutException:\n",
    "        print(f\"  ✗ Timeout loading {company_name}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Process all companies\n",
    "if companies:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing {len(companies)} companies...\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    all_contributions = []\n",
    "    \n",
    "    for i, company in enumerate(companies, 1):\n",
    "        company_name = company['company_name']\n",
    "        company_url = company['company_url']\n",
    "        \n",
    "        # Scrape this company\n",
    "        contributions = extract_company_contributions(\n",
    "            driver, company_url, company_name, i, len(companies)\n",
    "        )\n",
    "        \n",
    "        # Add to master list\n",
    "        all_contributions.extend(contributions)\n",
    "        \n",
    "        # Be nice to the server\n",
    "        time.sleep(DELAY_BETWEEN)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"✓ Total contributions extracted: {len(all_contributions)}\")\n",
    "    print(f\"{'='*70}\")\n",
    "else:\n",
    "    print(\"\\n✗ No companies to process\")\n",
    "    all_contributions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Save to Excel\n",
    "\n",
    "Create a professional Excel file with 3 sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(companies_data, all_contributions, filename):\n",
    "    \"\"\"\n",
    "    Saves data to Excel with professional formatting\n",
    "    Creates 3 sheets: Companies, Contributions, Summary\n",
    "    \"\"\"\n",
    "    print(f\"\\nCreating Excel file: {filename}\")\n",
    "    \n",
    "    wb = Workbook()\n",
    "    \n",
    "    # --- SHEET 1: Company List ---\n",
    "    ws1 = wb.active\n",
    "    ws1.title = \"Companies\"\n",
    "    \n",
    "    if companies_data:\n",
    "        # Headers\n",
    "        headers = list(companies_data[0].keys())\n",
    "        ws1.append(headers)\n",
    "        \n",
    "        # Format header row\n",
    "        header_fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "        header_font = Font(bold=True, color=\"FFFFFF\", size=11)\n",
    "        header_alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        \n",
    "        for cell in ws1[1]:\n",
    "            cell.fill = header_fill\n",
    "            cell.font = header_font\n",
    "            cell.alignment = header_alignment\n",
    "        \n",
    "        # Add data rows\n",
    "        for company in companies_data:\n",
    "            row = [company.get(h, '') for h in headers]\n",
    "            ws1.append(row)\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        for column in ws1.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if cell.value and len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 3, 60)\n",
    "            ws1.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "    # --- SHEET 2: All Contributions ---\n",
    "    ws2 = wb.create_sheet(\"Contributions\")\n",
    "    \n",
    "    if all_contributions:\n",
    "        # Headers\n",
    "        headers = list(all_contributions[0].keys())\n",
    "        ws2.append(headers)\n",
    "        \n",
    "        # Format header row\n",
    "        for cell in ws2[1]:\n",
    "            cell.fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "            cell.font = Font(bold=True, color=\"FFFFFF\", size=11)\n",
    "            cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "        \n",
    "        # Add data rows\n",
    "        for contribution in all_contributions:\n",
    "            row = [contribution.get(h, '') for h in headers]\n",
    "            ws2.append(row)\n",
    "        \n",
    "        # Auto-adjust column widths\n",
    "        for column in ws2.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if cell.value and len(str(cell.value)) > max_length:\n",
    "                        max_length = len(str(cell.value))\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 3, 60)\n",
    "            ws2.column_dimensions[column_letter].width = adjusted_width\n",
    "    \n",
    "    # --- SHEET 3: Summary ---\n",
    "    ws3 = wb.create_sheet(\"Summary\")\n",
    "    ws3.append(['DATA SUMMARY'])\n",
    "    ws3.append([''])\n",
    "    ws3.append(['Metric', 'Value'])\n",
    "    ws3.append(['Total Companies', len(companies_data)])\n",
    "    ws3.append(['Total Contributions', len(all_contributions)])\n",
    "    ws3.append(['Extraction Date', datetime.now().strftime('%Y-%m-%d %H:%M:%S')])\n",
    "    \n",
    "    ws3['A1'].font = Font(bold=True, size=14)\n",
    "    for row in ws3.iter_rows(min_row=3, max_row=3):\n",
    "        for cell in row:\n",
    "            cell.fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n",
    "            cell.font = Font(bold=True, color=\"FFFFFF\")\n",
    "    \n",
    "    ws3.column_dimensions['A'].width = 30\n",
    "    ws3.column_dimensions['B'].width = 40\n",
    "    \n",
    "    # Save file\n",
    "    wb.save(filename)\n",
    "    print(f\"✓ File saved successfully\")\n",
    "    print(f\"  - Sheet 1: {len(companies_data)} companies\")\n",
    "    print(f\"  - Sheet 2: {len(all_contributions)} contributions\")\n",
    "    print(f\"  - Sheet 3: Summary stats\")\n",
    "\n",
    "# Save the data\n",
    "if companies and all_contributions:\n",
    "    save_to_excel(companies, all_contributions, OUTPUT_FILE)\n",
    "else:\n",
    "    print(\"\\n⚠ No data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Close the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close browser\n",
    "driver.quit()\n",
    "print(\"\\n✓ Browser closed\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCRAPING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Companies processed: {len(companies)}\")\n",
    "print(f\"Contributions extracted: {len(all_contributions)}\")\n",
    "print(f\"Output file: {OUTPUT_FILE}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Quick Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview companies data\n",
    "if companies:\n",
    "    print(\"First 5 companies:\")\n",
    "    df_companies = pd.DataFrame(companies)\n",
    "    display(df_companies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview contributions data\n",
    "if all_contributions:\n",
    "    print(\"First 10 contributions:\")\n",
    "    df_contributions = pd.DataFrame(all_contributions)\n",
    "    display(df_contributions.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic stats\n",
    "if all_contributions:\n",
    "    df_contributions = pd.DataFrame(all_contributions)\n",
    "    print(\"\\nContributions per company:\")\n",
    "    print(df_contributions['Company'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
