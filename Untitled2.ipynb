{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca77d6b-d57b-40db-a16a-eccbd5f8ef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CARGANDO DATOS...\n",
      "============================================================\n",
      "\n",
      "üìä TRADES cargados: 108,759 filas x 66 columnas\n",
      "üë§ LEGISLATORS cargados: 12,758 filas x 22 columnas\n",
      "\n",
      "============================================================\n",
      "EXPLORANDO COLUMNAS...\n",
      "============================================================\n",
      "\n",
      "üìã Columnas en TRADES:\n",
      "['BioGuideID', 'trade_id']\n",
      "\n",
      "üìã Columnas en LEGISLATORS:\n",
      "['bioguideid ']\n",
      "\n",
      "üîë Columna bioguide en TRADES: 'BioGuideID'\n",
      "üîë Columna bioguide en LEGISLATORS: 'bioguideid '\n",
      "\n",
      "============================================================\n",
      "LIMPIANDO BIOGUIDE IDs...\n",
      "============================================================\n",
      "\n",
      "üìù Ejemplos de bioguide_id en TRADES:\n",
      "['P000595', 'P000595', 'T000490', 'T000490', 'T000490', 'T000490', 'T000490', 'T000490', 'T000490', 'T000490']\n",
      "\n",
      "üìù Ejemplos de bioguide_id en LEGISLATORS:\n",
      "['C000127', 'K000367', 'S000033', 'NAN', 'B001261', 'W000437', 'C001035', 'C001056', 'D000563', 'G000359']\n",
      "\n",
      "üìä Bioguide IDs √∫nicos en TRADES: 331\n",
      "üìä Bioguide IDs √∫nicos en LEGISLATORS: 12427\n",
      "\n",
      "============================================================\n",
      "VERIFICANDO MATCHES...\n",
      "============================================================\n",
      "\n",
      "‚úÖ IDs que hacen match: 274\n",
      "‚ùå IDs en trades SIN match en legislators: 57\n",
      "\n",
      "‚ö†Ô∏è  Primeros 20 IDs sin match:\n",
      "['C001069', 'R000570', 'G000535', 'B001260', 'Y000063', 'I000024', 'C001046', 'R000589', 'B001294', 'K000375', 'M001193', 'M001163', 'N000182', 'A000373', 'H000636', 'W000779', 'S000583', 'M001187', 'F000451', 'L000554']\n",
      "\n",
      "üìâ Trades que se perder√°n (sin info de pol√≠tico): 9,150\n",
      "üìà Trades que se conservar√°n: 99,609\n",
      "\n",
      "============================================================\n",
      "REALIZANDO MERGE...\n",
      "============================================================\n",
      "\n",
      "üë§ Legislators √∫nicos para merge: 12427\n",
      "\n",
      "‚úÖ RESULTADO DEL MERGE:\n",
      "   - Trades originales: 108,759\n",
      "   - Trades despu√©s del merge (inner): 99,609\n",
      "   - Trades eliminados (sin info): 9,150\n",
      "\n",
      "============================================================\n",
      "CREANDO VARIABLES DUMMY...\n",
      "============================================================\n",
      "‚úÖ has_twitter creada: 79470 con Twitter\n",
      "‚úÖ has_facebook creada: 81127 con Facebook\n",
      "‚úÖ has_wikipedia creada: 99609 con Wikipedia\n",
      "‚úÖ is_male creada: 85913 hombres, 13696 mujeres\n",
      "‚úÖ chamber creada: House=89026, Senate=10583\n",
      "‚úÖ party_code creada:\n",
      "   1 (Democrat):    49787\n",
      "   2 (Republican):  49733\n",
      "   3 (Independent): 70\n",
      "‚úÖ Dummies de partido creadas: is_democrat, is_republican, is_independent\n",
      "üóëÔ∏è  Columnas eliminadas: ['twitter', 'facebook', 'youtube', 'wikipedia_id']\n",
      "\n",
      "üìã Nuevas variables creadas:\n",
      "   - has_twitter: {1: 79470, 0: 20139}\n",
      "   - has_facebook: {1: 81127, 0: 18482}\n",
      "   - has_wikipedia: {1: 99609}\n",
      "   - is_male: {1: 85913, 0: 13696}\n",
      "   - chamber: {1: 89026, 2: 10583}\n",
      "   - party_code: {1.0: 49787, 2.0: 49733, 3.0: 70}\n",
      "   - is_democrat: {0: 49822, 1: 49787}\n",
      "   - is_republican: {0: 49876, 1: 49733}\n",
      "   - is_independent: {0: 99539, 1: 70}\n",
      "\n",
      "============================================================\n",
      "VERIFICANDO RESULTADO...\n",
      "============================================================\n",
      "\n",
      "üìä Shape final: (99609, 89)\n",
      "\n",
      "üìã Columnas finales (89):\n",
      "['Ticker', 'TickerType', 'Company', 'Traded', 'Transaction', 'Trade_Size_USD', 'Status', 'Subholding', 'Description', 'Name', 'BioGuideID', 'Filed', 'Party', 'District', 'Chamber', 'Comments', 'Quiver_Upload_Time', 'excess_return', 'State', 'last_modified', 'Ticker_Clean', 'is_equity', 'trade_id', 'return_t', 'abs_return_t', 'return_overnight', 'return_intraday', 'momentum_5d', 'momentum_20d', 'momentum_60d', 'momentum_252d', 'realized_vol_30d', 'parkinson_vol_30d', 'realized_vol_60d', 'vol_of_vol_60d', 'realized_vol_252d', 'volume_t', 'dollar_volume_t', 'volume_ratio_30d', 'abnormal_volume_30d', 'amihud_illiq_20d', 'roll_spread_30d', 'hl_spread_20d', 'zero_volume_days_30d', 'beta_252d', 'r2_market_252d', 'alpha_ff3_252d', 'beta_mkt_ff3_252d', 'beta_smb_ff3_252d', 'beta_hml_ff3_252d', 'r2_ff3_252d', 'market_cap', 'price', 'book_value', 'price_to_book', 'ev_to_ebitda', 'car_raw_30d', 'car_capm_30d', 'car_ff3_30d', 'error', 'car_raw_60d', 'car_capm_60d', 'car_ff3_60d', 'car_raw_90d', 'car_capm_90d', 'car_ff3_90d', 'bioguide_id_clean', 'full_name', 'birthday', 'gender', 'type', 'state', 'senate_class', 'party', \"Bachelor's\", 'Religion', 'Base salary', 'Net worth', 'Term ends', 'Years in position', 'has_twitter', 'has_facebook', 'has_wikipedia', 'is_male', 'chamber', 'party_code', 'is_democrat', 'is_republican', 'is_independent']\n",
      "\n",
      "üìù Primeras filas del dataset mergeado:\n",
      "  Ticker TickerType                                            Company  \\\n",
      "0    SWK      Stock                         Stanley Black & Decker Inc   \n",
      "1    WPC      Stock                              W. P. Carey Inc. REIT   \n",
      "2     PG         ST                           PROCTER & GAMBLE COMPANY   \n",
      "3    IBM         ST  INTERNATIONAL BUSINESS MACHINES CORPORATION CO...   \n",
      "4   LRCX         ST            LAM RESEARCH CORPORATION - COMMON STOCK   \n",
      "\n",
      "      Traded Transaction     Trade_Size_USD Status  \\\n",
      "0 2026-01-12    Purchase  $15,001 - $50,000    New   \n",
      "1 2026-01-12    Purchase  $15,001 - $50,000    New   \n",
      "2 2026-01-09    Purchase   $1,001 - $15,000    NEW   \n",
      "3 2026-01-08    Purchase   $1,001 - $15,000    NEW   \n",
      "4 2026-01-08        Sale  $15,001 - $50,000    NEW   \n",
      "\n",
      "                                          Subholding Description  \\\n",
      "0                                               None        None   \n",
      "1                                               None        None   \n",
      "2   DAVID TAYLOR TRUST > SARDINIA READY MIX 401(K...        None   \n",
      "3   DAVID TAYLOR TRUST > SCHWAB JOINT BROKERAGE #...        None   \n",
      "4   DAVID TAYLOR TRUST > SARDINIA READY MIX 401(K...        None   \n",
      "\n",
      "              Name  ... Years in position has_twitter has_facebook  \\\n",
      "0     Peters, Gary  ...              11.0           1            1   \n",
      "1     Peters, Gary  ...              11.0           1            1   \n",
      "2  David J. Taylor  ...               NaN           1            1   \n",
      "3  David J. Taylor  ...               NaN           1            1   \n",
      "4  David J. Taylor  ...               NaN           1            1   \n",
      "\n",
      "  has_wikipedia is_male chamber party_code  is_democrat is_republican  \\\n",
      "0             1       1       2        1.0            1             0   \n",
      "1             1       1       2        1.0            1             0   \n",
      "2             1       1       1        2.0            0             1   \n",
      "3             1       1       1        2.0            0             1   \n",
      "4             1       1       1        2.0            0             1   \n",
      "\n",
      "  is_independent  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "\n",
      "[5 rows x 89 columns]\n",
      "\n",
      "üìä Resumen de variables dummy:\n",
      "\n",
      "has_twitter:\n",
      "has_twitter\n",
      "1    79470\n",
      "0    20139\n",
      "Name: count, dtype: int64\n",
      "\n",
      "has_facebook:\n",
      "has_facebook\n",
      "1    81127\n",
      "0    18482\n",
      "Name: count, dtype: int64\n",
      "\n",
      "has_wikipedia:\n",
      "has_wikipedia\n",
      "1    99609\n",
      "Name: count, dtype: int64\n",
      "\n",
      "is_male:\n",
      "is_male\n",
      "1    85913\n",
      "0    13696\n",
      "Name: count, dtype: int64\n",
      "\n",
      "chamber:\n",
      "chamber\n",
      "1    89026\n",
      "2    10583\n",
      "Name: count, dtype: int64\n",
      "\n",
      "party_code:\n",
      "party_code\n",
      "1.0    49787\n",
      "2.0    49733\n",
      "3.0       70\n",
      "NaN       19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "GUARDANDO RESULTADO...\n",
      "============================================================\n",
      "\n",
      "üíæ Guardado en: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\congress_trades_merged.parquet\n",
      "üíæ Tambi√©n guardado en CSV: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\congress_trades_merged.csv\n",
      "\n",
      "============================================================\n",
      "RESUMEN FINAL\n",
      "============================================================\n",
      "\n",
      "üìä ESTAD√çSTICAS DEL MERGE:\n",
      "   - Trades originales:     108,759\n",
      "   - Legislators √∫nicos:    12,427\n",
      "   - Trades finales:        99,609\n",
      "   - Trades eliminados:     9,150 (8.4%)\n",
      "   \n",
      "üìã VARIABLES DUMMY CREADAS:\n",
      "   - has_twitter:     1 = tiene Twitter, 0 = no tiene\n",
      "   - has_facebook:    1 = tiene Facebook, 0 = no tiene  \n",
      "   - has_wikipedia:   1 = tiene Wikipedia, 0 = no tiene\n",
      "   - is_male:         1 = Hombre, 0 = Mujer\n",
      "   - chamber:         1 = House, 2 = Senate\n",
      "   - party_code:      1 = Democrat, 2 = Republican, 3 = Independent\n",
      "   - is_democrat:     1 = Democrat, 0 = otro\n",
      "   - is_republican:   1 = Republican, 0 = otro\n",
      "   - is_independent:  1 = Independent, 0 = otro\n",
      "   \n",
      "üíæ ARCHIVOS GENERADOS:\n",
      "   - C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\congress_trades_merged.parquet\n",
      "   - C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\congress_trades_merged.csv\n",
      "\n",
      "‚úÖ ¬°MERGE COMPLETADO!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script para mergear datos de trades del Congreso con informaci√≥n de legisladores\n",
    "Proyecto: Detecci√≥n de Insider Trading - Maestr√≠a en Econom√≠a UdeSA\n",
    "\n",
    "Autor: [Tu nombre]\n",
    "Fecha: Enero 2026\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURACI√ìN - AJUSTAR ESTAS RUTAS SEG√öN TU ESTRUCTURA\n",
    "# =============================================================================\n",
    "BASE_PATH = Path(r\"C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\")\n",
    "TRADES_PATH = BASE_PATH / \"outputs\" / \"congress_trading_features_FIXED.parquet\"\n",
    "LEGISLATORS_PATH = BASE_PATH / \"info basica politicos\" / \"legislators_complete.xlsx\"\n",
    "OUTPUT_PATH = BASE_PATH / \"outputs\" / \"congress_trades_merged.parquet\"\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CARGAR LOS DATOS\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"CARGANDO DATOS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cargar trades\n",
    "trades = pd.read_parquet(TRADES_PATH)\n",
    "print(f\"\\nüìä TRADES cargados: {trades.shape[0]:,} filas x {trades.shape[1]} columnas\")\n",
    "\n",
    "# Cargar legislators\n",
    "legislators = pd.read_excel(LEGISLATORS_PATH)\n",
    "print(f\"üë§ LEGISLATORS cargados: {legislators.shape[0]:,} filas x {legislators.shape[1]} columnas\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. EXPLORAR Y LIMPIAR COLUMNAS DE BIOGUIDE ID\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPLORANDO COLUMNAS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Mostrar columnas de cada dataset\n",
    "print(\"\\nüìã Columnas en TRADES:\")\n",
    "print([col for col in trades.columns if 'bioguide' in col.lower() or 'bio' in col.lower() or 'id' in col.lower()])\n",
    "\n",
    "print(\"\\nüìã Columnas en LEGISLATORS:\")\n",
    "print([col for col in legislators.columns if 'bioguide' in col.lower() or 'bio' in col.lower()])\n",
    "\n",
    "# Identificar la columna de bioguide en cada dataset\n",
    "# NOTA: Ajusta estos nombres si son diferentes en tus datos\n",
    "bioguide_col_trades = None\n",
    "bioguide_col_legislators = None\n",
    "\n",
    "# Buscar en trades\n",
    "for col in trades.columns:\n",
    "    if 'bioguide' in col.lower():\n",
    "        bioguide_col_trades = col\n",
    "        break\n",
    "\n",
    "# Buscar en legislators\n",
    "for col in legislators.columns:\n",
    "    if 'bioguide' in col.lower():\n",
    "        bioguide_col_legislators = col\n",
    "        break\n",
    "\n",
    "print(f\"\\nüîë Columna bioguide en TRADES: '{bioguide_col_trades}'\")\n",
    "print(f\"üîë Columna bioguide en LEGISLATORS: '{bioguide_col_legislators}'\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. LIMPIAR LAS COLUMNAS DE BIOGUIDE ID\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LIMPIANDO BIOGUIDE IDs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Limpiar espacios y estandarizar\n",
    "if bioguide_col_trades:\n",
    "    trades['bioguide_id_clean'] = trades[bioguide_col_trades].astype(str).str.strip().str.upper()\n",
    "    \n",
    "if bioguide_col_legislators:\n",
    "    legislators['bioguide_id_clean'] = legislators[bioguide_col_legislators].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(\"\\nüìù Ejemplos de bioguide_id en TRADES:\")\n",
    "print(trades['bioguide_id_clean'].head(10).tolist())\n",
    "\n",
    "print(\"\\nüìù Ejemplos de bioguide_id en LEGISLATORS:\")\n",
    "print(legislators['bioguide_id_clean'].head(10).tolist())\n",
    "\n",
    "# Verificar valores √∫nicos\n",
    "unique_trades = trades['bioguide_id_clean'].nunique()\n",
    "unique_legislators = legislators['bioguide_id_clean'].nunique()\n",
    "print(f\"\\nüìä Bioguide IDs √∫nicos en TRADES: {unique_trades}\")\n",
    "print(f\"üìä Bioguide IDs √∫nicos en LEGISLATORS: {unique_legislators}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. VERIFICAR MATCH ANTES DEL MERGE\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICANDO MATCHES...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "trades_ids = set(trades['bioguide_id_clean'].unique())\n",
    "legislators_ids = set(legislators['bioguide_id_clean'].unique())\n",
    "\n",
    "matches = trades_ids.intersection(legislators_ids)\n",
    "no_match_in_legislators = trades_ids - legislators_ids\n",
    "\n",
    "print(f\"\\n‚úÖ IDs que hacen match: {len(matches)}\")\n",
    "print(f\"‚ùå IDs en trades SIN match en legislators: {len(no_match_in_legislators)}\")\n",
    "\n",
    "if no_match_in_legislators:\n",
    "    print(\"\\n‚ö†Ô∏è  Primeros 20 IDs sin match:\")\n",
    "    print(list(no_match_in_legislators)[:20])\n",
    "\n",
    "# Contar trades que se perder√≠an\n",
    "trades_sin_match = trades[~trades['bioguide_id_clean'].isin(legislators_ids)]\n",
    "print(f\"\\nüìâ Trades que se perder√°n (sin info de pol√≠tico): {len(trades_sin_match):,}\")\n",
    "print(f\"üìà Trades que se conservar√°n: {len(trades) - len(trades_sin_match):,}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. REALIZAR EL MERGE\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REALIZANDO MERGE...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Seleccionar columnas relevantes de legislators (ajusta seg√∫n necesites)\n",
    "# Renombrar columnas con espacios o nombres problem√°ticos\n",
    "legislators_clean = legislators.rename(columns=lambda x: x.strip())\n",
    "\n",
    "# Columnas a mantener de legislators (ajusta esta lista)\n",
    "cols_to_keep = [\n",
    "    'bioguide_id_clean',  # clave de merge\n",
    "    'full_name',\n",
    "    'birthday',\n",
    "    'gender',\n",
    "    'type',  # sen o rep\n",
    "    'state',\n",
    "    'senate_class',\n",
    "    'party',\n",
    "    'twitter',\n",
    "    'facebook',\n",
    "    'youtube',\n",
    "    'wikipedia_id',\n",
    "    \"Bachelor's\",\n",
    "    'Religion',\n",
    "    'Base salary',\n",
    "    'Net worth',\n",
    "    'Term ends',\n",
    "    'Years in position'\n",
    "]\n",
    "\n",
    "# Filtrar solo columnas que existen\n",
    "cols_available = [col for col in cols_to_keep if col in legislators_clean.columns or col == 'bioguide_id_clean']\n",
    "legislators_subset = legislators_clean[cols_available].copy()\n",
    "\n",
    "# Eliminar duplicados en legislators (quedarse con el registro m√°s reciente si hay duplicados)\n",
    "legislators_subset = legislators_subset.drop_duplicates(subset=['bioguide_id_clean'], keep='last')\n",
    "print(f\"\\nüë§ Legislators √∫nicos para merge: {len(legislators_subset)}\")\n",
    "\n",
    "# MERGE: left join para ver qu√© se pierde, luego inner join para quedarnos solo con matches\n",
    "merged = trades.merge(\n",
    "    legislators_subset,\n",
    "    on='bioguide_id_clean',\n",
    "    how='inner',  # Solo quedarnos con los que tienen match\n",
    "    indicator=False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ RESULTADO DEL MERGE:\")\n",
    "print(f\"   - Trades originales: {len(trades):,}\")\n",
    "print(f\"   - Trades despu√©s del merge (inner): {len(merged):,}\")\n",
    "print(f\"   - Trades eliminados (sin info): {len(trades) - len(merged):,}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. CREAR VARIABLES DUMMY / INDICADORAS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREANDO VARIABLES DUMMY...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- HAS_TWITTER, HAS_FACEBOOK, HAS_WIKIPEDIA (1 si tiene, 0 si no) ---\n",
    "if 'twitter' in merged.columns:\n",
    "    merged['has_twitter'] = merged['twitter'].notna().astype(int)\n",
    "    print(f\"‚úÖ has_twitter creada: {merged['has_twitter'].sum()} con Twitter\")\n",
    "\n",
    "if 'facebook' in merged.columns:\n",
    "    merged['has_facebook'] = merged['facebook'].notna().astype(int)\n",
    "    print(f\"‚úÖ has_facebook creada: {merged['has_facebook'].sum()} con Facebook\")\n",
    "\n",
    "if 'wikipedia_id' in merged.columns:\n",
    "    merged['has_wikipedia'] = merged['wikipedia_id'].notna().astype(int)\n",
    "    print(f\"‚úÖ has_wikipedia creada: {merged['has_wikipedia'].sum()} con Wikipedia\")\n",
    "\n",
    "# --- GENDER: 1 = Hombre (M), 0 = Mujer (F) ---\n",
    "if 'gender' in merged.columns:\n",
    "    merged['is_male'] = (merged['gender'].str.upper() == 'M').astype(int)\n",
    "    print(f\"‚úÖ is_male creada: {merged['is_male'].sum()} hombres, {(merged['is_male']==0).sum()} mujeres\")\n",
    "\n",
    "# --- CHAMBER: 1 = House (rep), 2 = Senate (sen) ---\n",
    "if 'type' in merged.columns:\n",
    "    merged['chamber'] = merged['type'].str.lower().map({'rep': 1, 'house': 1, 'sen': 2, 'senate': 2})\n",
    "    print(f\"‚úÖ chamber creada: House={(merged['chamber']==1).sum()}, Senate={(merged['chamber']==2).sum()}\")\n",
    "\n",
    "# --- PARTY: 1 = Democrat, 2 = Republican, 3 = Independent ---\n",
    "if 'party' in merged.columns:\n",
    "    def map_party(p):\n",
    "        if pd.isna(p):\n",
    "            return np.nan\n",
    "        p_lower = str(p).lower()\n",
    "        if 'democrat' in p_lower or p_lower == 'd':\n",
    "            return 1\n",
    "        elif 'republican' in p_lower or p_lower == 'r':\n",
    "            return 2\n",
    "        elif 'independent' in p_lower or p_lower == 'i':\n",
    "            return 3\n",
    "        else:\n",
    "            return np.nan  # Otros casos\n",
    "    \n",
    "    merged['party_code'] = merged['party'].apply(map_party)\n",
    "    print(f\"‚úÖ party_code creada:\")\n",
    "    print(f\"   1 (Democrat):    {(merged['party_code']==1).sum()}\")\n",
    "    print(f\"   2 (Republican):  {(merged['party_code']==2).sum()}\")\n",
    "    print(f\"   3 (Independent): {(merged['party_code']==3).sum()}\")\n",
    "\n",
    "# --- Tambi√©n crear dummies separadas para cada partido (√∫til para regresiones) ---\n",
    "merged['is_democrat'] = (merged['party_code'] == 1).astype(int)\n",
    "merged['is_republican'] = (merged['party_code'] == 2).astype(int)\n",
    "merged['is_independent'] = (merged['party_code'] == 3).astype(int)\n",
    "print(f\"‚úÖ Dummies de partido creadas: is_democrat, is_republican, is_independent\")\n",
    "\n",
    "# --- Eliminar columnas originales de redes sociales (ya no necesarias) ---\n",
    "cols_to_drop = ['twitter', 'facebook', 'youtube', 'wikipedia_id']\n",
    "cols_existing_to_drop = [col for col in cols_to_drop if col in merged.columns]\n",
    "if cols_existing_to_drop:\n",
    "    merged = merged.drop(columns=cols_existing_to_drop)\n",
    "    print(f\"üóëÔ∏è  Columnas eliminadas: {cols_existing_to_drop}\")\n",
    "\n",
    "print(\"\\nüìã Nuevas variables creadas:\")\n",
    "new_vars = ['has_twitter', 'has_facebook', 'has_wikipedia', 'is_male', 'chamber', \n",
    "            'party_code', 'is_democrat', 'is_republican', 'is_independent']\n",
    "for var in new_vars:\n",
    "    if var in merged.columns:\n",
    "        print(f\"   - {var}: {merged[var].value_counts().to_dict()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. VERIFICAR RESULTADO\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICANDO RESULTADO...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Shape final: {merged.shape}\")\n",
    "print(f\"\\nüìã Columnas finales ({len(merged.columns)}):\")\n",
    "print(merged.columns.tolist())\n",
    "\n",
    "print(\"\\nüìù Primeras filas del dataset mergeado:\")\n",
    "print(merged.head())\n",
    "\n",
    "# Estad√≠sticas de las nuevas variables\n",
    "print(\"\\nüìä Resumen de variables dummy:\")\n",
    "dummy_vars = ['has_twitter', 'has_facebook', 'has_wikipedia', 'is_male', 'chamber', 'party_code']\n",
    "for var in dummy_vars:\n",
    "    if var in merged.columns:\n",
    "        print(f\"\\n{var}:\")\n",
    "        print(merged[var].value_counts(dropna=False))\n",
    "\n",
    "# =============================================================================\n",
    "# 8. GUARDAR RESULTADO\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GUARDANDO RESULTADO...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Guardar en parquet (eficiente)\n",
    "merged.to_parquet(OUTPUT_PATH, index=False)\n",
    "print(f\"\\nüíæ Guardado en: {OUTPUT_PATH}\")\n",
    "\n",
    "# Tambi√©n guardar en CSV para inspecci√≥n f√°cil\n",
    "csv_path = OUTPUT_PATH.with_suffix('.csv')\n",
    "merged.to_csv(csv_path, index=False)\n",
    "print(f\"üíæ Tambi√©n guardado en CSV: {csv_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. RESUMEN FINAL\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN FINAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "new_vars_list = ['has_twitter', 'has_facebook', 'has_wikipedia', 'is_male', \n",
    "                 'chamber', 'party_code', 'is_democrat', 'is_republican', 'is_independent']\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä ESTAD√çSTICAS DEL MERGE:\n",
    "   - Trades originales:     {len(trades):,}\n",
    "   - Legislators √∫nicos:    {len(legislators_subset):,}\n",
    "   - Trades finales:        {len(merged):,}\n",
    "   - Trades eliminados:     {len(trades) - len(merged):,} ({100*(len(trades)-len(merged))/len(trades):.1f}%)\n",
    "   \n",
    "üìã VARIABLES DUMMY CREADAS:\n",
    "   - has_twitter:     1 = tiene Twitter, 0 = no tiene\n",
    "   - has_facebook:    1 = tiene Facebook, 0 = no tiene  \n",
    "   - has_wikipedia:   1 = tiene Wikipedia, 0 = no tiene\n",
    "   - is_male:         1 = Hombre, 0 = Mujer\n",
    "   - chamber:         1 = House, 2 = Senate\n",
    "   - party_code:      1 = Democrat, 2 = Republican, 3 = Independent\n",
    "   - is_democrat:     1 = Democrat, 0 = otro\n",
    "   - is_republican:   1 = Republican, 0 = otro\n",
    "   - is_independent:  1 = Independent, 0 = otro\n",
    "   \n",
    "üíæ ARCHIVOS GENERADOS:\n",
    "   - {OUTPUT_PATH}\n",
    "   - {csv_path}\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ ¬°MERGE COMPLETADO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f903cc-d362-4442-8b65-bacf17d38ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CARGANDO LEGISLATORS Y CREANDO √çNDICES DE MATCHING...\n",
      "============================================================\n",
      "Legislators cargados: 12758\n",
      "Diccionarios creados:\n",
      "  - Full name + state: 862 entradas\n",
      "  - No middle + state: 862 entradas\n",
      "  - Last name + state: 850 entradas\n",
      "  - Name key: 862 entradas\n",
      "  - Name only (√∫nicos): 802 entradas\n",
      "  - Name no middle only (√∫nicos): 802 entradas\n",
      "\n",
      "============================================================\n",
      "PROCESANDO ARCHIVOS DE COMIT√âS...\n",
      "============================================================\n",
      "\n",
      "üìÅ Procesando: house\n",
      "   Filas: 3360\n",
      "   ‚úÖ Matched: 1437 (42.8%)\n",
      "   ‚ùå Sin match: 1923\n",
      "   M√©todos de match:\n",
      "match_method\n",
      "no_match           1923\n",
      "full_name+state     927\n",
      "no_middle+state     305\n",
      "last+state          167\n",
      "name_key             35\n",
      "full_name_only        2\n",
      "no_middle_only        1\n",
      "\n",
      "   ‚ö†Ô∏è Ejemplos sin match:\n",
      "          full_name state     party\n",
      "16  Nydia Vel√°zquez    NY  Democrat\n",
      "37  Nydia Vel√°zquez    NY  Democrat\n",
      "43    Ed Perlmutter    CO  Democrat\n",
      "61      Chuy Garc√≠a    IL  Democrat\n",
      "92  Nydia Vel√°zquez    NY  Democrat\n",
      "\n",
      "üìÅ Procesando: house_119\n",
      "   Filas: 260\n",
      "   ‚úÖ Matched: 221 (85.0%)\n",
      "   ‚ùå Sin match: 39\n",
      "   M√©todos de match:\n",
      "match_method\n",
      "full_name+state    84\n",
      "full_name_only     79\n",
      "no_match           39\n",
      "no_middle_only     23\n",
      "no_middle+state    20\n",
      "last+state          9\n",
      "name_key            6\n",
      "\n",
      "   ‚ö†Ô∏è Ejemplos sin match:\n",
      "       full_name        state     party\n",
      "3      Don Davis          NaN  Democrat\n",
      "11     Jim Costa          NaN  Democrat\n",
      "15  Rosa DeLauro  Connecticut  Democrat\n",
      "23  Marcy Kaptur         Ohio  Democrat\n",
      "25   Steny Hoyer     Maryland  Democrat\n",
      "\n",
      "üìÅ Procesando: senate\n",
      "   Filas: 1932\n",
      "   ‚úÖ Matched: 196 (10.1%)\n",
      "   ‚ùå Sin match: 1736\n",
      "   M√©todos de match:\n",
      "match_method\n",
      "no_match          1736\n",
      "full_name_only      90\n",
      "last+state          88\n",
      "no_middle_only      18\n",
      "\n",
      "   ‚ö†Ô∏è Ejemplos sin match:\n",
      "         full_name state       party\n",
      "2       John Smith    CO  Republican\n",
      "3  Michael Johnson    CT    Democrat\n",
      "4   David Williams    DE  Republican\n",
      "5     Robert Brown    FL    Democrat\n",
      "6      James Jones    GA  Republican\n",
      "\n",
      "üìÅ Procesando: senate_119\n",
      "   Filas: 170\n",
      "   ‚úÖ Matched: 162 (95.3%)\n",
      "   ‚ùå Sin match: 8\n",
      "   M√©todos de match:\n",
      "match_method\n",
      "full_name+state    121\n",
      "no_middle+state     21\n",
      "name_key            11\n",
      "no_match             8\n",
      "last+state           7\n",
      "full_name_only       2\n",
      "\n",
      "   ‚ö†Ô∏è Ejemplos sin match:\n",
      "             full_name         state     party\n",
      "5      Michael Bennett      Colorado  Democrat\n",
      "7        Ben Ray Luj√°n  Nuevo M√©xico  Democrat\n",
      "82       Ben Ray Luj√°n  Nuevo M√©xico  Democrat\n",
      "92           Ron Wyden        Oregon  Democrat\n",
      "94  Sheldon Whitehouse  Rhode Island  Democrat\n",
      "\n",
      "============================================================\n",
      "GUARDANDO RESULTADOS...\n",
      "============================================================\n",
      "\n",
      "Total registros combinados: 5722\n",
      "Con bioguide_id: 2016\n",
      "üíæ Guardado: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\committees_with_bioguide.csv\n",
      "üíæ Guardado: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\house_with_bioguide.csv\n",
      "üíæ Guardado: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\house_119_with_bioguide.csv\n",
      "üíæ Guardado: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\senate_with_bioguide.csv\n",
      "üíæ Guardado: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\senate_119_with_bioguide.csv\n",
      "\n",
      "============================================================\n",
      "REGISTROS SIN MATCH (para revisi√≥n manual)\n",
      "============================================================\n",
      "üíæ Lista de no matches guardada: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\committees_no_match.csv\n",
      "\n",
      "Top 20 sin match:\n",
      "      full_name state  count\n",
      "870  Senator 20    CA     12\n",
      "869   Senator 2    CA     12\n",
      "865  Senator 16    CA     12\n",
      "858   Senator 1    CA     12\n",
      "871   Senator 3    CA     12\n",
      "872   Senator 4    CA     12\n",
      "873   Senator 5    CA     12\n",
      "868  Senator 19    CA     12\n",
      "866  Senator 17    CA     12\n",
      "867  Senator 18    CA     12\n",
      "861  Senator 12    CA     12\n",
      "862  Senator 13    CA     12\n",
      "863  Senator 14    CA     12\n",
      "864  Senator 15    CA     12\n",
      "876   Senator 8    CA     12\n",
      "875   Senator 7    CA     12\n",
      "874   Senator 6    CA     12\n",
      "877   Senator 9    CA     12\n",
      "860  Senator 11    CA     12\n",
      "859  Senator 10    CA     12\n",
      "\n",
      "‚úÖ ¬°PROCESO COMPLETADO!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script para agregar bioguide_id a las bases de comit√©s del Congreso\n",
    "Matching por nombre + estado con m√∫ltiples estrategias\n",
    "\n",
    "Proyecto: Detecci√≥n de Insider Trading - Maestr√≠a en Econom√≠a UdeSA\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURACI√ìN\n",
    "# =============================================================================\n",
    "BASE_PATH = Path(r\"C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\")\n",
    "LEGISLATORS_PATH = BASE_PATH / \"info basica politicos\" / \"legislators_complete.xlsx\"\n",
    "\n",
    "# Archivos de comit√©s (ajustar rutas seg√∫n tu estructura)\n",
    "COMMITTEE_FILES = {\n",
    "    'house': BASE_PATH / \"info basica politicos\" / \"house_committee.csv\",\n",
    "    'house_119': BASE_PATH / \"info basica politicos\" / \"house_committee_119.csv\",\n",
    "    'senate': BASE_PATH / \"info basica politicos\" / \"senate_committee.csv\",\n",
    "    'senate_119': BASE_PATH / \"info basica politicos\" / \"senate_committee_119.csv\",\n",
    "}\n",
    "\n",
    "OUTPUT_PATH = BASE_PATH / \"outputs\"\n",
    "\n",
    "# =============================================================================\n",
    "# FUNCIONES DE NORMALIZACI√ìN DE NOMBRES\n",
    "# =============================================================================\n",
    "\n",
    "def remove_accents(text):\n",
    "    \"\"\"Remueve acentos y caracteres especiales\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Normalizar unicode y remover acentos\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')\n",
    "    return text\n",
    "\n",
    "def normalize_name(name):\n",
    "    \"\"\"Normaliza un nombre para matching\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).lower().strip()\n",
    "    # Remover acentos\n",
    "    name = remove_accents(name)\n",
    "    # Remover sufijos comunes\n",
    "    name = re.sub(r'\\s+(jr\\.?|sr\\.?|iii|ii|iv)$', '', name, flags=re.IGNORECASE)\n",
    "    # Remover puntuaci√≥n\n",
    "    name = re.sub(r'[.,]', '', name)\n",
    "    # Normalizar espacios\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "    return name.strip()\n",
    "\n",
    "def extract_first_name(full_name):\n",
    "    \"\"\"Extrae el primer nombre\"\"\"\n",
    "    if pd.isna(full_name):\n",
    "        return \"\"\n",
    "    parts = str(full_name).strip().split()\n",
    "    return parts[0].lower() if parts else \"\"\n",
    "\n",
    "def extract_last_name(full_name):\n",
    "    \"\"\"Extrae el apellido (√∫ltima palabra)\"\"\"\n",
    "    if pd.isna(full_name):\n",
    "        return \"\"\n",
    "    parts = str(full_name).strip().split()\n",
    "    # Remover sufijos\n",
    "    while parts and parts[-1].lower() in ['jr', 'jr.', 'sr', 'sr.', 'ii', 'iii', 'iv']:\n",
    "        parts.pop()\n",
    "    return parts[-1].lower() if parts else \"\"\n",
    "\n",
    "def remove_middle_initial(name):\n",
    "    \"\"\"Remueve iniciales del medio (ej: 'Roger F. Wicker' -> 'Roger Wicker')\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    # Patr√≥n para iniciales del medio (una letra seguida de punto opcional)\n",
    "    name = re.sub(r'\\s+[A-Z]\\.?\\s+', ' ', str(name))\n",
    "    return normalize_name(name)\n",
    "\n",
    "def create_name_key(first_name, last_name, state):\n",
    "    \"\"\"Crea una clave √∫nica basada en nombre y estado\"\"\"\n",
    "    first = normalize_name(first_name)[:3] if first_name else \"\"  # Primeras 3 letras\n",
    "    last = normalize_name(last_name)\n",
    "    st = str(state).upper().strip() if state else \"\"\n",
    "    return f\"{first}_{last}_{st}\"\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CARGAR LEGISLATORS Y CREAR DICCIONARIOS DE MATCHING\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"CARGANDO LEGISLATORS Y CREANDO √çNDICES DE MATCHING...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "legislators = pd.read_excel(LEGISLATORS_PATH)\n",
    "\n",
    "# Limpiar nombre de columna bioguide\n",
    "legislators.columns = legislators.columns.str.strip()\n",
    "bioguide_col = 'bioguideid'\n",
    "\n",
    "print(f\"Legislators cargados: {len(legislators)}\")\n",
    "\n",
    "# Crear columnas normalizadas\n",
    "legislators['full_name_norm'] = legislators['full_name'].apply(normalize_name)\n",
    "legislators['full_name_no_middle'] = legislators['full_name'].apply(remove_middle_initial)\n",
    "legislators['first_name_norm'] = legislators['full_name'].apply(extract_first_name)\n",
    "legislators['last_name_norm'] = legislators['full_name'].apply(extract_last_name)\n",
    "legislators['state_norm'] = legislators['state'].str.upper().str.strip()\n",
    "\n",
    "# Crear clave compuesta\n",
    "legislators['name_key'] = legislators.apply(\n",
    "    lambda x: create_name_key(x['first_name_norm'], x['last_name_norm'], x['state_norm']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Crear diccionarios de matching (varios niveles)\n",
    "# Nivel 1: full_name exacto + state\n",
    "match_dict_full = {}\n",
    "for _, row in legislators.iterrows():\n",
    "    if pd.notna(row[bioguide_col]):\n",
    "        key = f\"{row['full_name_norm']}_{row['state_norm']}\"\n",
    "        match_dict_full[key] = row[bioguide_col]\n",
    "\n",
    "# Nivel 2: full_name sin middle initial + state\n",
    "match_dict_no_middle = {}\n",
    "for _, row in legislators.iterrows():\n",
    "    if pd.notna(row[bioguide_col]):\n",
    "        key = f\"{row['full_name_no_middle']}_{row['state_norm']}\"\n",
    "        match_dict_no_middle[key] = row[bioguide_col]\n",
    "\n",
    "# Nivel 3: last_name + state (menos preciso, puede haber duplicados)\n",
    "match_dict_last_state = {}\n",
    "for _, row in legislators.iterrows():\n",
    "    if pd.notna(row[bioguide_col]):\n",
    "        key = f\"{row['last_name_norm']}_{row['state_norm']}\"\n",
    "        if key not in match_dict_last_state:  # Solo guardar el primero\n",
    "            match_dict_last_state[key] = row[bioguide_col]\n",
    "\n",
    "# Nivel 4: name_key (first 3 chars + last + state)\n",
    "match_dict_key = {}\n",
    "for _, row in legislators.iterrows():\n",
    "    if pd.notna(row[bioguide_col]):\n",
    "        match_dict_key[row['name_key']] = row[bioguide_col]\n",
    "\n",
    "# Nivel 5: Solo nombre (sin estado) - para cuando no hay estado\n",
    "# Solo guardar si el nombre es √∫nico\n",
    "match_dict_name_only = {}\n",
    "name_counts = legislators['full_name_norm'].value_counts()\n",
    "unique_names = name_counts[name_counts == 1].index\n",
    "for _, row in legislators.iterrows():\n",
    "    if pd.notna(row[bioguide_col]) and row['full_name_norm'] in unique_names:\n",
    "        match_dict_name_only[row['full_name_norm']] = row[bioguide_col]\n",
    "\n",
    "# Nivel 6: Nombre sin middle initial (sin estado)\n",
    "match_dict_name_no_middle_only = {}\n",
    "name_no_middle_counts = legislators['full_name_no_middle'].value_counts()\n",
    "unique_names_no_middle = name_no_middle_counts[name_no_middle_counts == 1].index\n",
    "for _, row in legislators.iterrows():\n",
    "    if pd.notna(row[bioguide_col]) and row['full_name_no_middle'] in unique_names_no_middle:\n",
    "        match_dict_name_no_middle_only[row['full_name_no_middle']] = row[bioguide_col]\n",
    "\n",
    "print(f\"Diccionarios creados:\")\n",
    "print(f\"  - Full name + state: {len(match_dict_full)} entradas\")\n",
    "print(f\"  - No middle + state: {len(match_dict_no_middle)} entradas\")\n",
    "print(f\"  - Last name + state: {len(match_dict_last_state)} entradas\")\n",
    "print(f\"  - Name key: {len(match_dict_key)} entradas\")\n",
    "print(f\"  - Name only (√∫nicos): {len(match_dict_name_only)} entradas\")\n",
    "print(f\"  - Name no middle only (√∫nicos): {len(match_dict_name_no_middle_only)} entradas\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. FUNCI√ìN PARA HACER MATCHING\n",
    "# =============================================================================\n",
    "\n",
    "def find_bioguide(row, state_col='state'):\n",
    "    \"\"\"Intenta encontrar bioguide_id usando m√∫ltiples estrategias\"\"\"\n",
    "    full_name = normalize_name(row.get('full_name', ''))\n",
    "    first_name = normalize_name(row.get('first_name', ''))\n",
    "    last_name = normalize_name(row.get('last_name', ''))\n",
    "    \n",
    "    # Normalizar estado (manejar nombres completos vs abreviaciones)\n",
    "    state_raw = row.get(state_col, '')\n",
    "    state = str(state_raw).strip().upper() if pd.notna(state_raw) else \"\"\n",
    "    \n",
    "    # Mapeo de nombres de estado a abreviaciones (ingl√©s y espa√±ol)\n",
    "    state_abbrev = {\n",
    "        # Ingl√©s\n",
    "        'ALABAMA': 'AL', 'ALASKA': 'AK', 'ARIZONA': 'AZ', 'ARKANSAS': 'AR',\n",
    "        'CALIFORNIA': 'CA', 'COLORADO': 'CO', 'CONNECTICUT': 'CT', 'DELAWARE': 'DE',\n",
    "        'FLORIDA': 'FL', 'GEORGIA': 'GA', 'HAWAII': 'HI', 'IDAHO': 'ID',\n",
    "        'ILLINOIS': 'IL', 'INDIANA': 'IN', 'IOWA': 'IA', 'KANSAS': 'KS',\n",
    "        'KENTUCKY': 'KY', 'LOUISIANA': 'LA', 'MAINE': 'ME', 'MARYLAND': 'MD',\n",
    "        'MASSACHUSETTS': 'MA', 'MICHIGAN': 'MI', 'MINNESOTA': 'MN', 'MISSISSIPPI': 'MS',\n",
    "        'MISSOURI': 'MO', 'MONTANA': 'MT', 'NEBRASKA': 'NE', 'NEVADA': 'NV',\n",
    "        'NEW HAMPSHIRE': 'NH', 'NEW JERSEY': 'NJ', 'NEW MEXICO': 'NM', 'NEW YORK': 'NY',\n",
    "        'NORTH CAROLINA': 'NC', 'NORTH DAKOTA': 'ND', 'OHIO': 'OH', 'OKLAHOMA': 'OK',\n",
    "        'OREGON': 'OR', 'PENNSYLVANIA': 'PA', 'RHODE ISLAND': 'RI', \n",
    "        'SOUTH CAROLINA': 'SC', 'SOUTH DAKOTA': 'SD', 'TENNESSEE': 'TN', \n",
    "        'TEXAS': 'TX', 'UTAH': 'UT', 'VERMONT': 'VT', 'VIRGINIA': 'VA', \n",
    "        'WASHINGTON': 'WA', 'WEST VIRGINIA': 'WV', 'WISCONSIN': 'WI', 'WYOMING': 'WY',\n",
    "        'DISTRICT OF COLUMBIA': 'DC', 'PUERTO RICO': 'PR', 'GUAM': 'GU',\n",
    "        'VIRGIN ISLANDS': 'VI', 'AMERICAN SAMOA': 'AS', 'NORTHERN MARIANA ISLANDS': 'MP',\n",
    "        # Espa√±ol\n",
    "        'PENSILVANIA': 'PA', 'NUEVA YORK': 'NY', 'NUEVA JERSEY': 'NJ',\n",
    "        'NUEVO MEXICO': 'NM', 'NUEVO M√âXICO': 'NM', 'CAROLINA DEL NORTE': 'NC',\n",
    "        'CAROLINA DEL SUR': 'SC', 'DAKOTA DEL NORTE': 'ND', 'DAKOTA DEL SUR': 'SD',\n",
    "        'VIRGINIA OCCIDENTAL': 'WV', 'VIRGINIA DEL OESTE': 'WV',\n",
    "        'LUISIANA': 'LA', 'FLORIDA': 'FL', 'GEORGIA': 'GA', 'TEJAS': 'TX',\n",
    "        'KENTUCKY': 'KY', 'TENNESSEE': 'TN', 'MISISIPI': 'MS', 'MISSISSIPPI': 'MS',\n",
    "        'ARKANSAS': 'AR', 'KANSAS': 'KS', 'NEBRASKA': 'NE', 'IOWA': 'IA',\n",
    "        'WISCONSIN': 'WI', 'MICHIGAN': 'MI', 'OHIO': 'OH', 'INDIANA': 'IN',\n",
    "        'ILLINOIS': 'IL', 'MINNESOTA': 'MN', 'MISSOURI': 'MO', 'ARIZONA': 'AZ',\n",
    "        'COLORADO': 'CO', 'UTAH': 'UT', 'NEVADA': 'NV', 'MONTANA': 'MT',\n",
    "        'IDAHO': 'ID', 'WYOMING': 'WY', 'OREGON': 'OR', 'WASHINGTON': 'WA',\n",
    "        'ALASKA': 'AK', 'HAWAI': 'HI', 'HAWAII': 'HI', 'MAINE': 'ME',\n",
    "        'VERMONT': 'VT', 'CONNECTICUT': 'CT', 'RHODE ISLAND': 'RI',\n",
    "        'MASSACHUSETTS': 'MA', 'MARYLAND': 'MD', 'DELAWARE': 'DE',\n",
    "        'DISTRITO DE COLUMBIA': 'DC', 'ISLA DE RHODE': 'RI',\n",
    "        # Typos comunes\n",
    "        'PENNSILVANIA': 'PA', 'CALIFORNI': 'CA', 'CALIFRONIA': 'CA',\n",
    "    }\n",
    "    \n",
    "    # Normalizar estado\n",
    "    state_normalized = state\n",
    "    if state in state_abbrev:\n",
    "        state_normalized = state_abbrev[state]\n",
    "    elif len(state) > 2:\n",
    "        # Remover acentos del estado\n",
    "        state_clean = remove_accents(state).upper()\n",
    "        if state_clean in state_abbrev:\n",
    "            state_normalized = state_abbrev[state_clean]\n",
    "        else:\n",
    "            # Intentar match parcial\n",
    "            for full, abbr in state_abbrev.items():\n",
    "                if full in state_clean or state_clean in full:\n",
    "                    state_normalized = abbr\n",
    "                    break\n",
    "    \n",
    "    state = state_normalized\n",
    "    \n",
    "    # Estrategia 1: Full name + state\n",
    "    key1 = f\"{full_name}_{state}\"\n",
    "    if key1 in match_dict_full:\n",
    "        return match_dict_full[key1], 'full_name+state'\n",
    "    \n",
    "    # Estrategia 2: Full name sin middle initial + state\n",
    "    full_no_middle = remove_middle_initial(row.get('full_name', ''))\n",
    "    key2 = f\"{full_no_middle}_{state}\"\n",
    "    if key2 in match_dict_no_middle:\n",
    "        return match_dict_no_middle[key2], 'no_middle+state'\n",
    "    \n",
    "    # Estrategia 3: Construir full name desde first + last\n",
    "    constructed_name = f\"{first_name} {last_name}\".strip()\n",
    "    key3 = f\"{constructed_name}_{state}\"\n",
    "    if key3 in match_dict_no_middle:\n",
    "        return match_dict_no_middle[key3], 'constructed+state'\n",
    "    \n",
    "    # Estrategia 4: Name key\n",
    "    name_key = create_name_key(first_name, last_name, state)\n",
    "    if name_key in match_dict_key:\n",
    "        return match_dict_key[name_key], 'name_key'\n",
    "    \n",
    "    # Estrategia 5: Last name + state (menos preciso)\n",
    "    key5 = f\"{last_name}_{state}\"\n",
    "    if key5 in match_dict_last_state:\n",
    "        return match_dict_last_state[key5], 'last+state'\n",
    "    \n",
    "    # =====================================================\n",
    "    # ESTRATEGIAS SIN ESTADO (cuando state es NaN o vac√≠o)\n",
    "    # =====================================================\n",
    "    \n",
    "    # Estrategia 6: Full name solo (sin estado) - buscar en todos\n",
    "    if full_name in match_dict_name_only:\n",
    "        return match_dict_name_only[full_name], 'full_name_only'\n",
    "    \n",
    "    # Estrategia 7: Full name sin middle initial (sin estado)\n",
    "    if full_no_middle in match_dict_name_no_middle_only:\n",
    "        return match_dict_name_no_middle_only[full_no_middle], 'no_middle_only'\n",
    "    \n",
    "    # Estrategia 8: Constructed name (sin estado)\n",
    "    if constructed_name and constructed_name in match_dict_name_no_middle_only:\n",
    "        return match_dict_name_no_middle_only[constructed_name], 'constructed_only'\n",
    "    \n",
    "    return None, 'no_match'\n",
    "\n",
    "# =============================================================================\n",
    "# 3. PROCESAR CADA ARCHIVO DE COMIT√âS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROCESANDO ARCHIVOS DE COMIT√âS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_committees = []\n",
    "\n",
    "for name, filepath in COMMITTEE_FILES.items():\n",
    "    print(f\"\\nüìÅ Procesando: {name}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep=';')\n",
    "    except:\n",
    "        df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Eliminar columnas vac√≠as\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    print(f\"   Filas: {len(df)}\")\n",
    "    \n",
    "    # Aplicar matching\n",
    "    results = df.apply(find_bioguide, axis=1)\n",
    "    df['bioguide_id'] = [r[0] for r in results]\n",
    "    df['match_method'] = [r[1] for r in results]\n",
    "    \n",
    "    # Estad√≠sticas\n",
    "    matched = df['bioguide_id'].notna().sum()\n",
    "    print(f\"   ‚úÖ Matched: {matched} ({100*matched/len(df):.1f}%)\")\n",
    "    print(f\"   ‚ùå Sin match: {len(df) - matched}\")\n",
    "    \n",
    "    # Ver m√©todos de matching usados\n",
    "    print(f\"   M√©todos de match:\")\n",
    "    print(df['match_method'].value_counts().to_string())\n",
    "    \n",
    "    # Ver algunos que no matchearon\n",
    "    no_match = df[df['bioguide_id'].isna()]\n",
    "    if len(no_match) > 0:\n",
    "        print(f\"\\n   ‚ö†Ô∏è Ejemplos sin match:\")\n",
    "        sample_cols = ['full_name', 'state', 'party']\n",
    "        sample_cols = [c for c in sample_cols if c in no_match.columns]\n",
    "        print(no_match[sample_cols].head(5).to_string())\n",
    "    \n",
    "    # Agregar source\n",
    "    df['source_file'] = name\n",
    "    all_committees.append(df)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. COMBINAR Y GUARDAR\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GUARDANDO RESULTADOS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combinar todos los comit√©s\n",
    "all_committees_df = pd.concat(all_committees, ignore_index=True)\n",
    "\n",
    "print(f\"\\nTotal registros combinados: {len(all_committees_df)}\")\n",
    "print(f\"Con bioguide_id: {all_committees_df['bioguide_id'].notna().sum()}\")\n",
    "\n",
    "# Guardar archivo combinado\n",
    "output_combined = OUTPUT_PATH / \"committees_with_bioguide.csv\"\n",
    "all_committees_df.to_csv(output_combined, index=False)\n",
    "print(f\"üíæ Guardado: {output_combined}\")\n",
    "\n",
    "# Tambi√©n guardar cada archivo individual actualizado\n",
    "for name, filepath in COMMITTEE_FILES.items():\n",
    "    df_subset = all_committees_df[all_committees_df['source_file'] == name].drop(columns=['source_file'])\n",
    "    output_individual = OUTPUT_PATH / f\"{name}_with_bioguide.csv\"\n",
    "    df_subset.to_csv(output_individual, index=False)\n",
    "    print(f\"üíæ Guardado: {output_individual}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. RESUMEN DE NO MATCHES PARA REVISI√ìN MANUAL\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REGISTROS SIN MATCH (para revisi√≥n manual)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "no_matches = all_committees_df[all_committees_df['bioguide_id'].isna()]\n",
    "if len(no_matches) > 0:\n",
    "    no_match_summary = no_matches.groupby(['full_name', 'state']).size().reset_index(name='count')\n",
    "    no_match_summary = no_match_summary.sort_values('count', ascending=False)\n",
    "    \n",
    "    output_no_match = OUTPUT_PATH / \"committees_no_match.csv\"\n",
    "    no_match_summary.to_csv(output_no_match, index=False)\n",
    "    print(f\"üíæ Lista de no matches guardada: {output_no_match}\")\n",
    "    print(f\"\\nTop 20 sin match:\")\n",
    "    print(no_match_summary.head(20).to_string())\n",
    "\n",
    "print(\"\\n‚úÖ ¬°PROCESO COMPLETADO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1538c4-2465-493b-959c-dd3531b08e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CARGANDO DATOS...\n",
      "============================================================\n",
      "üìä Trades cargados: 99,609 filas\n",
      "üìã Comit√©s cargados: 5,722 filas\n",
      "\n",
      "Columnas en trades: ['Ticker', 'TickerType', 'Company', 'Traded', 'Transaction', 'Trade_Size_USD', 'Status', 'Subholding', 'Description', 'Name']...\n",
      "Columnas en committees: ['committee', 'chamber', 'congress', 'year_start', 'year_end', 'full_name', 'first_name', 'last_name', 'party', 'state', 'role', 'Unnamed: 11', 'bioguide_id', 'match_method', 'source_file', 'Unnamed: 12']\n",
      "\n",
      "============================================================\n",
      "PREPARANDO COMIT√âS...\n",
      "============================================================\n",
      "Comit√©s con bioguide_id: 2,016\n",
      "\n",
      "Comit√©s √∫nicos: 55\n",
      "T√≥picos √∫nicos: 22\n",
      "\n",
      "üìã Mapeo de comit√©s:\n",
      "                                committee_name committee_id committee_topic  count\n",
      "0                    Administraci√≥n de la Casa      COM_001           other      6\n",
      "1                                  Agricultura      COM_002           other     12\n",
      "2                                  Agriculture      COM_003     agriculture    143\n",
      "3           Agriculture Nutrition and Forestry      COM_004           other      8\n",
      "4          Agriculture, Nutrition and Forestry      COM_005     agriculture     10\n",
      "5                               Appropriations      COM_006          budget    168\n",
      "6                               Armed Services      COM_007         defense    175\n",
      "7                           Asuntos exteriores      COM_008           other     15\n",
      "8            Banking Housing and Urban Affairs      COM_009           other      7\n",
      "9           Banking, Housing and Urban Affairs      COM_010         finance     14\n",
      "10                                      Budget      COM_011          budget     57\n",
      "11               Ciencia, espacio y tecnolog√≠a      COM_012           other     11\n",
      "12        Commerce, Science and Transportation      COM_013        commerce     13\n",
      "13                 Committee on Indian Affairs      COM_014           other      8\n",
      "14                  Educaci√≥n y fuerza laboral      COM_015           other      9\n",
      "15                     Education and Workforce      COM_016       education      9\n",
      "16                         Energy and Commerce      COM_017          energy    121\n",
      "17                Energy and Natural Resources      COM_018          energy     25\n",
      "18                          Energ√≠a y Comercio      COM_019           other      9\n",
      "19                Environment and Public Works      COM_020     environment     15\n",
      "20                                      Ethics      COM_021          ethics     10\n",
      "21                                     Finance      COM_022         finance     45\n",
      "22                          Financial Services      COM_023         finance    187\n",
      "23                             Foreign Affairs      COM_024         foreign    123\n",
      "24                           Foreign Relations      COM_025         foreign     21\n",
      "25        Health  Education Labor and Pensions      COM_026           other     15\n",
      "26       Health, Education, Labor and Pensions      COM_027          health      8\n",
      "27                           Homeland Security      COM_028        security    103\n",
      "28  Homeland Security and Governmental Affairs      COM_029        security     20\n",
      "29                        House Administration      COM_030  administration     14\n",
      "30                                Intelligence      COM_031    intelligence     33\n",
      "31                                   Judiciary      COM_032       judiciary    178\n",
      "32                              Modos y medios      COM_033           other      9\n",
      "33                           Natural Resources      COM_034     environment     45\n",
      "34                                      Normas      COM_035           other      5\n",
      "35                Oversight and Accountability      COM_036       oversight     14\n",
      "36                             Peque√±a empresa      COM_037           other     10\n",
      "37                          Recursos naturales      COM_038           other     12\n",
      "38                                       Rules      COM_039           rules     13\n",
      "39                    Rules and Administration      COM_040           rules     10\n",
      "40               Science  Space and Technology      COM_041           other      8\n",
      "41                          Seguridad Nacional      COM_042           other     22\n",
      "42                  Select Committee on Ethics      COM_043           other      4\n",
      "43            Select Committee on Intelligence      COM_044    intelligence     24\n",
      "44                       Servicios financieros      COM_045           other     14\n",
      "45                              Small Business      COM_046        business      5\n",
      "46         Small Business and Entrepreneurship      COM_047        business      7\n",
      "47                  Special Committee on Aging      COM_048           other      8\n",
      "48         Supervisi√≥n y reforma gubernamental      COM_049           other     18\n",
      "49           Transportation and Infrastructure      COM_050  infrastructure     25\n",
      "50                Transporte e Infraestructura      COM_051           other     13\n",
      "51                            Veterans Affairs      COM_052        veterans     34\n",
      "52                           Veterans' Affairs      COM_053        veterans      8\n",
      "53                              Ways and Means      COM_054             tax    108\n",
      "54                                       √âtica      COM_055           other      8\n",
      "\n",
      "============================================================\n",
      "PROCESANDO A√ëOS...\n",
      "============================================================\n",
      "Columnas de fecha encontradas: ['Traded', 'Filed']\n",
      "\n",
      "Todas las columnas en trades:\n",
      "['Ticker', 'TickerType', 'Company', 'Traded', 'Transaction', 'Trade_Size_USD', 'Status', 'Subholding', 'Description', 'Name', 'BioGuideID', 'Filed', 'Party', 'District', 'Chamber', 'Comments', 'Quiver_Upload_Time', 'excess_return', 'State', 'last_modified', 'Ticker_Clean', 'is_equity', 'trade_id', 'return_t', 'abs_return_t', 'return_overnight', 'return_intraday', 'momentum_5d', 'momentum_20d', 'momentum_60d', 'momentum_252d', 'realized_vol_30d', 'parkinson_vol_30d', 'realized_vol_60d', 'vol_of_vol_60d', 'realized_vol_252d', 'volume_t', 'dollar_volume_t', 'volume_ratio_30d', 'abnormal_volume_30d', 'amihud_illiq_20d', 'roll_spread_30d', 'hl_spread_20d', 'zero_volume_days_30d', 'beta_252d', 'r2_market_252d', 'alpha_ff3_252d', 'beta_mkt_ff3_252d', 'beta_smb_ff3_252d', 'beta_hml_ff3_252d', 'r2_ff3_252d', 'market_cap', 'price', 'book_value', 'price_to_book', 'ev_to_ebitda', 'car_raw_30d', 'car_capm_30d', 'car_ff3_30d', 'error', 'car_raw_60d', 'car_capm_60d', 'car_ff3_60d', 'car_raw_90d', 'car_capm_90d', 'car_ff3_90d', 'bioguide_id_clean', 'full_name', 'birthday', 'gender', 'type', 'state', 'senate_class', 'party', \"Bachelor's\", 'Religion', 'Base salary', 'Net worth', 'Term ends', 'Years in position', 'has_twitter', 'has_facebook', 'has_wikipedia', 'is_male', 'chamber', 'party_code', 'is_democrat', 'is_republican', 'is_independent']\n",
      "Usando columna: Traded\n",
      "Rango de a√±os en trades: 2012 - 2026\n",
      "\n",
      "============================================================\n",
      "PREPARANDO COMIT√âS POR A√ëO...\n",
      "============================================================\n",
      "A√±os en comit√©s: [np.int64(2017), np.int64(2019), np.int64(2021), np.int64(2023), np.int64(2025)]\n",
      "Comit√©s expandidos (cubriendo 2 a√±os por congreso): 4,032\n",
      "\n",
      "============================================================\n",
      "CREANDO LOOKUP TABLE...\n",
      "============================================================\n",
      "Combinaciones √∫nicas bioguide+a√±o: 3,132\n",
      "\n",
      "============================================================\n",
      "MERGEANDO TRADES CON COMIT√âS...\n",
      "============================================================\n",
      "Columnas bioguide en trades: ['BioGuideID', 'bioguide_id_clean']\n",
      "\n",
      "Resultado del merge:\n",
      "  - Trades totales: 99,609\n",
      "  - Con comit√©: 55,423\n",
      "  - Sin comit√©: 44,186\n",
      "\n",
      "============================================================\n",
      "IMPUTANDO MISSING CON MODA...\n",
      "============================================================\n",
      "Legisladores con moda calculada: 170\n",
      "Missing antes de imputar: 44,186\n",
      "Missing despu√©s de imputar: 17,032\n",
      "Imputados: 27,154\n",
      "\n",
      "Comit√©s imputados (flag): 44,186\n",
      "\n",
      "============================================================\n",
      "RESUMEN FINAL\n",
      "============================================================\n",
      "\n",
      "üìä Dataset final: (99609, 97)\n",
      "\n",
      "üìã Distribuci√≥n por comit√© (top 15):\n",
      "committee_name\n",
      "Armed Services                   29129\n",
      "Foreign Affairs                  22786\n",
      "Homeland Security                 8546\n",
      "Financial Services                4160\n",
      "Energy and Commerce               2518\n",
      "Appropriations                    2360\n",
      "Ways and Means                    1999\n",
      "Agriculture                       1903\n",
      "Natural Resources                 1297\n",
      "Education and Workforce            906\n",
      "Finance                            781\n",
      "Judiciary                          601\n",
      "Recursos naturales                 597\n",
      "Science  Space and Technology      539\n",
      "Environment and Public Works       535\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìã Distribuci√≥n por t√≥pico:\n",
      "committee_topic\n",
      "defense           29129\n",
      "foreign           22786\n",
      "security           8633\n",
      "finance            4975\n",
      "other              3578\n",
      "budget             2729\n",
      "energy             2543\n",
      "agriculture        2097\n",
      "tax                1999\n",
      "environment        1832\n",
      "education           906\n",
      "judiciary           601\n",
      "veterans            229\n",
      "rules               193\n",
      "commerce            124\n",
      "intelligence        123\n",
      "ethics               55\n",
      "infrastructure       37\n",
      "business              7\n",
      "oversight             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìã Distribuci√≥n por chamber:\n",
      "committee_chamber\n",
      "house     76790\n",
      "senate     5787\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìã Missing finales:\n",
      "  - committee_name: 17,032\n",
      "  - committee_topic: 17,032\n",
      "\n",
      "üíæ Guardado: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\congress_trades_with_committees.parquet\n",
      "üíæ Guardado: C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\\outputs\\congress_trades_with_committees.csv\n",
      "\n",
      "============================================================\n",
      "COLUMNAS AGREGADAS\n",
      "============================================================\n",
      "\n",
      "‚úÖ committee_name     - Nombre del comit√© en ingl√©s\n",
      "‚úÖ committee_id       - ID √∫nico del comit√© (COM_001, COM_002, etc.)\n",
      "‚úÖ committee_chamber  - 'house' o 'senate'\n",
      "‚úÖ committee_topic    - Palabra clave (finance, energy, defense, etc.)\n",
      "‚úÖ committee_role     - Rol en el comit√© (Chair, Member, etc.)\n",
      "‚úÖ committee_imputed  - 1 si fue imputado con moda, 0 si es dato real\n",
      "\n",
      "\n",
      "‚úÖ ¬°PROCESO COMPLETADO!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script para mergear trades con informaci√≥n de comit√©s\n",
    "Agrega: committee_name, committee_id, committee_chamber, committee_topic\n",
    "\n",
    "Proyecto: Detecci√≥n de Insider Trading - Maestr√≠a en Econom√≠a UdeSA\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURACI√ìN\n",
    "# =============================================================================\n",
    "BASE_PATH = Path(r\"C:\\Users\\sebib\\Documents\\GitHub\\US_Congress\\data\")\n",
    "TRADES_PATH = BASE_PATH / \"outputs\" / \"congress_trades_merged.parquet\"  # El archivo ya mergeado con info de pol√≠ticos\n",
    "COMMITTEES_PATH = BASE_PATH / \"outputs\" / \"committees_with_bioguide.csv\"\n",
    "OUTPUT_PATH = BASE_PATH / \"outputs\" / \"congress_trades_with_committees.parquet\"\n",
    "\n",
    "# =============================================================================\n",
    "# MAPEO DE COMIT√âS: ESPA√ëOL ‚Üí INGL√âS Y T√ìPICOS\n",
    "# =============================================================================\n",
    "\n",
    "# Diccionario de traducci√≥n espa√±ol ‚Üí ingl√©s\n",
    "COMMITTEE_TRANSLATION = {\n",
    "    # Senate (espa√±ol)\n",
    "    'agricultura, nutrici√≥n y silvicultura': 'Agriculture, Nutrition and Forestry',\n",
    "    'asignaciones': 'Appropriations',\n",
    "    'servicios armados': 'Armed Services',\n",
    "    'banca, vivienda y asuntos urbanos': 'Banking, Housing and Urban Affairs',\n",
    "    'presupuesto': 'Budget',\n",
    "    'comercio, ciencia y transporte': 'Commerce, Science and Transportation',\n",
    "    'energ√≠a y recursos naturales': 'Energy and Natural Resources',\n",
    "    'medio ambiente y obras p√∫blicas': 'Environment and Public Works',\n",
    "    'finanzas': 'Finance',\n",
    "    'relaciones exteriores': 'Foreign Relations',\n",
    "    'salud, educaci√≥n, trabajo y pensiones': 'Health, Education, Labor and Pensions',\n",
    "    'seguridad nacional y asuntos gubernamentales': 'Homeland Security and Governmental Affairs',\n",
    "    'judicial': 'Judiciary',\n",
    "    'reglas y administraci√≥n': 'Rules and Administration',\n",
    "    'peque√±as empresas y emprendimiento': 'Small Business and Entrepreneurship',\n",
    "    'asuntos de veteranos': 'Veterans Affairs',\n",
    "}\n",
    "\n",
    "# Mapeo de comit√© ‚Üí t√≥pico/palabra clave\n",
    "COMMITTEE_TOPICS = {\n",
    "    # House\n",
    "    'financial services': 'finance',\n",
    "    'ways and means': 'tax',\n",
    "    'finance': 'finance',\n",
    "    'agriculture': 'agriculture',\n",
    "    'appropriations': 'budget',\n",
    "    'armed services': 'defense',\n",
    "    'budget': 'budget',\n",
    "    'education and workforce': 'education',\n",
    "    'education and labor': 'education',\n",
    "    'energy and commerce': 'energy',\n",
    "    'ethics': 'ethics',\n",
    "    'foreign affairs': 'foreign',\n",
    "    'homeland security': 'security',\n",
    "    'house administration': 'administration',\n",
    "    'judiciary': 'judiciary',\n",
    "    'natural resources': 'environment',\n",
    "    'oversight and accountability': 'oversight',\n",
    "    'oversight and reform': 'oversight',\n",
    "    'rules': 'rules',\n",
    "    'science': 'science',\n",
    "    'science, space and technology': 'science',\n",
    "    'small business': 'business',\n",
    "    'transportation and infrastructure': 'infrastructure',\n",
    "    'veterans affairs': 'veterans',\n",
    "    \"veterans' affairs\": 'veterans',\n",
    "    'intelligence': 'intelligence',\n",
    "    'select committee on intelligence': 'intelligence',\n",
    "    \n",
    "    # Senate\n",
    "    'agriculture, nutrition and forestry': 'agriculture',\n",
    "    'banking, housing and urban affairs': 'finance',\n",
    "    'commerce, science and transportation': 'commerce',\n",
    "    'energy and natural resources': 'energy',\n",
    "    'environment and public works': 'environment',\n",
    "    'foreign relations': 'foreign',\n",
    "    'health, education, labor and pensions': 'health',\n",
    "    'homeland security and governmental affairs': 'security',\n",
    "    'rules and administration': 'rules',\n",
    "    'small business and entrepreneurship': 'business',\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CARGAR DATOS\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"CARGANDO DATOS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cargar trades (ya tiene info de pol√≠ticos)\n",
    "trades = pd.read_parquet(TRADES_PATH)\n",
    "print(f\"üìä Trades cargados: {len(trades):,} filas\")\n",
    "\n",
    "# Cargar comit√©s con bioguide\n",
    "committees = pd.read_csv(COMMITTEES_PATH)\n",
    "print(f\"üìã Comit√©s cargados: {len(committees):,} filas\")\n",
    "\n",
    "# Ver columnas\n",
    "print(f\"\\nColumnas en trades: {trades.columns.tolist()[:10]}...\")\n",
    "print(f\"Columnas en committees: {committees.columns.tolist()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. LIMPIAR Y PREPARAR COMIT√âS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREPARANDO COMIT√âS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Filtrar solo los que tienen bioguide_id\n",
    "committees = committees[committees['bioguide_id'].notna()].copy()\n",
    "print(f\"Comit√©s con bioguide_id: {len(committees):,}\")\n",
    "\n",
    "# Normalizar nombre de comit√©\n",
    "committees['committee_lower'] = committees['committee'].str.lower().str.strip()\n",
    "\n",
    "# Traducir espa√±ol ‚Üí ingl√©s\n",
    "committees['committee_english'] = committees['committee_lower'].map(COMMITTEE_TRANSLATION)\n",
    "committees['committee_english'] = committees['committee_english'].fillna(committees['committee'])\n",
    "\n",
    "# Limpiar nombre final\n",
    "committees['committee_name'] = committees['committee_english'].str.strip()\n",
    "\n",
    "# Asignar t√≥pico\n",
    "committees['committee_topic'] = committees['committee_name'].str.lower().map(COMMITTEE_TOPICS)\n",
    "committees['committee_topic'] = committees['committee_topic'].fillna('other')\n",
    "\n",
    "# Crear ID de comit√©\n",
    "unique_committees = committees['committee_name'].str.lower().unique()\n",
    "committee_id_map = {name: f\"COM_{i+1:03d}\" for i, name in enumerate(sorted(unique_committees))}\n",
    "committees['committee_id'] = committees['committee_name'].str.lower().map(committee_id_map)\n",
    "\n",
    "# Chamber\n",
    "committees['committee_chamber'] = committees['chamber'].str.lower()\n",
    "\n",
    "print(f\"\\nComit√©s √∫nicos: {committees['committee_name'].nunique()}\")\n",
    "print(f\"T√≥picos √∫nicos: {committees['committee_topic'].nunique()}\")\n",
    "\n",
    "# Mostrar mapeo de comit√©s\n",
    "print(\"\\nüìã Mapeo de comit√©s:\")\n",
    "committee_summary = committees.groupby(['committee_name', 'committee_id', 'committee_topic']).size().reset_index(name='count')\n",
    "print(committee_summary.to_string())\n",
    "\n",
    "# =============================================================================\n",
    "# 3. DETERMINAR A√ëO EN TRADES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROCESANDO A√ëOS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Buscar columna de fecha en trades\n",
    "date_cols = [col for col in trades.columns if any(x in col.lower() for x in ['date', 'fecha', 'traded', 'filed']) and 'last' not in col.lower()]\n",
    "print(f\"Columnas de fecha encontradas: {date_cols}\")\n",
    "\n",
    "# Mostrar todas las columnas para debug\n",
    "print(f\"\\nTodas las columnas en trades:\")\n",
    "print(trades.columns.tolist())\n",
    "\n",
    "# Usar la columna 'Traded' para el a√±o del trade\n",
    "if 'Traded' in trades.columns:\n",
    "    trades['trade_date'] = pd.to_datetime(trades['Traded'], errors='coerce')\n",
    "    trades['trade_year'] = trades['trade_date'].dt.year\n",
    "    print(f\"Usando columna: Traded\")\n",
    "elif date_cols:\n",
    "    date_col = date_cols[0]\n",
    "    trades['trade_date'] = pd.to_datetime(trades[date_col], errors='coerce')\n",
    "    trades['trade_year'] = trades['trade_date'].dt.year\n",
    "    print(f\"Usando columna de fecha: {date_col}\")\n",
    "else:\n",
    "    raise ValueError(\"No se encontr√≥ columna 'Traded' o similar. Revisar datos.\")\n",
    "\n",
    "print(f\"Rango de a√±os en trades: {trades['trade_year'].min()} - {trades['trade_year'].max()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. PREPARAR COMIT√âS POR A√ëO\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREPARANDO COMIT√âS POR A√ëO...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Normalizar a√±os en comit√©s (algunos tienen congress number en vez de a√±o)\n",
    "def normalize_year(row):\n",
    "    year = row['year_start']\n",
    "    # Convertir a n√∫mero si es string\n",
    "    try:\n",
    "        year = int(float(year))\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "    \n",
    "    if year < 2000:  # Es n√∫mero de congreso, no a√±o\n",
    "        # Congress 115 = 2017-2018, 116 = 2019-2020, etc.\n",
    "        congress_to_year = {\n",
    "            115: 2017, 116: 2019, 117: 2021, 118: 2023, 119: 2025\n",
    "        }\n",
    "        return congress_to_year.get(year, year)\n",
    "    return year\n",
    "\n",
    "committees['year'] = committees.apply(normalize_year, axis=1)\n",
    "print(f\"A√±os en comit√©s: {sorted(committees['year'].unique())}\")\n",
    "\n",
    "# Expandir comit√©s para cubrir ambos a√±os del congreso\n",
    "# (cada congreso dura 2 a√±os)\n",
    "committees_expanded = []\n",
    "for _, row in committees.iterrows():\n",
    "    year = row['year']\n",
    "    # Agregar para el a√±o actual\n",
    "    committees_expanded.append(row.to_dict())\n",
    "    # Agregar para el a√±o siguiente (mismo congreso)\n",
    "    row_next = row.to_dict()\n",
    "    row_next['year'] = year + 1\n",
    "    committees_expanded.append(row_next)\n",
    "\n",
    "committees_expanded = pd.DataFrame(committees_expanded)\n",
    "print(f\"Comit√©s expandidos (cubriendo 2 a√±os por congreso): {len(committees_expanded):,}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. CREAR TABLA DE LOOKUP: BIOGUIDE + A√ëO ‚Üí COMIT√â(S)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREANDO LOOKUP TABLE...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Un pol√≠tico puede estar en m√∫ltiples comit√©s el mismo a√±o\n",
    "# Vamos a tomar el \"principal\" (donde tiene rol m√°s importante) o el primero\n",
    "\n",
    "# Ordenar por importancia del rol\n",
    "role_priority = {'chair': 1, 'ranking member': 2, 'vice chair': 3, 'member': 4}\n",
    "committees_expanded['role_lower'] = committees_expanded['role'].str.lower().fillna('member')\n",
    "committees_expanded['role_priority'] = committees_expanded['role_lower'].map(role_priority).fillna(5)\n",
    "\n",
    "# Para cada bioguide + a√±o, tomar el comit√© donde tiene rol m√°s importante\n",
    "committees_primary = committees_expanded.sort_values('role_priority').groupby(\n",
    "    ['bioguide_id', 'year']\n",
    ").first().reset_index()\n",
    "\n",
    "print(f\"Combinaciones √∫nicas bioguide+a√±o: {len(committees_primary):,}\")\n",
    "\n",
    "# Seleccionar columnas relevantes\n",
    "lookup = committees_primary[['bioguide_id', 'year', 'committee_name', 'committee_id', \n",
    "                              'committee_chamber', 'committee_topic', 'role']].copy()\n",
    "lookup = lookup.rename(columns={'role': 'committee_role'})\n",
    "\n",
    "# =============================================================================\n",
    "# 6. MERGE TRADES CON COMIT√âS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MERGEANDO TRADES CON COMIT√âS...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar columna de bioguide en trades\n",
    "bioguide_cols_trades = [col for col in trades.columns if 'bioguide' in col.lower()]\n",
    "print(f\"Columnas bioguide en trades: {bioguide_cols_trades}\")\n",
    "bioguide_col_trades = bioguide_cols_trades[0] if bioguide_cols_trades else None\n",
    "\n",
    "# Preparar trades para merge\n",
    "trades['bioguide_for_merge'] = trades[bioguide_col_trades].astype(str).str.strip().str.upper()\n",
    "lookup['bioguide_for_merge'] = lookup['bioguide_id'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Merge\n",
    "trades_with_committees = trades.merge(\n",
    "    lookup[['bioguide_for_merge', 'year', 'committee_name', 'committee_id', \n",
    "            'committee_chamber', 'committee_topic', 'committee_role']],\n",
    "    left_on=['bioguide_for_merge', 'trade_year'],\n",
    "    right_on=['bioguide_for_merge', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Limpiar\n",
    "trades_with_committees = trades_with_committees.drop(columns=['year', 'bioguide_for_merge'], errors='ignore')\n",
    "\n",
    "print(f\"\\nResultado del merge:\")\n",
    "print(f\"  - Trades totales: {len(trades_with_committees):,}\")\n",
    "print(f\"  - Con comit√©: {trades_with_committees['committee_name'].notna().sum():,}\")\n",
    "print(f\"  - Sin comit√©: {trades_with_committees['committee_name'].isna().sum():,}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. IMPUTAR MISSING CON MODA\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IMPUTANDO MISSING CON MODA...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Para cada legislador, calcular su comit√© m√°s frecuente (moda)\n",
    "def get_mode(series):\n",
    "    \"\"\"Retorna la moda de una serie, o NaN si est√° vac√≠a\"\"\"\n",
    "    mode = series.mode()\n",
    "    return mode.iloc[0] if len(mode) > 0 else np.nan\n",
    "\n",
    "# Calcular moda por legislador (usando todos los a√±os donde s√≠ tiene comit√©)\n",
    "legislator_modes = trades_with_committees[trades_with_committees['committee_name'].notna()].groupby(\n",
    "    bioguide_col_trades\n",
    ").agg({\n",
    "    'committee_name': get_mode,\n",
    "    'committee_id': get_mode,\n",
    "    'committee_chamber': get_mode,\n",
    "    'committee_topic': get_mode,\n",
    "    'committee_role': get_mode,\n",
    "}).reset_index()\n",
    "\n",
    "legislator_modes.columns = [bioguide_col_trades, 'mode_committee_name', 'mode_committee_id', \n",
    "                            'mode_committee_chamber', 'mode_committee_topic', 'mode_committee_role']\n",
    "\n",
    "print(f\"Legisladores con moda calculada: {len(legislator_modes)}\")\n",
    "\n",
    "# Merge con las modas\n",
    "trades_with_committees = trades_with_committees.merge(\n",
    "    legislator_modes,\n",
    "    on=bioguide_col_trades,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Imputar missing\n",
    "missing_before = trades_with_committees['committee_name'].isna().sum()\n",
    "\n",
    "trades_with_committees['committee_name'] = trades_with_committees['committee_name'].fillna(\n",
    "    trades_with_committees['mode_committee_name'])\n",
    "trades_with_committees['committee_id'] = trades_with_committees['committee_id'].fillna(\n",
    "    trades_with_committees['mode_committee_id'])\n",
    "trades_with_committees['committee_chamber'] = trades_with_committees['committee_chamber'].fillna(\n",
    "    trades_with_committees['mode_committee_chamber'])\n",
    "trades_with_committees['committee_topic'] = trades_with_committees['committee_topic'].fillna(\n",
    "    trades_with_committees['mode_committee_topic'])\n",
    "trades_with_committees['committee_role'] = trades_with_committees['committee_role'].fillna(\n",
    "    trades_with_committees['mode_committee_role'])\n",
    "\n",
    "missing_after = trades_with_committees['committee_name'].isna().sum()\n",
    "\n",
    "print(f\"Missing antes de imputar: {missing_before:,}\")\n",
    "print(f\"Missing despu√©s de imputar: {missing_after:,}\")\n",
    "print(f\"Imputados: {missing_before - missing_after:,}\")\n",
    "\n",
    "# Eliminar columnas auxiliares\n",
    "mode_cols = [col for col in trades_with_committees.columns if col.startswith('mode_')]\n",
    "trades_with_committees = trades_with_committees.drop(columns=mode_cols)\n",
    "\n",
    "# =============================================================================\n",
    "# 8. CREAR FLAG DE IMPUTACI√ìN\n",
    "# =============================================================================\n",
    "# Agregar columna que indica si el comit√© fue imputado o no\n",
    "# (Rehacemos el merge para marcar)\n",
    "\n",
    "trades_with_committees_temp = trades.merge(\n",
    "    lookup[['bioguide_for_merge', 'year', 'committee_name']].rename(columns={'committee_name': 'original_committee'}),\n",
    "    left_on=[trades[bioguide_col_trades].astype(str).str.strip().str.upper(), 'trade_year'],\n",
    "    right_on=['bioguide_for_merge', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "trades_with_committees['committee_imputed'] = trades_with_committees_temp['original_committee'].isna().astype(int)\n",
    "\n",
    "print(f\"\\nComit√©s imputados (flag): {trades_with_committees['committee_imputed'].sum():,}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 9. RESUMEN Y GUARDAR\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN FINAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dataset final: {trades_with_committees.shape}\")\n",
    "\n",
    "print(f\"\\nüìã Distribuci√≥n por comit√© (top 15):\")\n",
    "print(trades_with_committees['committee_name'].value_counts().head(15))\n",
    "\n",
    "print(f\"\\nüìã Distribuci√≥n por t√≥pico:\")\n",
    "print(trades_with_committees['committee_topic'].value_counts())\n",
    "\n",
    "print(f\"\\nüìã Distribuci√≥n por chamber:\")\n",
    "print(trades_with_committees['committee_chamber'].value_counts())\n",
    "\n",
    "print(f\"\\nüìã Missing finales:\")\n",
    "print(f\"  - committee_name: {trades_with_committees['committee_name'].isna().sum():,}\")\n",
    "print(f\"  - committee_topic: {trades_with_committees['committee_topic'].isna().sum():,}\")\n",
    "\n",
    "# Guardar\n",
    "trades_with_committees.to_parquet(OUTPUT_PATH, index=False)\n",
    "print(f\"\\nüíæ Guardado: {OUTPUT_PATH}\")\n",
    "\n",
    "# Tambi√©n CSV\n",
    "csv_path = OUTPUT_PATH.with_suffix('.csv')\n",
    "trades_with_committees.to_csv(csv_path, index=False)\n",
    "print(f\"üíæ Guardado: {csv_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 10. MOSTRAR COLUMNAS NUEVAS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COLUMNAS AGREGADAS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "‚úÖ committee_name     - Nombre del comit√© en ingl√©s\n",
    "‚úÖ committee_id       - ID √∫nico del comit√© (COM_001, COM_002, etc.)\n",
    "‚úÖ committee_chamber  - 'house' o 'senate'\n",
    "‚úÖ committee_topic    - Palabra clave (finance, energy, defense, etc.)\n",
    "‚úÖ committee_role     - Rol en el comit√© (Chair, Member, etc.)\n",
    "‚úÖ committee_imputed  - 1 si fue imputado con moda, 0 si es dato real\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ ¬°PROCESO COMPLETADO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f96ad4-ebae-4b44-a3a4-8ccfe4dbf936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
