{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Prediction Bases: Congressional Trading\n",
    "\n",
    "Constructs monthly prediction bases with comprehensive congressional trading features.\n",
    "\n",
    "**Outputs:**\n",
    "- `base_sp500_monthly.csv`: For predicting S&P 500 returns\n",
    "- `base_sector_monthly.csv`: For predicting sector returns\n",
    "\n",
    "**Feature Categories:**\n",
    "1. Direction (CSI, buy ratio, net)\n",
    "2. Timing (disclosure delay, end of month, day of week)\n",
    "3. Coordination (same day trades, party, committee)\n",
    "4. Behavior (frequent traders, first time, direction change)\n",
    "5. Power (chairs, seniority, net worth)\n",
    "6. Relevance (committee-sector match)\n",
    "7. Context (contrarian, volatility, liquidity)\n",
    "8. Composite signals (smart money, insider ring)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white',\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'font.size': 11,\n",
    "    'figure.dpi': 120\n",
    "})\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "INPUT_TRADES = 'data/outputs/congress_trades_with_committees.csv'\n",
    "SECTOR_CACHE = 'data/outputs/ticker_sector_cache.csv'\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = 'data/prediction_bases'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Date range\n",
    "START_DATE = '2012-01-01'\n",
    "END_DATE = '2024-12-31'\n",
    "\n",
    "# Sector ETFs\n",
    "SECTOR_ETFS = {\n",
    "    'Energy': 'XLE',\n",
    "    'Financials': 'XLF',\n",
    "    'Health Care': 'XLV',\n",
    "    'Industrials': 'XLI',\n",
    "    'Technology': 'XLK',\n",
    "    'Consumer Discretionary': 'XLY',\n",
    "    'Consumer Staples': 'XLP',\n",
    "    'Materials': 'XLB',\n",
    "    'Utilities': 'XLU',\n",
    "    'Real Estate': 'XLRE',\n",
    "    'Communication Services': 'XLC'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Committee to sector mapping\n",
    "COMMITTEE_TO_SECTORS = {\n",
    "    'Armed Services': ['Industrials', 'Technology', 'Communication Services'],\n",
    "    'Foreign Affairs': ['Industrials', 'Energy', 'Materials', 'Financials', 'Technology'],\n",
    "    'Homeland Security': ['Industrials', 'Technology', 'Communication Services'],\n",
    "    'Intelligence': ['Technology', 'Industrials', 'Communication Services'],\n",
    "    'Select Committee on Intelligence': ['Technology', 'Industrials'],\n",
    "    'Financial Services': ['Financials', 'Real Estate'],\n",
    "    'Banking, Housing and Urban Affairs': ['Financials', 'Real Estate'],\n",
    "    'Finance': ['Financials'],\n",
    "    'Ways and Means': ['Financials', 'Health Care', 'Consumer Discretionary'],\n",
    "    'Energy and Commerce': ['Energy', 'Utilities', 'Health Care', 'Communication Services'],\n",
    "    'Energy and Natural Resources': ['Energy', 'Utilities', 'Materials'],\n",
    "    'Natural Resources': ['Energy', 'Materials', 'Utilities'],\n",
    "    'Environment and Public Works': ['Energy', 'Utilities', 'Materials'],\n",
    "    'Health  Education Labor and Pensions': ['Health Care'],\n",
    "    'Agriculture': ['Consumer Staples', 'Consumer Defensive', 'Materials'],\n",
    "    'Agriculture Nutrition and Forestry': ['Consumer Staples', 'Consumer Defensive', 'Materials'],\n",
    "    'Transportation and Infrastructure': ['Industrials', 'Energy'],\n",
    "    'Appropriations': ['Industrials', 'Health Care', 'Technology', 'Financials'],\n",
    "    'Education and Workforce': ['Consumer Discretionary', 'Technology'],\n",
    "    'Small Business': ['Consumer Discretionary', 'Industrials'],\n",
    "    'Judiciary': ['Technology', 'Communication Services'],\n",
    "    'Commerce, Science and Transportation': ['Technology', 'Communication Services', 'Industrials'],\n",
    "    'Science  Space and Technology': ['Technology', 'Industrials'],\n",
    "    \"Veterans Affairs\": ['Health Care', 'Industrials'],\n",
    "    \"Veterans' Affairs\": ['Health Care', 'Industrials'],\n",
    "}\n",
    "\n",
    "# Informative committees (more likely to have material non-public info)\n",
    "INFO_COMMITTEES = [\n",
    "    'Armed Services', 'Financial Services', 'Energy and Commerce',\n",
    "    'Intelligence', 'Select Committee on Intelligence',\n",
    "    'Ways and Means', 'Appropriations', 'Health  Education Labor and Pensions',\n",
    "    'Banking, Housing and Urban Affairs', 'Finance'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 99,609 trades\n",
      "Columns: 97\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_TRADES)\n",
    "print(f'Loaded {len(df):,} trades')\n",
    "print(f'Columns: {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Trade-Level Features\n",
    "\n",
    "Before aggregating, we need to create features at the individual trade level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buys: 50,079, Sells: 49,088\n"
     ]
    }
   ],
   "source": [
    "# Basic date features\n",
    "df['trade_date'] = pd.to_datetime(df['Traded'])\n",
    "df['filed_date'] = pd.to_datetime(df['Filed'])\n",
    "df['trade_month'] = df['trade_date'].dt.to_period('M')\n",
    "df['trade_year'] = df['trade_date'].dt.year\n",
    "\n",
    "# Buy/sell\n",
    "df['is_buy'] = (df['Transaction'] == 'Purchase').astype(int)\n",
    "df['is_sell'] = df['Transaction'].str.contains('Sale', case=False, na=False).astype(int)\n",
    "\n",
    "# Amount proxy\n",
    "size_map = {\n",
    "    '$1,001 - $15,000': 8000,\n",
    "    '$15,001 - $50,000': 32500,\n",
    "    '$50,001 - $100,000': 75000,\n",
    "    '$100,001 - $250,000': 175000,\n",
    "    '$250,001 - $500,000': 375000,\n",
    "    '$500,001 - $1,000,000': 750000,\n",
    "    '$1,000,001 - $5,000,000': 3000000,\n",
    "    'Over $5,000,000': 7500000,\n",
    "}\n",
    "df['amount_proxy'] = df['Trade_Size_USD'].map(size_map).fillna(8000)\n",
    "df['is_large_trade'] = (df['amount_proxy'] >= 100000).astype(int)\n",
    "\n",
    "print(f'Buys: {df[\"is_buy\"].sum():,}, Sells: {df[\"is_sell\"].sum():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Timing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg disclosure delay: 41.9 days\n",
      "Long delay (>30d): 43.6%\n",
      "End of month: 18.6%\n"
     ]
    }
   ],
   "source": [
    "# Disclosure delay\n",
    "df['disclosure_delay'] = (df['filed_date'] - df['trade_date']).dt.days\n",
    "df['disclosure_delay'] = df['disclosure_delay'].clip(lower=0, upper=365)\n",
    "\n",
    "# Long delay indicator (> 30 days)\n",
    "df['long_delay'] = (df['disclosure_delay'] > 30).astype(int)\n",
    "\n",
    "# End of month (last 5 days)\n",
    "df['day_of_month'] = df['trade_date'].dt.day\n",
    "df['days_in_month'] = df['trade_date'].dt.daysinmonth\n",
    "df['end_of_month'] = (df['days_in_month'] - df['day_of_month'] <= 5).astype(int)\n",
    "\n",
    "# Day of week\n",
    "df['day_of_week'] = df['trade_date'].dt.dayofweek\n",
    "df['is_monday'] = (df['day_of_week'] == 0).astype(int)\n",
    "df['is_friday'] = (df['day_of_week'] == 4).astype(int)\n",
    "\n",
    "print(f'Avg disclosure delay: {df[\"disclosure_delay\"].mean():.1f} days')\n",
    "print(f'Long delay (>30d): {df[\"long_delay\"].mean()*100:.1f}%')\n",
    "print(f'End of month: {df[\"end_of_month\"].mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sector and Committee Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache: 600 tickers\n",
      "Fetching 4083 new tickers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/500 [00:02<07:20,  1.13it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: 37045XEF9\"}}}\n",
      "  3%|▎         | 14/500 [00:11<05:47,  1.40it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: SINT1\"}}}\n",
      "  5%|▌         | 27/500 [00:21<05:32,  1.42it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: 912797LL9\"}}}\n",
      " 10%|█         | 50/500 [00:38<05:07,  1.47it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: NEE.PRI\"}}}\n",
      " 15%|█▌        | 76/500 [00:56<05:04,  1.39it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: HAMILTO\"}}}\n",
      " 20%|██        | 102/500 [01:16<04:37,  1.43it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: DUKPA\"}}}\n",
      " 21%|██        | 103/500 [01:17<05:29,  1.21it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: CNE1\"}}}\n",
      " 26%|██▌       | 128/500 [01:35<04:20,  1.43it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: EXPEA\"}}}\n",
      " 26%|██▌       | 130/500 [01:37<04:48,  1.28it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: LOLI\"}}}\n",
      " 28%|██▊       | 140/500 [01:44<04:12,  1.43it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: 912796X87\"}}}\n",
      " 29%|██▉       | 144/500 [01:47<04:18,  1.38it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: B1W8P14\"}}}\n",
      " 40%|███▉      | 198/500 [02:26<03:39,  1.38it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: JASN1\"}}}\n",
      " 41%|████      | 205/500 [02:32<03:35,  1.37it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: TAAL\"}}}\n",
      " 42%|████▏     | 208/500 [02:34<03:45,  1.29it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: CEMCF\"}}}\n",
      " 50%|█████     | 250/500 [03:05<03:14,  1.29it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: ICOR2\"}}}\n",
      " 52%|█████▏    | 262/500 [03:15<03:02,  1.30it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: AILP\"}}}\n",
      " 58%|█████▊    | 288/500 [03:33<02:27,  1.44it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: 91282CFK2\"}}}\n",
      " 60%|█████▉    | 298/500 [03:42<02:46,  1.21it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: BH1\"}}}\n",
      " 62%|██████▏   | 310/500 [03:51<02:20,  1.35it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: BLOC-U\"}}}\n",
      " 64%|██████▎   | 318/500 [03:57<02:08,  1.41it/s]HTTP Error 500: <!DOCTYPE html>\n",
      "<html lang=\"en-us\">\n",
      "  <head>\n",
      "    <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>Yahoo</title>\n",
      "    <meta name=\"viewport\" content=\"width=device-width,initial-scale=1,minimal-ui\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n",
      "    <style>\n",
      "      html {\n",
      "          height: 100%;\n",
      "      }\n",
      "      body {\n",
      "          background: #fafafc url(https://s.yimg.com/nn/img/sad-panda-201402200631.png) 50% 50%;\n",
      "          background-size: cover;\n",
      "          height: 100%;\n",
      "          text-align: center;\n",
      "          font: 300 18px \"helvetica neue\", helvetica, verdana, tahoma, arial, sans-serif;\n",
      "          margin: 0;\n",
      "      }\n",
      "      table {\n",
      "          height: 100%;\n",
      "          width: 100%;\n",
      "          table-layout: fixed;\n",
      "          border-collapse: collapse;\n",
      "          border-spacing: 0;\n",
      "          border: none;\n",
      "      }\n",
      "      h1 {\n",
      "          font-size: 42px;\n",
      "          font-weight: 400;\n",
      "          color: #400090;\n",
      "      }\n",
      "      p {\n",
      "          color: #1A1A1A;\n",
      "      }\n",
      "      #message-1 {\n",
      "          font-weight: bold;\n",
      "          margin: 0;\n",
      "      }\n",
      "      #message-2 {\n",
      "          display: inline-block;\n",
      "          *display: inline;\n",
      "          zoom: 1;\n",
      "          max-width: 17em;\n",
      "          _width: 17em;\n",
      "      }\n",
      "      </style>\n",
      "      <script>\n",
      "      \n",
      "      </script>\n",
      "  </head>\n",
      "  <body>\n",
      "  <!-- status code : 500 -->\n",
      "  <!-- Unknown Host -->\n",
      "  <!-- host machine: ats-ncache-api--production-bf1-6c47649f4-2n2z9 -->\n",
      "  <!-- timestamp: 1769898411.882 -->\n",
      "  <!-- url: https://default.finance-yql-production.finance-k8s.omega.yahoo.com/v10/finance/quoteSummary/07/01/36?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=07%2F01%2F36&crumb=IlfSKNIxtYh-->\n",
      "  <script type=\"text/javascript\">\n",
      "    function buildUrl(url, parameters){\n",
      "      var qs = [];\n",
      "      for(var key in parameters) {\n",
      "        var value = parameters[key];\n",
      "        qs.push(encodeURIComponent(key) + \"=\" + encodeURIComponent(value));\n",
      "      }\n",
      "      url = url + \"?\" + qs.join('&');\n",
      "      return url;\n",
      "    }\n",
      "\n",
      "    function generateBRBMarkup(site) {\n",
      "      params.source = 'brb';\n",
      "      generateBeaconMarkup(params);\n",
      "      var englishHeader = 'Will be right back...';\n",
      "      var englishMessage1 = 'Thank you for your patience.';\n",
      "      var englishMessage2 = 'Our engineers are working quickly to resolve the issue.';\n",
      "      var defaultLogoStyle = '';\n",
      "      var siteDataMap = {\n",
      "        'default': {\n",
      "          logo: 'https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_p_205x58_frontpage.png',\n",
      "          logoAlt: 'Yahoo Logo',\n",
      "          logoStyle: defaultLogoStyle,\n",
      "          header: englishHeader,\n",
      "          message1: englishMessage1,\n",
      "          message2: englishMessage2\n",
      "        }\n",
      "      };\n",
      "\n",
      "      var siteDetails = siteDataMap['default'];\n",
      "\n",
      "      document.write('<table><tbody><tr><td>');\n",
      "      document.write('<div id=\"content\">');\n",
      "      document.write('<img src=\"' + siteDetails['logo'] + '\" alt=\"' + siteDetails['logoAlt'] + '\" style=\"' + siteDetails['logoStyle'] + '\">');\n",
      "      document.write('<h1 style=\"margin-top:20px;\">' + siteDetails['header'] + '</h1>');\n",
      "      document.write('<p id=\"message-1\">' + siteDetails['message1'] + '</p>');\n",
      "      document.write('<p id=\"message-2\">' + siteDetails['message2'] + '</p>');\n",
      "      document.write('</div>');\n",
      "      document.write('</td></tr></tbody></table>');\n",
      "    }\n",
      "\n",
      "    function generateBeaconMarkup(params) {\n",
      "        document.write('<img src=\"' + buildUrl('//geo.yahoo.com/b', params) + '\" style=\"display:none;\" width=\"0px\" height=\"0px\"/>');\n",
      "        var beacon = new Image();\n",
      "        beacon.src = buildUrl('//bcn.fp.yahoo.com/p', params);\n",
      "    }\n",
      "\n",
      "    var hostname = window.location.hostname;\n",
      "    var device = 'desktop';\n",
      "    var ynet = ('-' === '1');\n",
      "    var time = new Date().getTime();\n",
      "    var params = {\n",
      "        s: '1197757129',\n",
      "        t: time,\n",
      "        err_url: document.URL,\n",
      "        err: '500',\n",
      "        test: '-',\n",
      "        ats_host: 'ats-ncache-api--production-bf1-6c47649f4-2n2z9',\n",
      "        rid: '-',\n",
      "        message: 'Unknown Host'\n",
      "    };\n",
      "\n",
      "    if(ynet) {\n",
      "        document.write('<div style=\"height: 5px; background-color: red;\"></div>');\n",
      "    }\n",
      "    generateBRBMarkup(hostname, params);\n",
      "\n",
      "  </script>\n",
      "  <noscript>\n",
      "  <table>\n",
      "    <tbody>\n",
      "      <tr>\n",
      "        <td>\n",
      "          <div id=\"englishContent\">\n",
      "            <h1 style=\"margin-top:20px;\">Will be right back...</h1>\n",
      "            <p id=\"message-1\">Thank you for your patience.</p>\n",
      "            <p id=\"message-2\">Our engineers are working quickly to resolve the issue.</p>\n",
      "          </div>\n",
      "        </td>\n",
      "      </tr>\n",
      "    </tbody>\n",
      "  </table>\n",
      "  </noscript>\n",
      "  </body>\n",
      "</html>\n",
      "\n",
      " 65%|██████▌   | 326/500 [04:04<02:04,  1.40it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: SYMBOL\"}}}\n",
      " 75%|███████▌  | 375/500 [04:41<01:34,  1.32it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: CCCS\"}}}\n",
      " 77%|███████▋  | 386/500 [04:50<01:22,  1.39it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: IGAF\"}}}\n",
      " 79%|███████▉  | 397/500 [04:58<01:21,  1.26it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: BGFV\"}}}\n",
      " 82%|████████▏ | 411/500 [05:09<01:02,  1.43it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: HES\"}}}\n",
      " 83%|████████▎ | 417/500 [05:14<01:03,  1.31it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: 506120KP8\"}}}\n",
      " 84%|████████▍ | 421/500 [05:18<00:59,  1.34it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: FDC1\"}}}\n",
      " 85%|████████▍ | 423/500 [05:32<04:36,  3.60s/it]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: MEAT\"}}}\n",
      " 86%|████████▌ | 430/500 [05:38<01:07,  1.03it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: NCMV\"}}}\n",
      " 90%|████████▉ | 448/500 [05:52<00:41,  1.24it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: WB1\"}}}\n",
      " 92%|█████████▏| 458/500 [06:00<00:29,  1.44it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: B923935\"}}}\n",
      " 92%|█████████▏| 462/500 [06:03<00:29,  1.29it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: PLL\"}}}\n",
      " 93%|█████████▎| 467/500 [06:07<00:26,  1.27it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: GSP1\"}}}\n",
      " 94%|█████████▍| 471/500 [06:11<00:23,  1.22it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: NYLD.A\"}}}\n",
      " 95%|█████████▍| 474/500 [06:14<00:23,  1.10it/s]HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: UST1\"}}}\n",
      "100%|██████████| 500/500 [06:38<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trades with sector: 21,408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load sector cache\n",
    "def get_ticker_sectors(tickers, cache_file):\n",
    "    try:\n",
    "        cache_df = pd.read_csv(cache_file)\n",
    "        cache = dict(zip(cache_df['ticker'], cache_df['sector']))\n",
    "        print(f'Loaded cache: {len(cache)} tickers')\n",
    "    except FileNotFoundError:\n",
    "        cache = {}\n",
    "        print('No cache found')\n",
    "    \n",
    "    tickers_unique = [t for t in set(tickers) if pd.notna(t)]\n",
    "    missing = [t for t in tickers_unique if t not in cache]\n",
    "    \n",
    "    if missing:\n",
    "        print(f'Fetching {len(missing)} new tickers...')\n",
    "        for ticker in tqdm(missing[:500]):\n",
    "            try:\n",
    "                info = yf.Ticker(ticker).info\n",
    "                cache[ticker] = info.get('sector', None)\n",
    "            except:\n",
    "                cache[ticker] = None\n",
    "        cache_df = pd.DataFrame({'ticker': list(cache.keys()), 'sector': list(cache.values())})\n",
    "        cache_df.to_csv(cache_file, index=False)\n",
    "    \n",
    "    return cache\n",
    "\n",
    "sector_cache = get_ticker_sectors(df['Ticker_Clean'].dropna().unique(), SECTOR_CACHE)\n",
    "df['sector'] = df['Ticker_Clean'].map(sector_cache)\n",
    "\n",
    "# Normalize\n",
    "sector_normalize = {\n",
    "    'Information Technology': 'Technology',\n",
    "    'Consumer Cyclical': 'Consumer Discretionary',\n",
    "    'Financial Services': 'Financials',\n",
    "    'Healthcare': 'Health Care',\n",
    "    'Basic Materials': 'Materials',\n",
    "}\n",
    "df['sector'] = df['sector'].replace(sector_normalize)\n",
    "\n",
    "print(f'Trades with sector: {df[\"sector\"].notna().sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committee related: 5.3%\n",
      "Info committee: 41.4%\n"
     ]
    }
   ],
   "source": [
    "# Committee match\n",
    "def get_committee_sectors(committee_name):\n",
    "    if pd.isna(committee_name):\n",
    "        return []\n",
    "    for comm, sectors in COMMITTEE_TO_SECTORS.items():\n",
    "        if comm.lower() in str(committee_name).lower() or str(committee_name).lower() in comm.lower():\n",
    "            return sectors\n",
    "    return []\n",
    "\n",
    "def check_committee_match(row):\n",
    "    if pd.isna(row.get('sector')) or pd.isna(row.get('committee_name')):\n",
    "        return 0\n",
    "    committee_sectors = get_committee_sectors(row['committee_name'])\n",
    "    if not committee_sectors:\n",
    "        return 0\n",
    "    for cs in committee_sectors:\n",
    "        if cs.lower() in str(row['sector']).lower() or str(row['sector']).lower() in cs.lower():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def is_info_committee(committee_name):\n",
    "    if pd.isna(committee_name):\n",
    "        return 0\n",
    "    for ic in INFO_COMMITTEES:\n",
    "        if ic.lower() in str(committee_name).lower():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df['committee_related'] = df.apply(check_committee_match, axis=1)\n",
    "df['is_info_committee'] = df['committee_name'].apply(is_info_committee)\n",
    "\n",
    "# Chair indicator\n",
    "if 'committee_role' in df.columns:\n",
    "    df['is_chair'] = df['committee_role'].str.lower().str.contains('chair|ranking', na=False).astype(int)\n",
    "else:\n",
    "    df['is_chair'] = 0\n",
    "\n",
    "print(f'Committee related: {df[\"committee_related\"].mean()*100:.1f}%')\n",
    "print(f'Info committee: {df[\"is_info_committee\"].mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Power Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior (>10 yrs): 5.4%\n",
      "Avg power index: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Seniority\n",
    "if 'Years in position' in df.columns:\n",
    "    df['years_in_position'] = pd.to_numeric(df['Years in position'], errors='coerce').fillna(0)\n",
    "    df['is_senior'] = (df['years_in_position'] >= 10).astype(int)\n",
    "else:\n",
    "    df['years_in_position'] = 0\n",
    "    df['is_senior'] = 0\n",
    "\n",
    "# Net worth\n",
    "if 'Net worth' in df.columns:\n",
    "    df['net_worth'] = pd.to_numeric(df['Net worth'], errors='coerce').fillna(0)\n",
    "    df['is_wealthy'] = (df['net_worth'] > df['net_worth'].median()).astype(int)\n",
    "else:\n",
    "    df['net_worth'] = 0\n",
    "    df['is_wealthy'] = 0\n",
    "\n",
    "# High profile (has social media presence)\n",
    "if 'has_twitter' in df.columns and 'has_wikipedia' in df.columns:\n",
    "    df['high_profile'] = ((df['has_twitter'] == True) | (df['has_wikipedia'] == True)).astype(int)\n",
    "else:\n",
    "    df['high_profile'] = 0\n",
    "\n",
    "# Senate indicator\n",
    "df['is_senator'] = (df['Chamber'] == 'Senate').astype(int)\n",
    "\n",
    "# Power index (composite)\n",
    "df['power_index'] = df['is_chair'] + df['is_senator'] + df['is_senior'] + df['is_info_committee']\n",
    "\n",
    "print(f'Senior (>10 yrs): {df[\"is_senior\"].mean()*100:.1f}%')\n",
    "print(f'Avg power index: {df[\"power_index\"].mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Behavior Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent traders: 93.8%\n",
      "First time: 18.6%\n",
      "Direction change: 28.0%\n"
     ]
    }
   ],
   "source": [
    "# Frequent trader (top 25% by trade count)\n",
    "trader_counts = df.groupby('Name')['trade_id'].count()\n",
    "frequent_threshold = trader_counts.quantile(0.75)\n",
    "frequent_traders = trader_counts[trader_counts >= frequent_threshold].index\n",
    "df['frequent_trader'] = df['Name'].isin(frequent_traders).astype(int)\n",
    "\n",
    "# First time trading this stock\n",
    "df = df.sort_values(['Name', 'Ticker_Clean', 'trade_date'])\n",
    "df['first_time'] = (~df.duplicated(subset=['Name', 'Ticker_Clean'], keep='first')).astype(int)\n",
    "\n",
    "# Direction change (was buying, now selling or vice versa)\n",
    "df = df.sort_values(['Name', 'Ticker_Clean', 'trade_date'])\n",
    "df['prev_is_buy'] = df.groupby(['Name', 'Ticker_Clean'])['is_buy'].shift(1)\n",
    "df['direction_change'] = ((df['is_buy'] != df['prev_is_buy']) & df['prev_is_buy'].notna()).astype(int)\n",
    "\n",
    "print(f'Frequent traders: {df[\"frequent_trader\"].mean()*100:.1f}%')\n",
    "print(f'First time: {df[\"first_time\"].mean()*100:.1f}%')\n",
    "print(f'Direction change: {df[\"direction_change\"].mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Coordination Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinated: 6.0%\n",
      "Party coordinated: 2.0%\n",
      "Committee coordinated: 0.2%\n"
     ]
    }
   ],
   "source": [
    "# Coordinated: multiple politicians trading same stock on same day\n",
    "daily_stock_traders = df.groupby(['trade_date', 'Ticker_Clean'])['Name'].nunique().reset_index()\n",
    "daily_stock_traders.columns = ['trade_date', 'Ticker_Clean', 'n_traders_same_day']\n",
    "df = df.merge(daily_stock_traders, on=['trade_date', 'Ticker_Clean'], how='left')\n",
    "df['coordinated'] = (df['n_traders_same_day'] >= 2).astype(int)\n",
    "\n",
    "# Party coordinated: multiple from same party on same stock same day\n",
    "party_stock_traders = df.groupby(['trade_date', 'Ticker_Clean', 'Party'])['Name'].nunique().reset_index()\n",
    "party_stock_traders.columns = ['trade_date', 'Ticker_Clean', 'Party', 'n_party_traders']\n",
    "df = df.merge(party_stock_traders, on=['trade_date', 'Ticker_Clean', 'Party'], how='left')\n",
    "df['party_coordinated'] = (df['n_party_traders'] >= 2).astype(int)\n",
    "\n",
    "# Committee coordinated: multiple from same committee on same stock same day\n",
    "if 'committee_name' in df.columns:\n",
    "    comm_stock_traders = df[df['committee_name'].notna()].groupby(['trade_date', 'Ticker_Clean', 'committee_name'])['Name'].nunique().reset_index()\n",
    "    comm_stock_traders.columns = ['trade_date', 'Ticker_Clean', 'committee_name', 'n_comm_traders']\n",
    "    df = df.merge(comm_stock_traders, on=['trade_date', 'Ticker_Clean', 'committee_name'], how='left')\n",
    "    df['n_comm_traders'] = df['n_comm_traders'].fillna(1)\n",
    "    df['committee_coordinated'] = (df['n_comm_traders'] >= 2).astype(int)\n",
    "else:\n",
    "    df['committee_coordinated'] = 0\n",
    "\n",
    "print(f'Coordinated: {df[\"coordinated\"].mean()*100:.1f}%')\n",
    "print(f'Party coordinated: {df[\"party_coordinated\"].mean()*100:.1f}%')\n",
    "print(f'Committee coordinated: {df[\"committee_coordinated\"].mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Context Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrarian: 39.3%\n",
      "High vol: 40.6%\n",
      "Illiquid: 20.2%\n",
      "Small cap: 19.8%\n"
     ]
    }
   ],
   "source": [
    "# Using existing market data columns if available\n",
    "# Contrarian: buying when stock falling, selling when rising\n",
    "if 'momentum_20d' in df.columns:\n",
    "    df['contrarian'] = ((df['is_buy'] == 1) & (df['momentum_20d'] < 0) | \n",
    "                        (df['is_sell'] == 1) & (df['momentum_20d'] > 0)).astype(int)\n",
    "else:\n",
    "    df['contrarian'] = 0\n",
    "\n",
    "# High volatility\n",
    "if 'realized_vol_30d' in df.columns:\n",
    "    vol_median = df['realized_vol_30d'].median()\n",
    "    df['high_vol'] = (df['realized_vol_30d'] > vol_median).astype(int)\n",
    "else:\n",
    "    df['high_vol'] = 0\n",
    "\n",
    "# Illiquid\n",
    "if 'amihud_illiq_20d' in df.columns:\n",
    "    illiq_75 = df['amihud_illiq_20d'].quantile(0.75)\n",
    "    df['illiquid'] = (df['amihud_illiq_20d'] > illiq_75).astype(int)\n",
    "else:\n",
    "    df['illiquid'] = 0\n",
    "\n",
    "# Small cap\n",
    "if 'market_cap' in df.columns:\n",
    "    cap_25 = df['market_cap'].quantile(0.25)\n",
    "    df['small_cap'] = (df['market_cap'] < cap_25).astype(int)\n",
    "else:\n",
    "    df['small_cap'] = 0\n",
    "\n",
    "print(f'Contrarian: {df[\"contrarian\"].mean()*100:.1f}%')\n",
    "print(f'High vol: {df[\"high_vol\"].mean()*100:.1f}%')\n",
    "print(f'Illiquid: {df[\"illiquid\"].mean()*100:.1f}%')\n",
    "print(f'Small cap: {df[\"small_cap\"].mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Composite Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart money: 3.72%\n",
      "Insider ring: 0.25%\n",
      "Hidden trade: 8.10%\n",
      "Strong signal: 0.02%\n"
     ]
    }
   ],
   "source": [
    "# Smart money: buy + info committee + chair\n",
    "df['smart_money'] = ((df['is_buy'] == 1) & \n",
    "                     (df['is_info_committee'] == 1) & \n",
    "                     (df['is_chair'] == 1)).astype(int)\n",
    "\n",
    "# Insider ring: committee coordinated (multiple from same committee)\n",
    "df['insider_ring'] = df['committee_coordinated']\n",
    "\n",
    "# Hidden trade: illiquid/small cap + info committee\n",
    "df['hidden_trade'] = (((df['illiquid'] == 1) | (df['small_cap'] == 1)) & \n",
    "                      (df['is_info_committee'] == 1)).astype(int)\n",
    "\n",
    "# Strong signal: committee related + large trade + first time\n",
    "df['strong_signal'] = ((df['committee_related'] == 1) & \n",
    "                       (df['is_large_trade'] == 1) & \n",
    "                       (df['first_time'] == 1)).astype(int)\n",
    "\n",
    "print(f'Smart money: {df[\"smart_money\"].mean()*100:.2f}%')\n",
    "print(f'Insider ring: {df[\"insider_ring\"].mean()*100:.2f}%')\n",
    "print(f'Hidden trade: {df[\"hidden_trade\"].mean()*100:.2f}%')\n",
    "print(f'Strong signal: {df[\"strong_signal\"].mean()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading S&P 500...\n",
      "Downloading VIX...\n",
      "S&P 500: 156 months\n"
     ]
    }
   ],
   "source": [
    "# S&P 500\n",
    "print('Downloading S&P 500...')\n",
    "sp500 = yf.download('^GSPC', start=START_DATE, end=END_DATE, auto_adjust=True, progress=False)\n",
    "sp500.columns = sp500.columns.get_level_values(0)\n",
    "sp500_monthly = sp500['Close'].resample('ME').last()\n",
    "sp500_ret = sp500_monthly.pct_change()\n",
    "\n",
    "# VIX\n",
    "print('Downloading VIX...')\n",
    "vix = yf.download('^VIX', start=START_DATE, end=END_DATE, auto_adjust=True, progress=False)\n",
    "vix.columns = vix.columns.get_level_values(0)\n",
    "vix_monthly = vix['Close'].resample('ME').last()\n",
    "\n",
    "# Realized volatility\n",
    "sp500_vol = sp500['Close'].pct_change().resample('ME').std() * np.sqrt(252)\n",
    "\n",
    "print(f'S&P 500: {len(sp500_monthly)} months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sector ETFs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:08<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sectors: 11, Months: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sector ETFs\n",
    "print('Downloading sector ETFs...')\n",
    "sector_returns = {}\n",
    "\n",
    "for sector, etf in tqdm(SECTOR_ETFS.items()):\n",
    "    try:\n",
    "        data = yf.download(etf, start=START_DATE, end=END_DATE, auto_adjust=True, progress=False)\n",
    "        data.columns = data.columns.get_level_values(0)\n",
    "        monthly = data['Close'].resample('ME').last()\n",
    "        sector_returns[sector] = monthly.pct_change()\n",
    "    except Exception as e:\n",
    "        print(f'Error {etf}: {e}')\n",
    "\n",
    "df_sector_ret = pd.DataFrame(sector_returns)\n",
    "df_sector_ret.index = df_sector_ret.index.to_period('M')\n",
    "\n",
    "print(f'Sectors: {len(df_sector_ret.columns)}, Months: {len(df_sector_ret)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aggregate to Monthly Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_monthly(df):\n",
    "    \"\"\"\n",
    "    Comprehensive monthly aggregation with all feature categories.\n",
    "    \"\"\"\n",
    "    \n",
    "    agg = df.groupby('trade_month').agg(\n",
    "        # === BASIC COUNTS ===\n",
    "        cong_total_trades=('trade_id', 'count'),\n",
    "        cong_buy_count=('is_buy', 'sum'),\n",
    "        cong_sell_count=('is_sell', 'sum'),\n",
    "        cong_unique_politicians=('Name', 'nunique'),\n",
    "        cong_unique_stocks=('Ticker_Clean', 'nunique'),\n",
    "        \n",
    "        # === AMOUNTS ===\n",
    "        cong_total_buy_amount=('amount_proxy', lambda x: (x * df.loc[x.index, 'is_buy']).sum()),\n",
    "        cong_total_sell_amount=('amount_proxy', lambda x: (x * df.loc[x.index, 'is_sell']).sum()),\n",
    "        cong_large_trades=('is_large_trade', 'sum'),\n",
    "        \n",
    "        # === TIMING ===\n",
    "        cong_avg_disclosure_delay=('disclosure_delay', 'mean'),\n",
    "        cong_long_delay_trades=('long_delay', 'sum'),\n",
    "        cong_end_of_month_trades=('end_of_month', 'sum'),\n",
    "        cong_monday_trades=('is_monday', 'sum'),\n",
    "        cong_friday_trades=('is_friday', 'sum'),\n",
    "        \n",
    "        # === COORDINATION ===\n",
    "        cong_coordinated_trades=('coordinated', 'sum'),\n",
    "        cong_party_coordinated_trades=('party_coordinated', 'sum'),\n",
    "        cong_committee_coordinated_trades=('committee_coordinated', 'sum'),\n",
    "        \n",
    "        # === BEHAVIOR ===\n",
    "        cong_frequent_trader_trades=('frequent_trader', 'sum'),\n",
    "        cong_first_time_trades=('first_time', 'sum'),\n",
    "        cong_direction_change_trades=('direction_change', 'sum'),\n",
    "        \n",
    "        # === POWER ===\n",
    "        cong_chair_trades=('is_chair', 'sum'),\n",
    "        cong_senior_trades=('is_senior', 'sum'),\n",
    "        cong_wealthy_trades=('is_wealthy', 'sum'),\n",
    "        cong_high_profile_trades=('high_profile', 'sum'),\n",
    "        cong_avg_power_index=('power_index', 'mean'),\n",
    "        cong_avg_seniority=('years_in_position', 'mean'),\n",
    "        cong_avg_networth=('net_worth', 'mean'),\n",
    "        \n",
    "        # === RELEVANCE ===\n",
    "        cong_committee_related_trades=('committee_related', 'sum'),\n",
    "        cong_info_committee_trades=('is_info_committee', 'sum'),\n",
    "        \n",
    "        # === CONTEXT ===\n",
    "        cong_contrarian_trades=('contrarian', 'sum'),\n",
    "        cong_high_vol_trades=('high_vol', 'sum'),\n",
    "        cong_illiquid_trades=('illiquid', 'sum'),\n",
    "        cong_small_cap_trades=('small_cap', 'sum'),\n",
    "        \n",
    "        # === COMPOSITE ===\n",
    "        cong_smart_money_trades=('smart_money', 'sum'),\n",
    "        cong_insider_ring_trades=('insider_ring', 'sum'),\n",
    "        cong_hidden_trades=('hidden_trade', 'sum'),\n",
    "        cong_strong_signal_trades=('strong_signal', 'sum'),\n",
    "        \n",
    "        # === BY PARTY ===\n",
    "        cong_dem_trades=('Party', lambda x: (x == 'D').sum()),\n",
    "        cong_rep_trades=('Party', lambda x: (x == 'R').sum()),\n",
    "        cong_dem_buys=('is_buy', lambda x: (x & (df.loc[x.index, 'Party'] == 'D')).sum()),\n",
    "        cong_rep_buys=('is_buy', lambda x: (x & (df.loc[x.index, 'Party'] == 'R')).sum()),\n",
    "        cong_dem_sells=('is_sell', lambda x: (x & (df.loc[x.index, 'Party'] == 'D')).sum()),\n",
    "        cong_rep_sells=('is_sell', lambda x: (x & (df.loc[x.index, 'Party'] == 'R')).sum()),\n",
    "        \n",
    "        # === BY CHAMBER ===\n",
    "        cong_senate_trades=('is_senator', 'sum'),\n",
    "        cong_house_trades=('is_senator', lambda x: (x == 0).sum()),\n",
    "    )\n",
    "    \n",
    "    # === DERIVED FEATURES ===\n",
    "    \n",
    "    # Direction\n",
    "    agg['cong_net'] = agg['cong_buy_count'] - agg['cong_sell_count']\n",
    "    agg['cong_buy_ratio'] = agg['cong_buy_count'] / (agg['cong_total_trades'] + 1)\n",
    "    agg['cong_csi'] = (agg['cong_buy_count'] - agg['cong_sell_count']) / (agg['cong_total_trades'] + 1)\n",
    "    agg['cong_csi_volume'] = (agg['cong_total_buy_amount'] - agg['cong_total_sell_amount']) / \\\n",
    "                             (agg['cong_total_buy_amount'] + agg['cong_total_sell_amount'] + 1)\n",
    "    \n",
    "    # Party CSI\n",
    "    agg['cong_csi_D'] = (agg['cong_dem_buys'] - agg['cong_dem_sells']) / (agg['cong_dem_trades'] + 1)\n",
    "    agg['cong_csi_R'] = (agg['cong_rep_buys'] - agg['cong_rep_sells']) / (agg['cong_rep_trades'] + 1)\n",
    "    agg['cong_dem_ratio'] = agg['cong_dem_trades'] / (agg['cong_total_trades'] + 1)\n",
    "    \n",
    "    # Chamber\n",
    "    agg['cong_senate_ratio'] = agg['cong_senate_trades'] / (agg['cong_total_trades'] + 1)\n",
    "    \n",
    "    # Intensity and concentration\n",
    "    agg['cong_intensity'] = agg['cong_total_trades'] / (agg['cong_unique_politicians'] + 1)\n",
    "    agg['cong_concentration'] = agg['cong_total_trades'] / (agg['cong_unique_stocks'] + 1)\n",
    "    agg['cong_trading_intensity'] = agg['cong_total_trades'] / agg['cong_total_trades'].rolling(12, min_periods=3).mean()\n",
    "    \n",
    "    # Proportions\n",
    "    total = agg['cong_total_trades'] + 1\n",
    "    agg['cong_pct_large'] = agg['cong_large_trades'] / total\n",
    "    agg['cong_pct_long_delay'] = agg['cong_long_delay_trades'] / total\n",
    "    agg['cong_pct_end_of_month'] = agg['cong_end_of_month_trades'] / total\n",
    "    agg['cong_pct_coordinated'] = agg['cong_coordinated_trades'] / total\n",
    "    agg['cong_pct_party_coordinated'] = agg['cong_party_coordinated_trades'] / total\n",
    "    agg['cong_pct_committee_coordinated'] = agg['cong_committee_coordinated_trades'] / total\n",
    "    agg['cong_pct_frequent_trader'] = agg['cong_frequent_trader_trades'] / total\n",
    "    agg['cong_pct_first_time'] = agg['cong_first_time_trades'] / total\n",
    "    agg['cong_pct_direction_change'] = agg['cong_direction_change_trades'] / total\n",
    "    agg['cong_pct_chair'] = agg['cong_chair_trades'] / total\n",
    "    agg['cong_pct_senior'] = agg['cong_senior_trades'] / total\n",
    "    agg['cong_pct_committee_related'] = agg['cong_committee_related_trades'] / total\n",
    "    agg['cong_pct_info_committee'] = agg['cong_info_committee_trades'] / total\n",
    "    agg['cong_pct_contrarian'] = agg['cong_contrarian_trades'] / total\n",
    "    agg['cong_pct_high_vol'] = agg['cong_high_vol_trades'] / total\n",
    "    agg['cong_pct_illiquid'] = agg['cong_illiquid_trades'] / total\n",
    "    agg['cong_pct_small_cap'] = agg['cong_small_cap_trades'] / total\n",
    "    agg['cong_pct_smart_money'] = agg['cong_smart_money_trades'] / total\n",
    "    agg['cong_pct_insider_ring'] = agg['cong_insider_ring_trades'] / total\n",
    "    agg['cong_pct_hidden'] = agg['cong_hidden_trades'] / total\n",
    "    agg['cong_pct_strong_signal'] = agg['cong_strong_signal_trades'] / total\n",
    "    \n",
    "    # Binary signals\n",
    "    agg['cong_any_activity'] = (agg['cong_total_trades'] > 0).astype(int)\n",
    "    agg['cong_consensus_buy'] = (agg['cong_buy_ratio'] > 0.7).astype(int)\n",
    "    agg['cong_consensus_sell'] = (agg['cong_buy_ratio'] < 0.3).astype(int)\n",
    "    agg['cong_bipartisan_buy'] = ((agg['cong_csi_D'] > 0) & (agg['cong_csi_R'] > 0)).astype(int)\n",
    "    agg['cong_bipartisan_sell'] = ((agg['cong_csi_D'] < 0) & (agg['cong_csi_R'] < 0)).astype(int)\n",
    "    agg['cong_bipartisan'] = (agg['cong_bipartisan_buy'] | agg['cong_bipartisan_sell']).astype(int)\n",
    "    agg['cong_strong_buy'] = ((agg['cong_csi'] > 0) & (agg['cong_info_committee_trades'] > 0)).astype(int)\n",
    "    \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly observations: 163\n",
      "Features: 83\n"
     ]
    }
   ],
   "source": [
    "congress_monthly = aggregate_monthly(df)\n",
    "\n",
    "print(f'Monthly observations: {len(congress_monthly)}')\n",
    "print(f'Features: {len(congress_monthly.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONGRESSIONAL FEATURES:\n",
      "==================================================\n",
      "  cong_any_activity\n",
      "  cong_avg_disclosure_delay\n",
      "  cong_avg_networth\n",
      "  cong_avg_power_index\n",
      "  cong_avg_seniority\n",
      "  cong_bipartisan\n",
      "  cong_bipartisan_buy\n",
      "  cong_bipartisan_sell\n",
      "  cong_buy_count\n",
      "  cong_buy_ratio\n",
      "  cong_chair_trades\n",
      "  cong_committee_coordinated_trades\n",
      "  cong_committee_related_trades\n",
      "  cong_concentration\n",
      "  cong_consensus_buy\n",
      "  cong_consensus_sell\n",
      "  cong_contrarian_trades\n",
      "  cong_coordinated_trades\n",
      "  cong_csi\n",
      "  cong_csi_D\n",
      "  cong_csi_R\n",
      "  cong_csi_volume\n",
      "  cong_dem_buys\n",
      "  cong_dem_ratio\n",
      "  cong_dem_sells\n",
      "  cong_dem_trades\n",
      "  cong_direction_change_trades\n",
      "  cong_end_of_month_trades\n",
      "  cong_first_time_trades\n",
      "  cong_frequent_trader_trades\n",
      "  cong_friday_trades\n",
      "  cong_hidden_trades\n",
      "  cong_high_profile_trades\n",
      "  cong_high_vol_trades\n",
      "  cong_house_trades\n",
      "  cong_illiquid_trades\n",
      "  cong_info_committee_trades\n",
      "  cong_insider_ring_trades\n",
      "  cong_intensity\n",
      "  cong_large_trades\n",
      "  cong_long_delay_trades\n",
      "  cong_monday_trades\n",
      "  cong_net\n",
      "  cong_party_coordinated_trades\n",
      "  cong_pct_chair\n",
      "  cong_pct_committee_coordinated\n",
      "  cong_pct_committee_related\n",
      "  cong_pct_contrarian\n",
      "  cong_pct_coordinated\n",
      "  cong_pct_direction_change\n",
      "  cong_pct_end_of_month\n",
      "  cong_pct_first_time\n",
      "  cong_pct_frequent_trader\n",
      "  cong_pct_hidden\n",
      "  cong_pct_high_vol\n",
      "  cong_pct_illiquid\n",
      "  cong_pct_info_committee\n",
      "  cong_pct_insider_ring\n",
      "  cong_pct_large\n",
      "  cong_pct_long_delay\n",
      "  cong_pct_party_coordinated\n",
      "  cong_pct_senior\n",
      "  cong_pct_small_cap\n",
      "  cong_pct_smart_money\n",
      "  cong_pct_strong_signal\n",
      "  cong_rep_buys\n",
      "  cong_rep_sells\n",
      "  cong_rep_trades\n",
      "  cong_sell_count\n",
      "  cong_senate_ratio\n",
      "  cong_senate_trades\n",
      "  cong_senior_trades\n",
      "  cong_small_cap_trades\n",
      "  cong_smart_money_trades\n",
      "  cong_strong_buy\n",
      "  cong_strong_signal_trades\n",
      "  cong_total_buy_amount\n",
      "  cong_total_sell_amount\n",
      "  cong_total_trades\n",
      "  cong_trading_intensity\n",
      "  cong_unique_politicians\n",
      "  cong_unique_stocks\n",
      "  cong_wealthy_trades\n"
     ]
    }
   ],
   "source": [
    "# List all features by category\n",
    "print('CONGRESSIONAL FEATURES:')\n",
    "print('='*50)\n",
    "for col in sorted(congress_monthly.columns):\n",
    "    print(f'  {col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aggregate by Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_by_sector(df):\n",
    "    \"\"\"Aggregate by sector x month.\"\"\"\n",
    "    \n",
    "    df_sec = df[df['sector'].notna()].copy()\n",
    "    \n",
    "    agg = df_sec.groupby(['trade_month', 'sector']).agg(\n",
    "        cong_total_trades=('trade_id', 'count'),\n",
    "        cong_buy_count=('is_buy', 'sum'),\n",
    "        cong_sell_count=('is_sell', 'sum'),\n",
    "        cong_unique_politicians=('Name', 'nunique'),\n",
    "        cong_committee_related_trades=('committee_related', 'sum'),\n",
    "        cong_info_committee_trades=('is_info_committee', 'sum'),\n",
    "        cong_chair_trades=('is_chair', 'sum'),\n",
    "        cong_large_trades=('is_large_trade', 'sum'),\n",
    "        cong_coordinated_trades=('coordinated', 'sum'),\n",
    "        cong_first_time_trades=('first_time', 'sum'),\n",
    "        cong_smart_money_trades=('smart_money', 'sum'),\n",
    "        cong_avg_disclosure_delay=('disclosure_delay', 'mean'),\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Committee-related buys/sells\n",
    "    comm_agg = df_sec[df_sec['committee_related'] == 1].groupby(['trade_month', 'sector']).agg(\n",
    "        cong_buys_committee=('is_buy', 'sum'),\n",
    "        cong_sells_committee=('is_sell', 'sum'),\n",
    "    ).reset_index()\n",
    "    \n",
    "    agg = agg.merge(comm_agg, on=['trade_month', 'sector'], how='left')\n",
    "    agg['cong_buys_committee'] = agg['cong_buys_committee'].fillna(0)\n",
    "    agg['cong_sells_committee'] = agg['cong_sells_committee'].fillna(0)\n",
    "    \n",
    "    # Derived\n",
    "    agg['cong_csi_sector'] = (agg['cong_buy_count'] - agg['cong_sell_count']) / (agg['cong_total_trades'] + 1)\n",
    "    n_comm = agg['cong_buys_committee'] + agg['cong_sells_committee']\n",
    "    agg['cong_csi_committee'] = (agg['cong_buys_committee'] - agg['cong_sells_committee']) / (n_comm + 1)\n",
    "    \n",
    "    total = agg['cong_total_trades'] + 1\n",
    "    agg['cong_pct_committee_related'] = agg['cong_committee_related_trades'] / total\n",
    "    agg['cong_pct_large'] = agg['cong_large_trades'] / total\n",
    "    agg['cong_pct_coordinated'] = agg['cong_coordinated_trades'] / total\n",
    "    agg['cong_pct_first_time'] = agg['cong_first_time_trades'] / total\n",
    "    agg['cong_intensity'] = agg['cong_total_trades'] / (agg['cong_unique_politicians'] + 1)\n",
    "    \n",
    "    agg['cong_trading_intensity'] = agg.groupby('sector')['cong_total_trades'].transform(\n",
    "        lambda x: x / x.rolling(12, min_periods=3).mean()\n",
    "    )\n",
    "    \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector-month observations: 1559\n",
      "Sectors: 12\n"
     ]
    }
   ],
   "source": [
    "sector_monthly = aggregate_by_sector(df)\n",
    "\n",
    "print(f'Sector-month observations: {len(sector_monthly)}')\n",
    "print(f'Sectors: {sector_monthly[\"sector\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build Final Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500 base: 155 obs, 92 cols\n"
     ]
    }
   ],
   "source": [
    "# S&P 500 base\n",
    "market_data = pd.DataFrame({\n",
    "    'sp500_ret': sp500_ret,\n",
    "    'sp500_ret_lag': sp500_ret.shift(1),\n",
    "    'sp500_ret_lag2': sp500_ret.shift(2),\n",
    "    'sp500_vol': sp500_vol,\n",
    "    'vix': vix_monthly,\n",
    "    'sp500_mom_3m': sp500_monthly.pct_change(3),\n",
    "    'sp500_mom_6m': sp500_monthly.pct_change(6),\n",
    "    'sp500_mom_12m': sp500_monthly.pct_change(12),\n",
    "    'ret_sp500_1m': sp500_ret.shift(-1),  # TARGET\n",
    "})\n",
    "market_data.index = market_data.index.to_period('M')\n",
    "\n",
    "base_sp500 = market_data.join(congress_monthly, how='left')\n",
    "\n",
    "# Fill missing\n",
    "for col in congress_monthly.columns:\n",
    "    if col in base_sp500.columns:\n",
    "        base_sp500[col] = base_sp500[col].fillna(0)\n",
    "\n",
    "base_sp500 = base_sp500[base_sp500['ret_sp500_1m'].notna()]\n",
    "\n",
    "print(f'S&P 500 base: {len(base_sp500)} obs, {len(base_sp500.columns)} cols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector base: 1583 obs, 32 cols\n"
     ]
    }
   ],
   "source": [
    "# Sector base\n",
    "sector_long = df_sector_ret.stack().reset_index()\n",
    "sector_long.columns = ['period', 'sector', 'ret_sector']\n",
    "\n",
    "sector_long['ret_sector_lag'] = sector_long.groupby('sector')['ret_sector'].shift(1)\n",
    "sector_long['ret_sector_lag2'] = sector_long.groupby('sector')['ret_sector'].shift(2)\n",
    "sector_long['vol_sector_3m'] = sector_long.groupby('sector')['ret_sector'].transform(\n",
    "    lambda x: x.rolling(3, min_periods=1).std()\n",
    ")\n",
    "sector_long['mom_sector_3m'] = sector_long.groupby('sector')['ret_sector'].transform(\n",
    "    lambda x: x.rolling(3, min_periods=1).sum()\n",
    ")\n",
    "sector_long['mom_sector_6m'] = sector_long.groupby('sector')['ret_sector'].transform(\n",
    "    lambda x: x.rolling(6, min_periods=1).sum()\n",
    ")\n",
    "sector_long['ret_sector_1m'] = sector_long.groupby('sector')['ret_sector'].shift(-1)  # TARGET\n",
    "\n",
    "sector_monthly['period'] = sector_monthly['trade_month']\n",
    "\n",
    "base_sector = sector_long.merge(sector_monthly, on=['period', 'sector'], how='left')\n",
    "\n",
    "# Fill missing\n",
    "cong_cols = [c for c in sector_monthly.columns if c.startswith('cong_')]\n",
    "for col in cong_cols:\n",
    "    if col in base_sector.columns:\n",
    "        base_sector[col] = base_sector[col].fillna(0)\n",
    "\n",
    "base_sector = base_sector[base_sector['ret_sector_1m'].notna()]\n",
    "\n",
    "print(f'Sector base: {len(base_sector)} obs, {len(base_sector.columns)} cols')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP CORRELATIONS WITH ret_sp500_1m:\n",
      "==================================================\n",
      "cong_csi_R                       0.1604\n",
      "cong_senior_trades               0.1563\n",
      "cong_bipartisan_buy              0.1316\n",
      "cong_consensus_buy               0.1208\n",
      "cong_pct_high_vol                0.1158\n",
      "cong_high_vol_trades             0.1146\n",
      "cong_pct_chair                  -0.1107\n",
      "cong_net                         0.0990\n",
      "cong_pct_strong_signal          -0.0949\n",
      "cong_pct_info_committee          0.0947\n",
      "cong_dem_ratio                   0.0925\n",
      "cong_party_coordinated_trades    0.0887\n",
      "cong_pct_smart_money             0.0846\n",
      "cong_strong_signal_trades       -0.0844\n",
      "cong_avg_seniority               0.0840\n",
      "Name: ret_sp500_1m, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Correlation with target\n",
    "print('TOP CORRELATIONS WITH ret_sp500_1m:')\n",
    "print('='*50)\n",
    "cong_features = [c for c in base_sp500.columns if c.startswith('cong_')]\n",
    "corr = base_sp500[cong_features + ['ret_sp500_1m']].corr()['ret_sp500_1m'].drop('ret_sp500_1m')\n",
    "print(corr.sort_values(key=abs, ascending=False).head(15).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/prediction_bases/base_sp500_monthly.csv\n",
      "Saved: data/prediction_bases/base_sector_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "sp500_path = os.path.join(OUTPUT_DIR, 'base_sp500_monthly.csv')\n",
    "sector_path = os.path.join(OUTPUT_DIR, 'base_sector_monthly.csv')\n",
    "\n",
    "base_sp500.to_csv(sp500_path)\n",
    "base_sector.to_csv(sector_path, index=False)\n",
    "\n",
    "print(f'Saved: {sp500_path}')\n",
    "print(f'Saved: {sector_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASE CONSTRUCTION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "S&P 500 BASE: 155 months, 92 features\n",
      "SECTOR BASE: 1583 sector-months, 32 features\n",
      "\n",
      "FEATURE CATEGORIES:\n",
      "  Direction: 4 features\n",
      "  Timing: 3 features\n",
      "  Coordination: 3 features\n",
      "  Behavior: 3 features\n",
      "  Power: 3 features\n",
      "  Relevance: 2 features\n",
      "  Context: 4 features\n",
      "  Composite: 4 features\n",
      "  Party: 3 features\n",
      "\n",
      "FILES: data/prediction_bases/\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print('='*70)\n",
    "print('BASE CONSTRUCTION COMPLETE')\n",
    "print('='*70)\n",
    "\n",
    "print(f'\\nS&P 500 BASE: {len(base_sp500)} months, {len(base_sp500.columns)} features')\n",
    "print(f'SECTOR BASE: {len(base_sector)} sector-months, {len(base_sector.columns)} features')\n",
    "\n",
    "print('\\nFEATURE CATEGORIES:')\n",
    "categories = {\n",
    "    'Direction': ['cong_csi', 'cong_csi_volume', 'cong_net', 'cong_buy_ratio'],\n",
    "    'Timing': ['cong_avg_disclosure_delay', 'cong_pct_long_delay', 'cong_pct_end_of_month'],\n",
    "    'Coordination': ['cong_pct_coordinated', 'cong_pct_party_coordinated', 'cong_pct_committee_coordinated'],\n",
    "    'Behavior': ['cong_pct_frequent_trader', 'cong_pct_first_time', 'cong_pct_direction_change'],\n",
    "    'Power': ['cong_pct_chair', 'cong_pct_senior', 'cong_avg_power_index'],\n",
    "    'Relevance': ['cong_pct_committee_related', 'cong_pct_info_committee'],\n",
    "    'Context': ['cong_pct_contrarian', 'cong_pct_high_vol', 'cong_pct_illiquid', 'cong_pct_small_cap'],\n",
    "    'Composite': ['cong_pct_smart_money', 'cong_pct_insider_ring', 'cong_pct_hidden', 'cong_strong_buy'],\n",
    "    'Party': ['cong_csi_D', 'cong_csi_R', 'cong_bipartisan'],\n",
    "}\n",
    "\n",
    "for cat, features in categories.items():\n",
    "    available = [f for f in features if f in base_sp500.columns]\n",
    "    print(f'  {cat}: {len(available)} features')\n",
    "\n",
    "print(f'\\nFILES: {OUTPUT_DIR}/')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "478\n"
     ]
    }
   ],
   "source": [
    "print(base_sp500.isnull().sum().sum())\n",
    "print(base_sector.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500 NaN:\n",
      "sp500_ret          1\n",
      "sp500_ret_lag      2\n",
      "sp500_ret_lag2     3\n",
      "sp500_mom_3m       3\n",
      "sp500_mom_6m       6\n",
      "sp500_mom_12m     12\n",
      "dtype: int64\n",
      "\n",
      "Sector NaN:\n",
      "ret_sector          11\n",
      "ret_sector_lag      22\n",
      "ret_sector_lag2     33\n",
      "vol_sector_3m       22\n",
      "mom_sector_3m       11\n",
      "mom_sector_6m       11\n",
      "trade_month        368\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ver cuáles tienen NaN\n",
    "print(\"S&P 500 NaN:\")\n",
    "print(base_sp500.isnull().sum()[base_sp500.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\nSector NaN:\")\n",
    "print(base_sector.isnull().sum()[base_sector.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500: 155 -> 143\n",
      "Sector: 1583 -> 1550\n",
      "\n",
      "NaN restantes: 0, 338\n"
     ]
    }
   ],
   "source": [
    "# S&P 500: dropear las primeras 12 filas (por mom_12m)\n",
    "base_sp500_clean = base_sp500.dropna()\n",
    "print(f\"S&P 500: {len(base_sp500)} -> {len(base_sp500_clean)}\")\n",
    "\n",
    "# Sector: dropear filas con NaN en variables públicas\n",
    "# (trade_month NaN es porque no hubo trades, las cong_ ya son 0)\n",
    "base_sector_clean = base_sector.dropna(subset=['ret_sector', 'ret_sector_lag', 'ret_sector_lag2', \n",
    "                                                'vol_sector_3m', 'mom_sector_3m', 'mom_sector_6m'])\n",
    "print(f\"Sector: {len(base_sector)} -> {len(base_sector_clean)}\")\n",
    "\n",
    "# Verificar\n",
    "print(f\"\\nNaN restantes: {base_sp500_clean.isnull().sum().sum()}, {base_sector_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN restantes: 0\n"
     ]
    }
   ],
   "source": [
    "# Dropear la columna trade_month de sector (es redundante, ya tenés 'period')\n",
    "base_sector_clean = base_sector_clean.drop(columns=['trade_month'])\n",
    "\n",
    "# Verificar\n",
    "print(f\"NaN restantes: {base_sector_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sp500_clean.to_csv('data/prediction_bases/base_sp500_monthly.csv')\n",
    "base_sector_clean.to_csv('data/prediction_bases/base_sector_monthly.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
