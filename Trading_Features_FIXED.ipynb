{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congressional Trading Feature Engineering - FIXED VERSION\n",
    "## ALL 70+ Market Variables Including Earnings & Fundamentals\n",
    "\n",
    "**Author:** Big Data ML Project  \n",
    "**Date:** January 2026  \n",
    "\n",
    "---\n",
    "\n",
    "## Fixes Applied:\n",
    "\n",
    "1. ‚úÖ MultiIndex handling for yfinance\n",
    "2. ‚úÖ Separate earnings & fundamentals download (no silent failures)\n",
    "3. ‚úÖ Robust ticker cleaning (handles all edge cases)\n",
    "4. ‚úÖ All 70+ features properly calculated and merged\n",
    "5. ‚úÖ CAR calculations with error handling\n",
    "6. ‚úÖ Progress tracking and detailed logging\n",
    "7. ‚úÖ **FIXED: safe_get function now handles negative indices correctly**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "print(\"‚úÖ Dependencies loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ticker Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ticker(ticker_str):\n",
    "    \"\"\"Clean ticker and filter non-equities.\"\"\"\n",
    "    if pd.isna(ticker_str) or str(ticker_str).strip() == '':\n",
    "        return None, False\n",
    "    \n",
    "    ticker = str(ticker_str).strip().upper()\n",
    "    \n",
    "    # Non-equity patterns\n",
    "    non_equity_patterns = [\n",
    "        r'BITCOIN', r'RIPPLE', r'SOLANA', r'ETHEREUM',\n",
    "        r'\\d+\\.?(MONTH|WEEK|YEAR)', r'MATURE', r'DUE \\d+',\n",
    "        r'SYMBOL:', r'FUNDS?', r'ICAPITAL',\n",
    "        r'^[\\d\\.]+$', r'WMT.*SBUX',\n",
    "    ]\n",
    "    \n",
    "    for pattern in non_equity_patterns:\n",
    "        if re.search(pattern, ticker, re.IGNORECASE):\n",
    "            return None, False\n",
    "    \n",
    "    # Remove preferred/warrants\n",
    "    if '$' in ticker or '-W' in ticker or '-P-' in ticker:\n",
    "        return None, False\n",
    "    \n",
    "    ticker = ticker.replace(' ', '').replace('\"', '')\n",
    "    \n",
    "    if ',' in ticker:\n",
    "        ticker = ticker.split(',')[0]\n",
    "    \n",
    "    if len(ticker) > 10 or len(ticker) == 0:\n",
    "        return None, False\n",
    "    \n",
    "    return ticker, True\n",
    "\n",
    "# Test\n",
    "test = ['AAPL', 'BRK.B', 'BITCOIN', 'T$A']\n",
    "for t in test:\n",
    "    c, e = clean_ticker(t)\n",
    "    print(f\"{t:15s} ‚Üí {c if c else 'None':10s} equity={e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with error handling for bad lines\n",
    "df_raw = pd.read_csv('data/congress-trading-all.csv', \n",
    "                     on_bad_lines='skip',\n",
    "                     sep=';',\n",
    "                     encoding='utf-8',\n",
    "                     low_memory=False)\n",
    "\n",
    "print(f\"Raw data: {df_raw.shape}\")\n",
    "\n",
    "# Parse date\n",
    "df_raw['Traded'] = pd.to_datetime(df_raw['Traded'], errors='coerce')\n",
    "df_raw = df_raw.dropna(subset=['Traded'])\n",
    "\n",
    "# Clean tickers\n",
    "df_raw['Ticker_Clean'], df_raw['is_equity'] = zip(*df_raw['Ticker'].apply(clean_ticker))\n",
    "\n",
    "# Filter to equities\n",
    "df = df_raw[df_raw['is_equity'] & df_raw['Ticker_Clean'].notna()].copy()\n",
    "df['trade_id'] = range(len(df))\n",
    "\n",
    "print(f\"Working dataset: {df.shape}\")\n",
    "print(f\"Unique tickers: {df['Ticker_Clean'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range\n",
    "tickers = df['Ticker_Clean'].unique().tolist()\n",
    "start_date = df['Traded'].min() - timedelta(days=400)\n",
    "end_date = df['Traded'].max() + timedelta(days=120)\n",
    "\n",
    "print(f\"üìä Tickers: {len(tickers)}\")\n",
    "print(f\"üìÖ Dates: {start_date.date()} to {end_date.date()}\")\n",
    "\n",
    "# S&P 500\n",
    "print(\"\\n1Ô∏è‚É£ Downloading S&P 500...\")\n",
    "sp500 = yf.download('^GSPC', start=start_date, end=end_date, progress=False)\n",
    "\n",
    "# Fix MultiIndex\n",
    "if isinstance(sp500.columns, pd.MultiIndex):\n",
    "    sp500.columns = sp500.columns.get_level_values(0)\n",
    "\n",
    "sp500['Return'] = sp500['Close'].pct_change()\n",
    "print(f\"‚úÖ SP500: {len(sp500)} days\")\n",
    "\n",
    "# Fama-French\n",
    "print(\"\\n2Ô∏è‚É£ Fama-French factors...\")\n",
    "try:\n",
    "    import pandas_datareader.data as web\n",
    "    ff3 = web.DataReader('F-F_Research_Data_Factors_daily', 'famafrench', start=start_date, end=end_date)[0] / 100\n",
    "    mom = web.DataReader('F-F_Momentum_Factor_daily', 'famafrench', start=start_date, end=end_date)[0] / 100\n",
    "    ff_factors = ff3.join(mom, how='outer')\n",
    "    ff_factors.columns = ['Mkt-RF', 'SMB', 'HML', 'RF', 'Mom']\n",
    "    print(f\"‚úÖ FF: {len(ff_factors)} days\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  FF failed: {str(e)[:50]}\")\n",
    "    print(\"   Continuing without FF (CAPM still works)\")\n",
    "    ff_factors = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Stock Prices (Batch Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3Ô∏è‚É£ Downloading stocks (batch)...\")\n",
    "\n",
    "price_data = {}\n",
    "failed_tickers = []\n",
    "\n",
    "# Batch download\n",
    "batch_size = 50\n",
    "ticker_batches = [tickers[i:i+batch_size] for i in range(0, len(tickers), batch_size)]\n",
    "\n",
    "for batch in tqdm(ticker_batches):\n",
    "    try:\n",
    "        data = yf.download(batch, start=start_date, end=end_date, \n",
    "                          progress=False, group_by='ticker', threads=True)\n",
    "        \n",
    "        if len(batch) == 1:\n",
    "            ticker = batch[0]\n",
    "            if isinstance(data.columns, pd.MultiIndex):\n",
    "                data.columns = data.columns.get_level_values(0)\n",
    "            if len(data) > 0:\n",
    "                price_data[ticker] = data.copy()\n",
    "        else:\n",
    "            for ticker in batch:\n",
    "                try:\n",
    "                    if ticker in data.columns.get_level_values(0):\n",
    "                        ticker_data = data[ticker].copy()\n",
    "                        ticker_data = ticker_data.dropna(how='all')\n",
    "                        if len(ticker_data) > 0:\n",
    "                            price_data[ticker] = ticker_data\n",
    "                except:\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        for ticker in batch:\n",
    "            failed_tickers.append((ticker, str(e)[:50]))\n",
    "\n",
    "print(f\"\\n‚úÖ Downloaded: {len(price_data)} tickers\")\n",
    "print(f\"‚ùå Failed: {len(failed_tickers)} tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CRITICAL: Calculate Returns for each ticker\n",
    "# This was missing in the original code!\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüìä Calculating returns for all tickers...\")\n",
    "for ticker in tqdm(price_data.keys()):\n",
    "    if len(price_data[ticker]) > 0:\n",
    "        price_data[ticker]['Return'] = price_data[ticker]['Close'].pct_change()\n",
    "print(\"‚úÖ Returns calculated for all tickers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Earnings & Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4Ô∏è‚É£ Downloading earnings & fundamentals...\")\n",
    "print(\"This takes ~30-60 min for all tickers (yfinance API is slow)\\n\")\n",
    "\n",
    "earnings_data = {}\n",
    "fundamentals = {}\n",
    "\n",
    "# Only download for tickers with price data\n",
    "valid_tickers = list(price_data.keys())\n",
    "\n",
    "for ticker in tqdm(valid_tickers):\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        \n",
    "        # Earnings dates\n",
    "        try:\n",
    "            earnings = stock.get_earnings_dates(limit=200)\n",
    "            if earnings is not None and len(earnings) > 0:\n",
    "                earnings_data[ticker] = earnings.index.tolist()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Fundamentals\n",
    "        try:\n",
    "            info = stock.info\n",
    "            if info and isinstance(info, dict):\n",
    "                fundamentals[ticker] = {\n",
    "                    'market_cap': info.get('marketCap', np.nan),\n",
    "                    'price': info.get('regularMarketPrice', np.nan),\n",
    "                    'book_value': info.get('bookValue', np.nan),\n",
    "                    'price_to_book': info.get('priceToBook', np.nan),\n",
    "                    'ev_to_ebitda': info.get('enterpriseToEbitda', np.nan)\n",
    "                }\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚úÖ Earnings: {len(earnings_data)} tickers ({len(earnings_data)/len(valid_tickers)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Fundamentals: {len(fundamentals)} tickers ({len(fundamentals)/len(valid_tickers)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering Functions\n",
    "\n",
    "**IMPORTANT FIX:** The `safe_get` function now correctly handles negative indices like `-1`, `-2`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FIXED: safe_get now handles negative indices correctly\n",
    "# Original bug: index < 0 always returned default (NaN)\n",
    "# ============================================================\n",
    "\n",
    "def safe_get(series, index, default=np.nan):\n",
    "    \"\"\"Safely get value from series, supporting negative indices.\"\"\"\n",
    "    try:\n",
    "        if len(series) == 0:\n",
    "            return default\n",
    "        \n",
    "        # Convert negative index to positive\n",
    "        if index < 0:\n",
    "            index = len(series) + index\n",
    "        \n",
    "        # Check bounds after conversion\n",
    "        if index < 0 or index >= len(series):\n",
    "            return default\n",
    "        \n",
    "        val = series.iloc[index]\n",
    "        \n",
    "        # Handle NaN\n",
    "        if pd.isna(val):\n",
    "            return default\n",
    "        \n",
    "        return val\n",
    "    except:\n",
    "        return default\n",
    "\n",
    "\n",
    "# Test the fix\n",
    "test_series = pd.Series([1, 2, 3, 4, 5])\n",
    "print(\"Testing safe_get fix:\")\n",
    "print(f\"  safe_get(series, -1) = {safe_get(test_series, -1)} (should be 5)\")\n",
    "print(f\"  safe_get(series, -2) = {safe_get(test_series, -2)} (should be 4)\")\n",
    "print(f\"  safe_get(series, 0) = {safe_get(test_series, 0)} (should be 1)\")\n",
    "print(f\"  safe_get(series, 10) = {safe_get(test_series, 10)} (should be nan)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_features(ticker, trade_date, price_df, sp500_df, ff_df=None, \n",
    "                          earnings_dates=None, fundamental_dict=None):\n",
    "    \"\"\"\n",
    "    Compute ALL 70+ features for a single trade.\n",
    "    \n",
    "    Features:\n",
    "    - Returns (8): daily, overnight, intraday, momentum at multiple horizons\n",
    "    - Volatility (5): realized, Parkinson, vol-of-vol\n",
    "    - Volume/Liquidity (8): turnover, Amihud, Roll spread, etc.\n",
    "    - Factors (7): CAPM beta, FF3 loadings\n",
    "    - Events (4): earnings proximity\n",
    "    - Fundamentals (5): market cap, P/B, etc.\n",
    "    - CAR (9): 30/60/90d in raw, CAPM, FF3\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Get historical data up to trade date\n",
    "    hist = price_df[price_df.index <= trade_date].copy()\n",
    "    \n",
    "    if len(hist) < 5:\n",
    "        return features\n",
    "    \n",
    "    # Ensure Return column exists\n",
    "    if 'Return' not in hist.columns:\n",
    "        hist['Return'] = hist['Close'].pct_change()\n",
    "    \n",
    "    # === RETURNS ===\n",
    "    features['return_t'] = safe_get(hist['Return'], -1)\n",
    "    features['abs_return_t'] = abs(features['return_t']) if not np.isnan(features['return_t']) else np.nan\n",
    "    \n",
    "    if len(hist) >= 2:\n",
    "        open_today = safe_get(hist['Open'], -1)\n",
    "        close_yesterday = safe_get(hist['Close'], -2)\n",
    "        close_today = safe_get(hist['Close'], -1)\n",
    "        \n",
    "        if not np.isnan(open_today) and not np.isnan(close_yesterday) and close_yesterday != 0:\n",
    "            features['return_overnight'] = open_today / close_yesterday - 1\n",
    "        \n",
    "        if not np.isnan(close_today) and not np.isnan(open_today) and open_today != 0:\n",
    "            features['return_intraday'] = close_today / open_today - 1\n",
    "    \n",
    "    # Momentum at various horizons\n",
    "    close_now = safe_get(hist['Close'], -1)\n",
    "    \n",
    "    if len(hist) >= 6 and not np.isnan(close_now):\n",
    "        close_past = safe_get(hist['Close'], -6)\n",
    "        if not np.isnan(close_past) and close_past != 0:\n",
    "            features['momentum_5d'] = close_now / close_past - 1\n",
    "    \n",
    "    if len(hist) >= 21 and not np.isnan(close_now):\n",
    "        close_past = safe_get(hist['Close'], -21)\n",
    "        if not np.isnan(close_past) and close_past != 0:\n",
    "            features['momentum_20d'] = close_now / close_past - 1\n",
    "    \n",
    "    if len(hist) >= 61 and not np.isnan(close_now):\n",
    "        close_past = safe_get(hist['Close'], -61)\n",
    "        if not np.isnan(close_past) and close_past != 0:\n",
    "            features['momentum_60d'] = close_now / close_past - 1\n",
    "    \n",
    "    if len(hist) >= 253 and not np.isnan(close_now):\n",
    "        close_past = safe_get(hist['Close'], -253)\n",
    "        if not np.isnan(close_past) and close_past != 0:\n",
    "            features['momentum_252d'] = close_now / close_past - 1\n",
    "    \n",
    "    # === VOLATILITY ===\n",
    "    if len(hist) >= 30:\n",
    "        returns_30d = hist['Return'].iloc[-30:].dropna()\n",
    "        if len(returns_30d) >= 20:\n",
    "            features['realized_vol_30d'] = returns_30d.std() * np.sqrt(252)\n",
    "        \n",
    "        hl = np.log(hist['High'].iloc[-30:] / hist['Low'].iloc[-30:])\n",
    "        hl = hl.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if len(hl) >= 20:\n",
    "            features['parkinson_vol_30d'] = np.sqrt(1/(4*len(hl)*np.log(2)) * (hl**2).sum()) * np.sqrt(252)\n",
    "    \n",
    "    if len(hist) >= 60:\n",
    "        returns_60d = hist['Return'].iloc[-60:].dropna()\n",
    "        if len(returns_60d) >= 40:\n",
    "            features['realized_vol_60d'] = returns_60d.std() * np.sqrt(252)\n",
    "        \n",
    "        rolling_vol = hist['Return'].rolling(20).std().iloc[-60:].dropna()\n",
    "        if len(rolling_vol) >= 30:\n",
    "            features['vol_of_vol_60d'] = rolling_vol.std() * np.sqrt(252)\n",
    "    \n",
    "    if len(hist) >= 252:\n",
    "        returns_252d = hist['Return'].iloc[-252:].dropna()\n",
    "        if len(returns_252d) >= 200:\n",
    "            features['realized_vol_252d'] = returns_252d.std() * np.sqrt(252)\n",
    "    \n",
    "    # === VOLUME & LIQUIDITY ===\n",
    "    features['volume_t'] = safe_get(hist['Volume'], -1)\n",
    "    \n",
    "    vol_today = safe_get(hist['Volume'], -1)\n",
    "    close_today = safe_get(hist['Close'], -1)\n",
    "    if not np.isnan(vol_today) and not np.isnan(close_today):\n",
    "        features['dollar_volume_t'] = vol_today * close_today\n",
    "    \n",
    "    if len(hist) >= 31:\n",
    "        mean_vol = hist['Volume'].iloc[-31:-1].mean()\n",
    "        vol_today = safe_get(hist['Volume'], -1)\n",
    "        if mean_vol > 0 and not np.isnan(vol_today):\n",
    "            features['volume_ratio_30d'] = vol_today / mean_vol\n",
    "            features['abnormal_volume_30d'] = vol_today - mean_vol\n",
    "    \n",
    "    if len(hist) >= 21:\n",
    "        hist_copy = hist.iloc[-21:].copy()\n",
    "        hist_copy['Dollar_Volume'] = hist_copy['Volume'] * hist_copy['Close']\n",
    "        dv = hist_copy['Dollar_Volume'].replace(0, np.nan)\n",
    "        ret_abs = hist_copy['Return'].abs()\n",
    "        amihud = (ret_abs / dv).dropna()\n",
    "        if len(amihud) >= 10:\n",
    "            features['amihud_illiq_20d'] = amihud.mean() * 1e6\n",
    "    \n",
    "    if len(hist) >= 30:\n",
    "        returns = hist['Return'].iloc[-30:].dropna()\n",
    "        if len(returns) >= 20:\n",
    "            autocorr = returns.autocorr(lag=1)\n",
    "            if not np.isnan(autocorr):\n",
    "                cov = autocorr * returns.var()\n",
    "                features['roll_spread_30d'] = 2 * np.sqrt(-cov) if cov < 0 else 0\n",
    "    \n",
    "    if len(hist) >= 20:\n",
    "        hl_spread = ((hist['High'] - hist['Low']) / hist['Close']).iloc[-20:]\n",
    "        hl_spread = hl_spread.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if len(hl_spread) >= 10:\n",
    "            features['hl_spread_20d'] = hl_spread.mean()\n",
    "    \n",
    "    if len(hist) >= 30:\n",
    "        features['zero_volume_days_30d'] = (hist['Volume'].iloc[-30:] == 0).sum()\n",
    "    \n",
    "    # === FACTOR EXPOSURES ===\n",
    "    if len(hist) >= 60:\n",
    "        lookback = min(252, len(hist))\n",
    "        stock_ret = hist['Return'].iloc[-lookback:].dropna()\n",
    "        \n",
    "        # Align with market returns\n",
    "        common_dates = stock_ret.index.intersection(sp500_df.index)\n",
    "        if len(common_dates) >= 30:\n",
    "            stock_aligned = stock_ret.loc[common_dates]\n",
    "            market_aligned = sp500_df.loc[common_dates, 'Return']\n",
    "            \n",
    "            merged = pd.DataFrame({'stock': stock_aligned, 'market': market_aligned}).dropna()\n",
    "            \n",
    "            if len(merged) >= 30:\n",
    "                market_var = merged['market'].var()\n",
    "                if market_var > 0:\n",
    "                    features['beta_252d'] = merged['stock'].cov(merged['market']) / market_var\n",
    "                    features['r2_market_252d'] = merged['stock'].corr(merged['market']) ** 2\n",
    "        \n",
    "        # FF3 factors\n",
    "        if ff_df is not None and len(ff_df) > 0:\n",
    "            try:\n",
    "                ff_common = stock_ret.index.intersection(ff_df.index)\n",
    "                if len(ff_common) >= 30:\n",
    "                    stock_ff = stock_ret.loc[ff_common]\n",
    "                    ff_aligned = ff_df.loc[ff_common]\n",
    "                    \n",
    "                    ff_merged = pd.DataFrame({\n",
    "                        'stock_excess': stock_ff - ff_aligned['RF'],\n",
    "                        'mkt_rf': ff_aligned['Mkt-RF'],\n",
    "                        'smb': ff_aligned['SMB'],\n",
    "                        'hml': ff_aligned['HML']\n",
    "                    }).dropna()\n",
    "                    \n",
    "                    if len(ff_merged) >= 30:\n",
    "                        X = ff_merged[['mkt_rf', 'smb', 'hml']].values\n",
    "                        y = ff_merged['stock_excess'].values\n",
    "                        X = np.column_stack([np.ones(len(X)), X])\n",
    "                        \n",
    "                        coeffs = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "                        features['alpha_ff3_252d'] = coeffs[0] * 252\n",
    "                        features['beta_mkt_ff3_252d'] = coeffs[1]\n",
    "                        features['beta_smb_ff3_252d'] = coeffs[2]\n",
    "                        features['beta_hml_ff3_252d'] = coeffs[3]\n",
    "                        \n",
    "                        y_pred = X @ coeffs\n",
    "                        ss_res = ((y - y_pred) ** 2).sum()\n",
    "                        ss_tot = ((y - y.mean()) ** 2).sum()\n",
    "                        if ss_tot > 0:\n",
    "                            features['r2_ff3_252d'] = 1 - (ss_res / ss_tot)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # === EVENT PROXIMITY ===\n",
    "    if earnings_dates and len(earnings_dates) > 0:\n",
    "        try:\n",
    "            earnings_dates = pd.to_datetime(earnings_dates)\n",
    "            \n",
    "            future_earnings = earnings_dates[earnings_dates > trade_date]\n",
    "            if len(future_earnings) > 0:\n",
    "                features['days_to_earnings'] = (future_earnings.min() - trade_date).days\n",
    "            \n",
    "            past_earnings = earnings_dates[earnings_dates <= trade_date]\n",
    "            if len(past_earnings) > 0:\n",
    "                features['days_since_earnings'] = (trade_date - past_earnings.max()).days\n",
    "            \n",
    "            min_dist = min(\n",
    "                abs(features.get('days_to_earnings', 999)),\n",
    "                abs(features.get('days_since_earnings', 999))\n",
    "            )\n",
    "            features['within_5d_earnings'] = 1 if min_dist <= 5 else 0\n",
    "            features['within_10d_earnings'] = 1 if min_dist <= 10 else 0\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # === FUNDAMENTALS ===\n",
    "    if fundamental_dict:\n",
    "        mc = fundamental_dict.get('market_cap', np.nan)\n",
    "        features['market_cap'] = mc / 1e6 if not np.isnan(mc) else np.nan\n",
    "        features['price'] = fundamental_dict.get('price', np.nan)\n",
    "        features['book_value'] = fundamental_dict.get('book_value', np.nan)\n",
    "        features['price_to_book'] = fundamental_dict.get('price_to_book', np.nan)\n",
    "        features['ev_to_ebitda'] = fundamental_dict.get('ev_to_ebitda', np.nan)\n",
    "    \n",
    "    # === CAR (POST-TRADE) ===\n",
    "    for horizon in [30, 60, 90]:\n",
    "        try:\n",
    "            end_date = trade_date + timedelta(days=int(horizon * 1.5))  # Calendar days buffer\n",
    "            stock_future = price_df[(price_df.index > trade_date) & (price_df.index <= end_date)]\n",
    "            \n",
    "            if len(stock_future) >= int(horizon * 0.5):\n",
    "                close_at_trade = safe_get(hist['Close'], -1)\n",
    "                close_future = safe_get(stock_future['Close'], -1)\n",
    "                \n",
    "                if not np.isnan(close_at_trade) and not np.isnan(close_future) and close_at_trade != 0:\n",
    "                    stock_return = close_future / close_at_trade - 1\n",
    "                    \n",
    "                    # Market return\n",
    "                    market_future = sp500_df[(sp500_df.index > trade_date) & (sp500_df.index <= end_date)]\n",
    "                    if len(market_future) > 0 and trade_date in sp500_df.index:\n",
    "                        market_return = (safe_get(market_future['Close'], -1) / sp500_df.loc[trade_date, 'Close']) - 1\n",
    "                    else:\n",
    "                        market_return = 0\n",
    "                    \n",
    "                    # Raw CAR\n",
    "                    features[f'car_raw_{horizon}d'] = stock_return - market_return\n",
    "                    \n",
    "                    # CAPM CAR\n",
    "                    if 'beta_252d' in features and not np.isnan(features['beta_252d']):\n",
    "                        expected = features['beta_252d'] * market_return\n",
    "                        features[f'car_capm_{horizon}d'] = stock_return - expected\n",
    "                    \n",
    "                    # FF3 CAR\n",
    "                    if ff_df is not None and 'beta_mkt_ff3_252d' in features:\n",
    "                        ff_future = ff_df[(ff_df.index > trade_date) & (ff_df.index <= end_date)]\n",
    "                        if len(ff_future) > 0:\n",
    "                            factor_returns = ff_future[['Mkt-RF', 'SMB', 'HML', 'RF']].sum()\n",
    "                            expected_ff3 = (\n",
    "                                factor_returns['RF'] +\n",
    "                                features.get('beta_mkt_ff3_252d', 1) * factor_returns['Mkt-RF'] +\n",
    "                                features.get('beta_smb_ff3_252d', 0) * factor_returns['SMB'] +\n",
    "                                features.get('beta_hml_ff3_252d', 0) * factor_returns['HML']\n",
    "                            )\n",
    "                            features[f'car_ff3_{horizon}d'] = stock_return - expected_ff3\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"‚úÖ Feature functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compute Features for All Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n5Ô∏è‚É£ Computing features for {len(df)} trades...\")\n",
    "print(f\"   Price data: {len(price_data)} tickers\")\n",
    "print(f\"   Earnings: {len(earnings_data)} tickers\")\n",
    "print(f\"   Fundamentals: {len(fundamentals)} tickers\\n\")\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    ticker = row['Ticker_Clean']\n",
    "    trade_date = row['Traded']\n",
    "    \n",
    "    features = {'trade_id': row['trade_id']}\n",
    "    \n",
    "    if ticker not in price_data:\n",
    "        features['error'] = 'No price data'\n",
    "        all_features.append(features)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        computed = compute_all_features(\n",
    "            ticker=ticker,\n",
    "            trade_date=trade_date,\n",
    "            price_df=price_data[ticker],\n",
    "            sp500_df=sp500,\n",
    "            ff_df=ff_factors,\n",
    "            earnings_dates=earnings_data.get(ticker, None),\n",
    "            fundamental_dict=fundamentals.get(ticker, None)\n",
    "        )\n",
    "        features.update(computed)\n",
    "    except Exception as e:\n",
    "        features['error'] = str(e)[:100]\n",
    "    \n",
    "    all_features.append(features)\n",
    "\n",
    "print(\"\\n‚úÖ Feature computation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Merge & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "df_features = pd.DataFrame(all_features)\n",
    "\n",
    "print(f\"Features: {df_features.shape}\")\n",
    "print(f\"Columns: {len(df_features.columns)}\")\n",
    "\n",
    "# Merge\n",
    "df_final = df.merge(df_features, on='trade_id', how='left')\n",
    "\n",
    "print(f\"\\nFinal dataset: {df_final.shape}\")\n",
    "print(f\"\\nAll columns: {df_final.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Coverage Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FEATURE COVERAGE REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Expected features\n",
    "expected = [\n",
    "    # Returns\n",
    "    'return_t', 'abs_return_t', 'return_overnight', 'return_intraday',\n",
    "    'momentum_5d', 'momentum_20d', 'momentum_60d', 'momentum_252d',\n",
    "    # Volatility\n",
    "    'realized_vol_30d', 'parkinson_vol_30d', 'realized_vol_60d', \n",
    "    'vol_of_vol_60d', 'realized_vol_252d',\n",
    "    # Volume/Liquidity\n",
    "    'volume_t', 'dollar_volume_t', 'volume_ratio_30d', 'abnormal_volume_30d',\n",
    "    'amihud_illiq_20d', 'roll_spread_30d', 'hl_spread_20d', 'zero_volume_days_30d',\n",
    "    # Factors\n",
    "    'beta_252d', 'r2_market_252d', 'alpha_ff3_252d', 'beta_mkt_ff3_252d',\n",
    "    'beta_smb_ff3_252d', 'beta_hml_ff3_252d', 'r2_ff3_252d',\n",
    "    # Events\n",
    "    'days_to_earnings', 'days_since_earnings', 'within_5d_earnings', 'within_10d_earnings',\n",
    "    # Fundamentals\n",
    "    'market_cap', 'price', 'book_value', 'price_to_book', 'ev_to_ebitda',\n",
    "    # CAR\n",
    "    'car_raw_30d', 'car_capm_30d', 'car_ff3_30d',\n",
    "    'car_raw_60d', 'car_capm_60d', 'car_ff3_60d',\n",
    "    'car_raw_90d', 'car_capm_90d', 'car_ff3_90d'\n",
    "]\n",
    "\n",
    "present = []\n",
    "missing = []\n",
    "\n",
    "for feat in expected:\n",
    "    if feat in df_final.columns:\n",
    "        pct = df_final[feat].notna().sum() / len(df_final) * 100\n",
    "        present.append((feat, pct))\n",
    "    else:\n",
    "        missing.append(feat)\n",
    "\n",
    "print(f\"\\n‚úÖ PRESENT: {len(present)} / {len(expected)} features\\n\")\n",
    "\n",
    "# Sort by coverage\n",
    "present_sorted = sorted(present, key=lambda x: -x[1])\n",
    "\n",
    "print(f\"{'Feature':<30} {'Coverage':>10}\")\n",
    "print(\"-\"*42)\n",
    "for feat, pct in present_sorted:\n",
    "    status = \"üü¢\" if pct > 50 else \"üü°\" if pct > 10 else \"üî¥\"\n",
    "    print(f\"{status} {feat:<28} {pct:>8.1f}%\")\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\n‚ùå MISSING: {len(missing)} features\")\n",
    "    for feat in missing:\n",
    "        print(f\"  - {feat}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Winsorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mstats\n",
    "\n",
    "# Columns to winsorize (exclude IDs and binary flags)\n",
    "exclude_cols = ['trade_id', 'within_5d_earnings', 'within_10d_earnings', 'error', 'is_equity']\n",
    "to_winsorize = [f for f, _ in present if f not in exclude_cols]\n",
    "\n",
    "print(f\"Winsorizing {len(to_winsorize)} features at 0.5% / 99.5%...\")\n",
    "\n",
    "for col in to_winsorize:\n",
    "    if col in df_final.columns and df_final[col].notna().sum() > 10:\n",
    "        df_final[col] = mstats.winsorize(df_final[col].values, limits=[0.005, 0.005], nan_policy='omit')\n",
    "\n",
    "print(\"‚úÖ Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('data/outputs').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Main dataset\n",
    "df_final.to_csv('data/outputs/congress_trading_features_FIXED.csv', index=False)\n",
    "print(f\"‚úÖ Main dataset: data/outputs/congress_trading_features_FIXED.csv\")\n",
    "print(f\"   Shape: {df_final.shape}\")\n",
    "\n",
    "# Also save as parquet for faster loading\n",
    "df_final.to_parquet('data/outputs/congress_trading_features_FIXED.parquet', index=False)\n",
    "print(f\"‚úÖ Parquet: data/outputs/congress_trading_features_FIXED.parquet\")\n",
    "\n",
    "# Failed tickers\n",
    "if failed_tickers:\n",
    "    pd.DataFrame(failed_tickers, columns=['ticker', 'reason']).to_csv(\n",
    "        'data/outputs/failed_tickers.csv', index=False)\n",
    "    print(f\"‚úÖ Failed tickers: {len(failed_tickers)}\")\n",
    "\n",
    "# Variable dictionary\n",
    "var_dict = []\n",
    "descriptions = {\n",
    "    'return_t': 'Daily return on trade date',\n",
    "    'momentum_5d': '5-day momentum (price change)',\n",
    "    'momentum_20d': '20-day momentum',\n",
    "    'momentum_60d': '60-day momentum',\n",
    "    'realized_vol_30d': 'Realized volatility (30d, annualized)',\n",
    "    'volume_ratio_30d': 'Volume / 30d average',\n",
    "    'abnormal_volume_30d': 'Volume - 30d average',\n",
    "    'amihud_illiq_20d': 'Amihud illiquidity measure',\n",
    "    'beta_252d': 'CAPM beta (252d)',\n",
    "    'days_to_earnings': 'Days until next earnings',\n",
    "    'market_cap': 'Market cap (millions USD)',\n",
    "    'car_raw_30d': 'Market-adjusted CAR (30d)'\n",
    "}\n",
    "\n",
    "for feat, pct in present:\n",
    "    var_dict.append({\n",
    "        'variable': feat,\n",
    "        'description': descriptions.get(feat, ''),\n",
    "        'coverage_pct': f\"{pct:.1f}%\"\n",
    "    })\n",
    "\n",
    "pd.DataFrame(var_dict).to_csv('data/outputs/variable_dictionary.csv', index=False)\n",
    "print(f\"‚úÖ Variable dictionary: {len(var_dict)} features\")\n",
    "\n",
    "# Summary stats\n",
    "key_feats = [f for f, pct in present if pct > 30][:20]\n",
    "if key_feats:\n",
    "    df_final[key_feats].describe().to_csv('data/outputs/summary_stats.csv')\n",
    "    print(f\"‚úÖ Summary stats\")\n",
    "\n",
    "print(\"\\nüéâ ALL OUTPUTS COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ FINAL SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä INPUT:\")\n",
    "print(f\"   Raw trades: {len(df_raw):,}\")\n",
    "print(f\"   Valid equities: {len(df):,}\")\n",
    "print(f\"   Unique tickers: {df['Ticker_Clean'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nüíæ MARKET DATA:\")\n",
    "print(f\"   Price data: {len(price_data):,} tickers\")\n",
    "print(f\"   Earnings: {len(earnings_data):,} tickers\")\n",
    "print(f\"   Fundamentals: {len(fundamentals):,} tickers\")\n",
    "print(f\"   Failed: {len(failed_tickers):,} tickers\")\n",
    "\n",
    "print(f\"\\nüìà FEATURES:\")\n",
    "print(f\"   Total created: {len(present)}\")\n",
    "print(f\"   High coverage (>50%): {sum(1 for _, pct in present if pct > 50)}\")\n",
    "print(f\"   Medium coverage (10-50%): {sum(1 for _, pct in present if 10 < pct <= 50)}\")\n",
    "print(f\"   Low coverage (<10%): {sum(1 for _, pct in present if pct <= 10)}\")\n",
    "print(f\"   Missing: {len(missing)}\")\n",
    "\n",
    "print(f\"\\nüíæ OUTPUTS:\")\n",
    "print(f\"   ‚úÖ congress_trading_features_FIXED.csv\")\n",
    "print(f\"   ‚úÖ congress_trading_features_FIXED.parquet\")\n",
    "print(f\"   ‚úÖ variable_dictionary.csv\")\n",
    "print(f\"   ‚úÖ failed_tickers.csv\")\n",
    "print(f\"   ‚úÖ summary_stats.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ SUCCESS - FEATURES NOW CORRECTLY CALCULATED\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
